{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03046c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "import random\n",
    "from difflib import SequenceMatcher\n",
    "from scipy import stats\n",
    "import sacrebleu\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "import spacy\n",
    "import re\n",
    "import edist.sed as sed\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac6c851",
   "metadata": {},
   "source": [
    "German word2vec model Facebook https://fasttext.cc/docs/en/crawl-vectors.html (cc.de.300.bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from https://gitlab.ub.uni-bielefeld.de/bpaassen/python-edit-distances/-/blob/master/sed_demo.ipynb\n",
    "def levenshtein(s1, s2):\n",
    "    return sed.standard_sed(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f222dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/difflib.html\n",
    "    \n",
    "def changes_spread(original_tokenized, changed_tokenized, opcodes):\n",
    "    start_change = -1\n",
    "    end_change = -1\n",
    "    for opcode in opcodes:\n",
    "        if opcode[0] != 'equal':\n",
    "            start_change = opcode[1]\n",
    "            break\n",
    "    for opcode in reversed(opcodes):\n",
    "        if opcode[0] != 'equal':\n",
    "            end_change = opcode[2]\n",
    "            break\n",
    "    return max(0, end_change-start_change)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8464b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_in_capital(sentence_tokenized, highlight_positions):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        sentence_tokenized: tokenzied sentence\n",
    "        highlight_positions: list of 2-sized tuples: [(p1, p2), (p3,p4), ...]\n",
    "            where we want to highlight sentence[p1:p2], sentence[p3:p4]\n",
    "    \"\"\"\n",
    "    highlighted_sentence = []\n",
    "    \n",
    "    last = 0  # index of the last position added to the new sentence\n",
    "    for (start, stop) in highlight_positions:\n",
    "        highlighted_sentence.extend(\n",
    "            sentence_tokenized[last:start] + \\\n",
    "            [w.upper() for w in sentence_tokenized[start:stop]]\n",
    "        )\n",
    "        last = stop\n",
    "    if last < len(sentence_tokenized):\n",
    "        highlighted_sentence.extend(\n",
    "            sentence_tokenized[last:]\n",
    "        )\n",
    "    return ' '.join(highlighted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de55b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_chunk_changed(original_tokenized, changed_tokenized, opcodes, \n",
    "                      chunk_max_length=1, spacy_model=None, w2v_model=None):\n",
    "    # Return the original and changed sentences with the chunk highlighted in capital\n",
    "    # Return whether this sentence has only two chunk changes within the max length. \n",
    "    # And return the distance between the two changed chunks\n",
    "    \n",
    "    is_two_chunk_changed = False\n",
    "    chunk_distance = pd.NA\n",
    "    is_same_subtree = pd.NA\n",
    "    changes_similarity = pd.NA\n",
    "    \n",
    "    \n",
    "    \n",
    "    changes_types = [o[0] for o in opcodes]\n",
    "    \n",
    "    # If not exactly two changes, return\n",
    "    if not (all(changes_type == 'replace' or changes_type == 'equal' for changes_type in changes_types) and \\\n",
    "        changes_types.count('replace') == 2):\n",
    "        return is_two_chunk_changed, chunk_distance, is_same_subtree, changes_similarity\n",
    "    \n",
    "    # Find the positions of the two changed chunks\n",
    "    i_replace = [i for i, change in enumerate(changes_types) if change == \"replace\"]\n",
    "    \n",
    "    # If two changed chunks not have length less than chunk_max_length, return\n",
    "    if not (opcodes[i_replace[0]][2] - opcodes[i_replace[0]][1] <= chunk_max_length and \\\n",
    "            opcodes[i_replace[1]][2] - opcodes[i_replace[1]][1] <= chunk_max_length):\n",
    "        return is_two_chunk_changed, chunk_distance, is_same_subtree, changes_similarity\n",
    "    \n",
    "    # At this point, this should be a valid two_chunk within length change\n",
    "    is_two_chunk_changed = True\n",
    "    \n",
    "    # Check if there is indeed an equal chunks in between of the two changed chunk\n",
    "    # Calculate the distance between two chunks = the equal chunk in between\n",
    "    i_equal_in_between = (i_replace[1] + i_replace[0]) // 2\n",
    "    assert opcodes[i_equal_in_between][0] == 'equal'\n",
    "    chunk_distance = opcodes[i_equal_in_between][2] - opcodes[i_equal_in_between][1]\n",
    "\n",
    "\n",
    "    if spacy_model is not None: \n",
    "        # In the two_chunk_changed case when chunk_max_length=1, i.e., only two words are changed \n",
    "        # comparing to the original translation\n",
    "        # Check if the two changed words are in the same sub tree of the dependency tree\n",
    "        if (opcodes[i_replace[0]][4] - opcodes[i_replace[0]][3] == 1 and \\\n",
    "            opcodes[i_replace[1]][4] - opcodes[i_replace[1]][3] == 1):\n",
    "            # Find the ancestors and children of the two changed words\n",
    "            doc = spacy_model(' '.join(changed_tokenized))\n",
    "            token1, token2 = None, None\n",
    "            family1, family2 = None, None\n",
    "            for token in doc:\n",
    "                if token.text == changed_tokenized[opcodes[i_replace[0]][3]]:\n",
    "                    token1 = token.text\n",
    "                    family1 = list(token.ancestors) + list(token.children)\n",
    "                    family1 = [t.text for t in family1]\n",
    "                elif token.text == changed_tokenized[opcodes[i_replace[1]][3]]:\n",
    "                    token2 = token.text\n",
    "                    family2 = list(token.ancestors) + list(token.children)\n",
    "                    family2 = [t.text for t in family2]\n",
    "\n",
    "            if token1 is None or token2 is None:\n",
    "                is_same_subtree = pd.NA\n",
    "            else:\n",
    "                if token1 in family2 or token2 in family1:\n",
    "                    is_same_subtree = True\n",
    "                else:\n",
    "                    is_same_subtree = False\n",
    "\n",
    "\n",
    "    # Calculate the senmatic similarity of the two changed words (cosine similarity in [-1, 1])\n",
    "    if w2v_model is not None:\n",
    "        # Can only calculate when only two single tokens are changed\n",
    "        if (opcodes[i_replace[0]][4] - opcodes[i_replace[0]][3] == 1 and \\\n",
    "            opcodes[i_replace[1]][4] - opcodes[i_replace[1]][3] == 1 and \\\n",
    "            opcodes[i_replace[0]][2] - opcodes[i_replace[0]][1] == 1 and \\\n",
    "            opcodes[i_replace[1]][2] - opcodes[i_replace[1]][1] == 1):\n",
    "\n",
    "            original_word_1 = original_tokenized[opcodes[i_replace[0]][1]]\n",
    "            changed_word_1 = changed_tokenized[opcodes[i_replace[0]][3]]\n",
    "\n",
    "            original_word_2 = original_tokenized[opcodes[i_replace[1]][1]]\n",
    "            changed_word_2 = changed_tokenized[opcodes[i_replace[1]][3]]\n",
    "\n",
    "            if original_word_1 in w2v_model.index_to_key and original_word_2 in w2v_model.index_to_key and \\\n",
    "                changed_word_1 in w2v_model.index_to_key and changed_word_2 in w2v_model.index_to_key:\n",
    "                changes_similarity = [{'original_word': original_word_1, \n",
    "                                       'changed_word': changed_word_1, \n",
    "                                       'semantic_similarity': w2v_model.similarity(original_word_1, changed_word_1)},\n",
    "                                      {'original_word': original_word_2,\n",
    "                                       'changed_word': changed_word_2,\n",
    "                                       'semantic_similarity': w2v_model.similarity(original_word_2, changed_word_2)}]\n",
    "\n",
    "\n",
    "    return is_two_chunk_changed, chunk_distance, is_same_subtree, changes_similarity\n",
    "    \n",
    "    \n",
    "def highlight_changes(original_tokenized, changed_tokenized, opcodes):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        original_tokenized: tokenized original sentence\n",
    "        changed_tokenized: tokenized changed sentence\n",
    "        opcodes: changes to get from `original_tokenized` to `changed_tokenized`\n",
    "    Returns:\n",
    "        original_sentence and changed_sentence with the changes highlighted in capital\n",
    "    \"\"\"\n",
    "    \n",
    "    highlighted_original_sentence_positions = []\n",
    "    highlighted_changed_sentence_positions = []\n",
    "    \n",
    "    for opcode in opcodes:\n",
    "        tag, i1, i2, j1, j2 = opcode[0], opcode[1], opcode[2], opcode[3], opcode[4]\n",
    "        \n",
    "        if tag != 'equal':\n",
    "            highlighted_original_sentence_positions.append((i1, i2))\n",
    "            highlighted_changed_sentence_positions.append((j1, j2))\n",
    "            \n",
    "    original_sentence_highlighted = highlight_in_capital(\n",
    "        sentence_tokenized=original_tokenized, \n",
    "        highlight_positions=highlighted_original_sentence_positions\n",
    "    )\n",
    "    \n",
    "    changed_sentence_highlighted = highlight_in_capital(\n",
    "        sentence_tokenized=changed_tokenized, \n",
    "        highlight_positions=highlighted_changed_sentence_positions\n",
    "    )\n",
    "    \n",
    "    return original_sentence_highlighted, changed_sentence_highlighted\n",
    "    \n",
    "    \n",
    "def calculate_change(original_tokenized, changed_tokenized):\n",
    "    # Return the original and changed sentences with the changes highlighted in capital\n",
    "    opcodes = SequenceMatcher(None, original_tokenized, changed_tokenized).get_opcodes()\n",
    "    \n",
    "    # Convert the opcodes (displayed by word index) to changes in words\n",
    "    changes = []\n",
    "    for opcode in opcodes:\n",
    "        tag, i1, i2, j1, j2 = opcode[0], opcode[1], opcode[2], opcode[3], opcode[4]\n",
    "        if tag != 'equal':\n",
    "            changes.append((tag, ' '.join(original_tokenized[i1:i2]), ' '.join(changed_tokenized[j1:j2])))\n",
    "    \n",
    "    return opcodes, changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alignment(path_prefix):\n",
    "    alignment_file_path = f\"{path_prefix}_word_alignment.txt\"\n",
    "    if not os.path.isfile(alignment_file_path):\n",
    "        raise RuntimeError(\"Alignment file not exist.\")\n",
    "        \n",
    "    else:\n",
    "        with open(alignment_file_path) as f:\n",
    "            lines = [line.rstrip() for line in f]\n",
    "            \n",
    "        translation_alignment = []\n",
    "        for line in lines:\n",
    "            word_pairs = line.split()\n",
    "            word_pairs = [word_pair.split('<sep>') for word_pair in word_pairs]\n",
    "            translation_alignment.append(dict(word_pairs))\n",
    "        return translation_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reason_of_change(alignment, changes, perturbed_src_word):\n",
    "    if type(changes) != list:\n",
    "        return pd.NA\n",
    "    elif perturbed_src_word not in alignment.keys():\n",
    "        changes[0]['change_type'] = None\n",
    "        changes[1]['change_type'] = None\n",
    "    elif alignment[perturbed_src_word] == changes[0]['changed_word'] and alignment[perturbed_src_word] == changes[1]['changed_word']:\n",
    "        # Both changes are due to perturbation --> weird --> pass\n",
    "        changes[0]['change_type'] = None\n",
    "        changes[1]['change_type'] = None\n",
    "    elif alignment[perturbed_src_word] != changes[0]['changed_word'] and alignment[perturbed_src_word] != changes[1]['changed_word']:\n",
    "        # Both changes NOT due to perturbation --> weird --> pass\n",
    "        changes[0]['change_type'] = None\n",
    "        changes[1]['change_type'] = None\n",
    "    elif alignment[perturbed_src_word] == changes[0]['changed_word']:\n",
    "        changes[0]['change_type'] = \"perturbed\"\n",
    "        changes[1]['change_type'] = \"not_perturbed\"\n",
    "    elif alignment[perturbed_src_word] == changes[1]['changed_word']:\n",
    "        changes[0]['change_type'] = \"not_perturbed\"\n",
    "        changes[1]['change_type'] = \"perturbed\"\n",
    "        \n",
    "    return changes\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ed6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag_not_perturbed_change(changes, spacy_model):\n",
    "    if type(changes) != list:\n",
    "        return pd.NA\n",
    "    elif changes[0]['change_type'] == \"not_perturbed\":\n",
    "        doc = spacy_model(changes[0]['changed_word'])\n",
    "        return [t.pos_ for t in doc][0]\n",
    "    elif changes[1]['change_type'] == \"not_perturbed\":\n",
    "        doc = spacy_model(changes[1]['changed_word'])\n",
    "        return [t.pos_ for t in doc][0]\n",
    "    return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8355ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output_df(dataset, src_lang, tgt_lang, perturb_type, beam, replacement_strategy, analyse_feature=True, \n",
    "                   ignore_case=False, no_of_replacements=1, chunk_max_length=1, spacy_model=None, \n",
    "                   w2v_model=None, use_alignment=False, winoMT=False, ref_available=False,\n",
    "                   two_chunks_analysis=False):\n",
    "    if winoMT:\n",
    "        path_prefix = \"../output/winoMT_asmetric/wmt19_winoMT_perturbed\"\n",
    "        output_df = pd.read_csv('../output/winoMT_asmetric/wmt19_winoMT_perturbed_format.csv', index_col=0)  \n",
    "    else:\n",
    "        path_prefix = f\"../output/{dataset}/{replacement_strategy}/beam{beam}_perturb{perturb_type}/{no_of_replacements}replacements/seed0/translations\"\n",
    "        output_df = pd.read_csv(f\"{path_prefix}.csv\", index_col=0)\n",
    "\n",
    "        # Join to get the translation of the original sentences as well\n",
    "        original_trans_path_prefix = \\\n",
    "            f\"../output/{dataset}/original/translations\"\n",
    "        original_trans = pd.read_csv(\n",
    "            f\"{original_trans_path_prefix}.csv\", index_col=0\n",
    "        )['SRC-Trans']\n",
    "        output_df = pd.merge(output_df, original_trans, how='left', left_on='SRC_original_idx',\n",
    "                            right_on=original_trans.index)\n",
    "        \n",
    "        \n",
    "    if 'mustSHE' in dataset:\n",
    "        output_df = output_df.merge(pd.read_csv(\n",
    "            f\"../data/MuST-SHE_v1.2/MuST-SHE-v1.2-data/tsv/MONOLINGUAL.fr_v1.2.tsv\",\n",
    "            sep='\\t')[['ID', 'CATEGORY']],\n",
    "            how='left', left_on='SRC_original_idx', right_on='ID'\n",
    "        )\n",
    "        \n",
    "    \n",
    "    # Convert columns with sentences to str type\n",
    "    cols = ['SRC', 'REF', 'SRC_perturbed', 'SRC_perturbed-Trans', 'SRC-Trans']\n",
    "    if not ref_available:\n",
    "        cols.remove('REF')\n",
    "    output_df[cols] = output_df[cols].astype(str)\n",
    "    \n",
    "    if ignore_case:\n",
    "        output_df[cols] = output_df[cols].applymap(lambda x: x.lower())\n",
    "    \n",
    "    # Reorder the columns\n",
    "    if winoMT:\n",
    "        cols = ['SRC', 'REF', 'original_word', 'perturbed_word', 'SRC_perturbed', 'SRC-Trans', 'SRC_perturbed-Trans', 'Bias_sample']\n",
    "    elif no_of_replacements == 1:\n",
    "        cols = ['SRC', 'REF', 'original_word', 'perturbed_word', 'SRC_perturbed', 'SRC-Trans', 'SRC_perturbed-Trans', 'SRC_original_idx']\n",
    "    else:\n",
    "        cols = ['SRC_masked_index', 'SRC', 'REF', 'original_word', 'perturbed_word', 'SRC_perturbed', 'SRC-Trans', 'SRC_perturbed-Trans', 'SRC_original_idx']\n",
    "    if not ref_available:\n",
    "        cols.remove('REF')\n",
    "    if 'mustSHE' in dataset:\n",
    "        cols.append('CATEGORY')\n",
    "    output_df = output_df[cols]\n",
    "    \n",
    "    if use_alignment:\n",
    "        if not winoMT:\n",
    "            original_alignment = load_alignment(original_trans_path_prefix)\n",
    "            output_df['original_trans_alignment'] = [alignment for alignment in original_alignment for _ in range(no_of_replacements)]\n",
    "        output_df['perturbed_trans_alignment'] = load_alignment(path_prefix)\n",
    "    \n",
    "    if analyse_feature:\n",
    "        print(f\"Original df shape: {output_df.shape}\")\n",
    "        output_df = output_df.dropna()\n",
    "        print(f\"After dropping none-perturbed sentences: {output_df.dropna().shape}\")\n",
    "        \n",
    "        tgt_tokenizer = MosesTokenizer(lang=tgt_lang)\n",
    "        src_tokenizer = MosesTokenizer(lang=src_lang)\n",
    "        \n",
    "        print(\"Tokenize everything ...\")\n",
    "        output_df['tokenized_SRC-Trans'] = output_df['SRC-Trans'].apply(\n",
    "            lambda x: tgt_tokenizer.tokenize(x, escape=False, aggressive_dash_splits=False)\n",
    "        )\n",
    "        output_df['tokenized_SRC_perturbed-Trans'] = output_df['SRC_perturbed-Trans'].apply(\n",
    "            lambda x: tgt_tokenizer.tokenize(x, escape=False, aggressive_dash_splits=False)\n",
    "        )\n",
    "        output_df['tokenized_SRC'] = output_df['SRC'].apply(\n",
    "            lambda x: src_tokenizer.tokenize(x, escape=False, aggressive_dash_splits=False)\n",
    "        )\n",
    "        if 'REF' in output_df.columns:\n",
    "            output_df['tokenized_REF'] = output_df['REF'].apply(\n",
    "                lambda x: tgt_tokenizer.tokenize(x, escape=False, aggressive_dash_splits=False)\n",
    "            )\n",
    "        \n",
    "        print('Calculating the changes between translations of original SRC and perturbed SRC ...')\n",
    "        # Calculate the changes, i.e., how to get from the original trans sentence \n",
    "        # to the changed trans sentence\n",
    "        output_df['opcodes'], output_df['changes'] \\\n",
    "            = zip(*output_df.apply(\n",
    "                lambda x: calculate_change(x['tokenized_SRC-Trans'], \n",
    "                                           x['tokenized_SRC_perturbed-Trans']\n",
    "                                          ),\n",
    "                axis=1)\n",
    "              )\n",
    "        \n",
    "        \n",
    "        print('Highlighting the changes ...')\n",
    "        # Highlight the changes in the trans sentences\n",
    "        output_df[\"SRC-Trans\"], output_df['SRC_perturbed-Trans'] \\\n",
    "            = zip(*output_df.apply(\n",
    "                lambda x: highlight_changes(\n",
    "                    x['tokenized_SRC-Trans'], \n",
    "                    x['tokenized_SRC_perturbed-Trans'], \n",
    "                    x['opcodes']), axis=1\n",
    "            ))\n",
    "        \n",
    "        \n",
    "        print('Calculating the edit distance ...')\n",
    "        if replacement_strategy == 'word2vec_similarity':\n",
    "            # SRC difference is the number of occurances of the word we perturb\n",
    "            output_df[\"SRC-edit_distance\"] = output_df.apply(lambda x: x['tokenized_SRC-Trans'].count(x['original_word']), axis=1)\n",
    "        else:\n",
    "            output_df[\"SRC-edit_distance\"] = 1\n",
    "        output_df['Trans-edit_distance'] =  output_df.apply(\n",
    "            lambda x: levenshtein(x['tokenized_SRC-Trans'], x['tokenized_SRC_perturbed-Trans']), axis=1)\n",
    "        \n",
    "#         output_df[\"#TransChanges-#SrcChanges\"] = output_df['Trans-edit_distance'] - output_df['SRC-edit_distance']\n",
    "        \n",
    "        output_df[\"#TransChanges/SentenceLength\"] = \\\n",
    "            output_df['Trans-edit_distance'] / output_df['tokenized_SRC-Trans'].apply(lambda x: len(x))\n",
    "        \n",
    "        output_df[\"ChangesSpread\"] = output_df.apply(\n",
    "            lambda x: changes_spread(x['tokenized_SRC-Trans'], \n",
    "                                     x['tokenized_SRC_perturbed-Trans'], \n",
    "                                     x['opcodes']), axis=1)\n",
    "        \n",
    "        output_df[\"ChangesSpread/SentenceLength\"] = \\\n",
    "            output_df[\"ChangesSpread\"] / output_df['tokenized_SRC-Trans'].apply(lambda x: len(x))\n",
    "        \n",
    "        \n",
    "        \n",
    "        if two_chunks_analysis:\n",
    "            print(\"Two-chunks changed analysis\")\n",
    "            # See if only two chunks within given max size are changed, \n",
    "            # and do some analysis on this special case\n",
    "            output_df['TwoChunksChanged'], output_df['ChunkDistance'], \\\n",
    "            output_df[\"is_same_subtree\"], output_df['changes_similarity'] \\\n",
    "                = zip(*output_df.apply(\n",
    "                    lambda x: two_chunk_changed(x['tokenized_SRC-Trans'],\n",
    "                                                x['tokenized_SRC_perturbed-Trans'],\n",
    "                                                x['opcodes'],\n",
    "                                                chunk_max_length=chunk_max_length,\n",
    "                                                spacy_model=spacy_model,\n",
    "                                                w2v_model=w2v_model), axis=1\n",
    "                ))\n",
    "\n",
    "        \n",
    "        print(\"Find out changes directly caused by perturbation using alignment\")\n",
    "        if use_alignment:\n",
    "            if two_chunks_analysis:\n",
    "                # In the case where two changes occurs and the two similarities is calculated, \n",
    "                # find out which change is due to the perturbation\n",
    "                output_df['changes_similarity'] = output_df.apply(\n",
    "                    lambda x: add_reason_of_change(\n",
    "                        alignment=x['perturbed_trans_alignment'],\n",
    "                        changes=x['changes_similarity'],\n",
    "                        perturbed_src_word=x['perturbed_word']\n",
    "                    ),\n",
    "                    axis=1\n",
    "                )\n",
    "            \n",
    "                if spacy_model is not None:\n",
    "                    # Add POS tagging of the not-perturbed change\n",
    "                    output_df['not_perturbed_TGT_change_type'] = output_df['changes_similarity'].apply(\n",
    "                        lambda x: pos_tag_not_perturbed_change(x, spacy_model))\n",
    "            \n",
    "            \n",
    "        print(\"Stats on some group changes\")\n",
    "        # Analyse on group of changes on the same sentence\n",
    "        if no_of_replacements > 1:\n",
    "            additional_col_1 = output_df.groupby(by='SRC_masked_index', axis=0)[['Trans-edit_distance']].std()\n",
    "            output_df = output_df.join(additional_col_1, rsuffix='--SD')\n",
    "            \n",
    "            if two_chunks_analysis:\n",
    "                additional_col_2 = output_df.groupby(by='SRC_masked_index', axis=0)[['TwoChunksChanged']].sum()\n",
    "                output_df = output_df.join(additional_col_2, rsuffix='--total')\n",
    "        \n",
    "    return output_df\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b86d1e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perturb_type = 'MultiplePerSentence_allWords'\n",
    "src_lang = 'en'\n",
    "tgt_lang = 'de'\n",
    "dataset = f'WMT21_DA_{src_lang}2{tgt_lang}'  # 'MuST-SHE-en2fr' 'IWSLT15-en2vi' 'wmt19-newstest2019-en2de'\n",
    "beam = 5\n",
    "replacement_strategy = 'masking_language_model'\n",
    "no_of_replacements = 30\n",
    "ignore_case = False  # Only Europarls needs ignore case\n",
    "chunk_max_length=1\n",
    "spacy_model = spacy.load(\"de_core_news_sm\")\n",
    "# Loading these models in is time consuming\n",
    "# de_model = load_facebook_model(\"../data/cc.de.300.bin\").wv\n",
    "# vi_model = load_facebook_model(\"../data/cc.vi.300.bin\").wv\n",
    "winoMT = False\n",
    "\n",
    "# # This overwrite the above params\n",
    "# winoMT = True\n",
    "# perturb_type = 'pronoun'\n",
    "# no_of_replacements = 1\n",
    "\n",
    "output = read_output_df(dataset=dataset, src_lang=src_lang, tgt_lang=tgt_lang, perturb_type=perturb_type, \n",
    "                        beam=beam, replacement_strategy=replacement_strategy, ignore_case=ignore_case,\n",
    "                        no_of_replacements=no_of_replacements, chunk_max_length=chunk_max_length,\n",
    "                        spacy_model=spacy_model, w2v_model=None, use_alignment=False, \n",
    "                        winoMT=winoMT, analyse_feature=True, two_chunks_analysis=False)\n",
    "\n",
    "# print('BLEU score: ')\n",
    "# sacrebleu.corpus_bleu(output['SRC-Trans'].tolist(), [output['REF'].tolist()]).score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd93d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.to_pickle(f'tmp_storages/analyse_{dataset}_{perturb_type}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0048b3d1",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "- On `wmt19-newstest2019-en2de, chunk_max_length=2`\n",
    "    - 902: change to 1 SRC word leads to fixed changes of an irrelevant word\n",
    "    - In many cases, the form of the verb (e.g., current or past tense) are changed --> harmful in the sense that it hurt performance score?\n",
    "    - Word not being translated \n",
    "    - Spoken/written style\n",
    "    - Time\n",
    "    \n",
    "    \n",
    "- On `IWSLT15-en2vi, adjective`\n",
    "    - 1003: change of 1 words consistently leads to change in subject\n",
    "    \n",
    "    - 1003, 145, 990 noun: same\n",
    "    - 236 noun: same, funny but not sure if it is wrong\n",
    "    - 308 verb same \n",
    "    \n",
    "--> Quantify the verb form change by stemming/lemmatization\n",
    "    \n",
    "Chúng, họ, gã, cô ấy, cô ta, anh ta, hắn\n",
    "\n",
    "Changes in the word \"you\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3442d9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output[output['#TransChanges-#SrcChanges'] > 10].head(5)\n",
    "# output[output[\"ChangesSpread/SentenceLength\"] > 0.85].head(20)\n",
    "\n",
    "\n",
    "\n",
    "# Two chunks changed that consistently changed over the different replacement of a word\n",
    "\n",
    "\n",
    "# output[(output[\"TwoChunksChanged\"] == True) & (output[\"TwoChunksChanged--total\"] == 5)].sort_values(by='ChunkDistance', axis=0, ascending=False).head(1)\n",
    "# output[(output[\"TwoChunksChanged\"] == True)].sort_values(by='ChunkDistance', axis=0, ascending=False).head(100)\n",
    "\n",
    "# Two words changed that are not in the same subtree\n",
    "# output[(output[\"TwoChunksChanged\"] == True) & (output[\"is_same_subtree\"] == False) & (output[\"TwoChunksChanged--total\"] == 5)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# IWSLT15-en2vi, noun\n",
    "# output.loc[[1003, 145, 990, 236]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976bde7",
   "metadata": {},
   "source": [
    "Sort the samples by the least similarity in changed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93bccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the 2-word-changed cases and similarity can be calculated\n",
    "def get_not_perturbed_change_similarity(changes):\n",
    "    for change in changes:\n",
    "        if change['change_type'] == 'not_perturbed':\n",
    "            return change['semantic_similarity']\n",
    "    return pd.NA\n",
    "\n",
    "analyse_df = output[\n",
    "    (output[\"TwoChunksChanged\"] == True) & output['changes_similarity'].notna() & output['not_perturbed_TGT_change_type'].isin(['NOUN', 'VERB', 'ADJ', 'PRON'])\n",
    "]\n",
    "analyse_df['similarity_not_perturbed'] = analyse_df['changes_similarity'].apply(\n",
    "    lambda x: get_not_perturbed_change_similarity(x)\n",
    ")\n",
    "analyse_df.sort_values(by='similarity_not_perturbed')[['SRC', \n",
    "                                                f'original_word', \n",
    "                                                f'perturbed_word',\n",
    "                                                'SRC-Trans',\n",
    "                                                f'SRC_perturbed-Trans',\n",
    "                                                'ChunkDistance',\n",
    "                                                'changes_similarity',\n",
    "                                                'similarity_not_perturbed',\n",
    "                                                'not_perturbed_TGT_change_type',\n",
    "#                                                 'Bias_sample'\n",
    "                                                      ]].head(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c53bf",
   "metadata": {},
   "source": [
    "### Calculate metrics for detecting the bias samples\n",
    "\n",
    "High precision --> higher chance that the returned samples are bias --> save human time\n",
    "\n",
    "High recall --> more bias samples are retreat --> can detect more type of bias\n",
    "\n",
    "We focus on precision then (save human cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a5dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(' -------------------- Most-changes filter -------------------- ')\n",
    "q = 20  # Take the q% sentences with the highest changes\n",
    "no_changes_thresthold = np.percentile(output['#TransChanges-#SrcChanges'], 100-q)\n",
    "bias_prediction = output['#TransChanges-#SrcChanges'] > no_changes_thresthold\n",
    "results = classification_report(\n",
    "    y_true=output['Bias_sample'], y_pred=bias_prediction, \n",
    ")\n",
    "print(results)\n",
    "\n",
    "print(' -------------------- Most-spreaded_changes filter -------------------- ')\n",
    "q = 20  # Take the q% sentences with the highest spread\n",
    "spread_thresthold = np.percentile(output['ChangesSpread/SentenceLength'], 100-q)\n",
    "bias_prediction = output['ChangesSpread/SentenceLength'] > spread_thresthold\n",
    "results = classification_report(\n",
    "    y_true=output['Bias_sample'], y_pred=bias_prediction, \n",
    ")\n",
    "print(results)\n",
    "\n",
    "print(' -------------------- Two-changes filter -------------------- ')\n",
    "bias_prediction = output[\"TwoChunksChanged\"]\n",
    "results = classification_report(\n",
    "    y_true=output['Bias_sample'], y_pred=bias_prediction, \n",
    ")\n",
    "print(results)\n",
    "\n",
    "\n",
    "print(' -------------------- Two-faraway-changes filter -------------------- ')\n",
    "q = 20  # Take the q% sentences with the furthest distance between 2 changes \n",
    "distance_thresthold = np.nanpercentile(output['ChunkDistance'], 100-q)\n",
    "bias_prediction = output[\"TwoChunksChanged\"] & (output['ChunkDistance'] > distance_thresthold)\n",
    "results = classification_report(\n",
    "    y_true=output['Bias_sample'], y_pred=bias_prediction, \n",
    ")\n",
    "print(results)\n",
    "\n",
    "print(' -------------------- Two-changes-different-subtree filter -------------------- ')\n",
    "bias_prediction = output[\"TwoChunksChanged\"] & (output[\"is_same_subtree\"] == False)\n",
    "results = classification_report(\n",
    "    y_true=output['Bias_sample'], y_pred=bias_prediction, \n",
    ")\n",
    "print(results)\n",
    "\n",
    "\n",
    "print(' -------------------- Two-change-dissimilar filter -------------------- ')\n",
    "q = 90  # Take the q% sentences with the lowest similarity of the not-perturbed change\n",
    "output = output.join(analyse_df['similarity_not_perturbed'])\n",
    "similiarity_threshold = np.nanpercentile(output['similarity_not_perturbed'], q)\n",
    "\n",
    "bias_prediction = output[\"TwoChunksChanged\"] & (output['similarity_not_perturbed'] < similiarity_threshold)\n",
    "results = classification_report(\n",
    "    y_true=output['Bias_sample'], y_pred=bias_prediction, \n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ab5c4",
   "metadata": {},
   "source": [
    "# Analyse on same original_word accross sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[[\n",
    "    'SRC_masked_index', 'SRC', 'original_word', 'perturbed_word', 'SRC_perturbed',\n",
    "    'SRC-Trans', 'SRC_perturbed-Trans', '#TransChanges-#SrcChanges',\n",
    "    '#TransChanges-#SrcChanges/SentenceLength',\n",
    "    'ChangesSpread/SentenceLength', 'TwoChunksChanged', 'ChunkDistance',\n",
    "    'is_same_subtree', 'changes_similarity', 'perturbed_trans_alignment',\n",
    "    'not_perturbed_TGT_change_type', 'Trans-edit_distance--SD',\n",
    "    '#TransChanges-#SrcChanges--SD', 'TwoChunksChanged--total'\n",
    "]].groupby('original_word').mean().head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb9c49",
   "metadata": {},
   "source": [
    "### Most changes filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f6d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupped_by_word = output.groupby('original_word').mean()\n",
    "\n",
    "q = 10  # Take the q% groups with the highest changes\n",
    "no_changes_thresthold = np.percentile(groupped_by_word['#TransChanges-#SrcChanges'], 100-q)\n",
    "bias_prediction = groupped_by_word['#TransChanges-#SrcChanges'] > no_changes_thresthold\n",
    "\n",
    "bias_word_predicted = groupped_by_word[bias_prediction].index.values\n",
    "\n",
    "output[\n",
    "    output['original_word'].isin(bias_word_predicted) & \\\n",
    "    (output['#TransChanges-#SrcChanges'] > no_changes_thresthold)\n",
    "].head(2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf0826",
   "metadata": {},
   "source": [
    "### Most-spreaded_changes filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e45372",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupped_by_word = output.groupby('original_word').mean()\n",
    "\n",
    "q = 10  # Take the q% sentences with the highest spread\n",
    "spread_thresthold = np.percentile(groupped_by_word['ChangesSpread/SentenceLength'], 100-q)\n",
    "bias_prediction = groupped_by_word['ChangesSpread/SentenceLength'] > spread_thresthold\n",
    "\n",
    "bias_word_predicted = groupped_by_word[bias_prediction].index.values\n",
    "\n",
    "output[\n",
    "    output['original_word'].isin(bias_word_predicted) & \\\n",
    "    (output['ChangesSpread/SentenceLength'] > spread_thresthold)\n",
    "].head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069aeb58",
   "metadata": {},
   "source": [
    "### Two-faraway-changes filter\n",
    "\n",
    "ACTUALLY two-changes is not a bias filter. It's just an auxilary filter to avoid paraphrasing cases. Using this we will miss out on the cases where the model has both paraphrasing and \n",
    "\n",
    "Here we consider in each group: the number of sentences that has 2 changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_change_only_groupped_by_word = output[output[\"TwoChunksChanged\"]].groupby('original_word').mean()\n",
    "\n",
    "\n",
    "q = 20  # Take the q% sentences with the furthest distance between 2 changes \n",
    "distance_thresthold = np.percentile(two_change_only_groupped_by_word['ChunkDistance'], 100-q)\n",
    "bias_prediction = two_change_only_groupped_by_word['ChunkDistance'] > distance_thresthold\n",
    "\n",
    "\n",
    "bias_word_predicted = two_change_only_groupped_by_word[bias_prediction].index.values\n",
    "\n",
    "output[\n",
    "    output[\"TwoChunksChanged\"] & \\\n",
    "    output['original_word'].isin(bias_word_predicted) & \\\n",
    "    (output['ChunkDistance'] > distance_thresthold)\n",
    "].head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98cd5f9",
   "metadata": {},
   "source": [
    "### Two-changes-different-subtree filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876de271",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = output[output[\"TwoChunksChanged\"] & output['is_same_subtree'].notna()]\n",
    "tmp['not_same_subtree'] = 1 - tmp['is_same_subtree'].astype(int)\n",
    "two_change_only_groupped_by_word = tmp.groupby('original_word').sum()\n",
    "\n",
    "q = 20  # Take the q% groups with the highest number of different subtree changes\n",
    "count_thresthold = np.percentile(two_change_only_groupped_by_word['not_same_subtree'], 100-q)\n",
    "bias_prediction = two_change_only_groupped_by_word['ChunkDistance'] > count_thresthold\n",
    "\n",
    "\n",
    "bias_word_predicted = two_change_only_groupped_by_word[bias_prediction].index.values\n",
    "\n",
    "output[\n",
    "    output[\"TwoChunksChanged\"] & \\\n",
    "    output['original_word'].isin(bias_word_predicted) & \\\n",
    "    (output['is_same_subtree'] == 0)\n",
    "].head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a02578",
   "metadata": {},
   "source": [
    "### Two-change-dissimilar filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ee3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.join(analyse_df['similarity_not_perturbed'])\n",
    "two_change_only_groupped_by_word = output[output[\"TwoChunksChanged\"]].groupby('original_word').mean()\n",
    "\n",
    "\n",
    "q = 20  # Take the q% sentences with the lowest similarity of the not-perturbed change\n",
    "similiarity_threshold = np.nanpercentile(two_change_only_groupped_by_word['similarity_not_perturbed'], q)\n",
    "bias_prediction = two_change_only_groupped_by_word['similarity_not_perturbed'] < similiarity_threshold\n",
    "\n",
    "\n",
    "bias_word_predicted = two_change_only_groupped_by_word[bias_prediction].index.values\n",
    "\n",
    "output[\n",
    "    output[\"TwoChunksChanged\"] & \\\n",
    "    output['original_word'].isin(bias_word_predicted) & \\\n",
    "    (output['similarity_not_perturbed'] < similiarity_threshold)\n",
    "].head(2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d52f9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11449a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6de148",
   "metadata": {},
   "source": [
    "## Find patterns\n",
    "\n",
    "when a word A is replaced with B, then the change C happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4534859",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[['SRC_masked_index', 'SRC', 'original_word', 'perturbed_word', 'SRC_perturbed',\n",
    "       'SRC-Trans', 'SRC_perturbed-Trans', 'changes']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260159f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def lower_remove_non_alphabet(input_str):\n",
    "    translation = input_str.maketrans(dict.fromkeys(string.punctuation, ' '))\n",
    "    return input_str.translate(translation).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ad595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_due_to_perturbation(change, original_word, perturbed_word, \n",
    "                           perturbed_trans_alignment_dict, original_trans_alignment_dict):\n",
    "    \"\"\"\n",
    "    A change in translation is directly due to perturbation if the (aligned) translation of perturbed_word\n",
    "    is in changed_part AND the (aligned) translation of original_word is in original_part\n",
    "    \n",
    "    Params:\n",
    "        change: tuple of (change_type, original_trans_part, changed_trans_part)\n",
    "        original_word: original word in the SRC that was perturbed\n",
    "        perturbed_word: the replacement of the original word\n",
    "        perturbed_trans_alignment_dict: {src_word1:trans_word1, src_word2:trans_word2,...} of the perturbed trans\n",
    "        original_trans_alignment_dict: {src_word1:trans_word1, src_word2:trans_word2,...} of the original trans\n",
    "    Return: bool, pd.NA in failed alignment case\n",
    "    \"\"\"\n",
    "    # Turn everything to lowercase, and remove any non-alphabet characters\n",
    "    change_type, original_trans_part, changed_trans_part = \\\n",
    "        change[0], lower_remove_non_alphabet(change[1]), lower_remove_non_alphabet(change[2])\n",
    "    perturbed_trans_alignment_dict = dict(\n",
    "        (lower_remove_non_alphabet(k).replace(' ', ''), lower_remove_non_alphabet(v).replace(' ', '')) for k,v in perturbed_trans_alignment_dict.items()\n",
    "    )\n",
    "    original_trans_alignment_dict = dict(\n",
    "        (lower_remove_non_alphabet(k).replace(' ', ''), lower_remove_non_alphabet(v).replace(' ', '')) for k,v in original_trans_alignment_dict.items()\n",
    "    )\n",
    "    original_word = lower_remove_non_alphabet(original_word)\n",
    "    perturbed_word = lower_remove_non_alphabet(perturbed_word)\n",
    "    \n",
    "\n",
    "    perturbed_word_appears_in_new_trans = pd.NA\n",
    "    if perturbed_word in perturbed_trans_alignment_dict.keys():\n",
    "        perturbed_word_trans = perturbed_trans_alignment_dict[perturbed_word]\n",
    "        if perturbed_word_trans in changed_trans_part.split():\n",
    "            perturbed_word_appears_in_new_trans = True\n",
    "        else:\n",
    "            perturbed_word_appears_in_new_trans = False\n",
    "            \n",
    "    # Missed-translation, or name-specific case\n",
    "    if perturbed_word in changed_trans_part.split():\n",
    "        perturbed_word_appears_in_new_trans = True\n",
    "            \n",
    "\n",
    "    original_word_appears_in_old_trans = pd.NA\n",
    "    if original_word in original_trans_alignment_dict.keys():\n",
    "        original_word_trans = original_trans_alignment_dict[original_word]\n",
    "        if original_word_trans in original_trans_part.split():\n",
    "            original_word_appears_in_old_trans = True\n",
    "        else:\n",
    "            original_word_appears_in_old_trans = False\n",
    "        \n",
    "        if perturbed_word in perturbed_trans_alignment_dict.keys():\n",
    "            if original_word == 'fort' and perturbed_word == 'île' and change == ('replace', 'Fort-de-France', 'Île-de-France'):\n",
    "                print('-------------------------')\n",
    "                print(change)\n",
    "                print('-' + original_word_trans + '-')\n",
    "                print('-' + perturbed_word_trans + '-')\n",
    "                print(original_word_appears_in_old_trans)\n",
    "                print(perturbed_word_appears_in_new_trans)\n",
    "                \n",
    "    # Missed-translation, or name-specific case\n",
    "    if original_word in original_trans_part.split():\n",
    "        original_word_appears_in_old_trans = True\n",
    "            \n",
    "    # If perturbed_word_appears_in_new_trans or original_word_appears_in_old_trans is true, then \n",
    "    # is_due_to_perturbation is true\n",
    "    if (not pd.isnull(perturbed_word_appears_in_new_trans)) and \\\n",
    "        (not pd.isnull(original_word_appears_in_old_trans)):\n",
    "        return (perturbed_word_appears_in_new_trans or original_word_appears_in_old_trans)\n",
    "    elif (pd.isnull(perturbed_word_appears_in_new_trans)) and \\\n",
    "        (not pd.isnull(original_word_appears_in_old_trans)):\n",
    "        if original_word_appears_in_old_trans:\n",
    "            return True\n",
    "        else:\n",
    "            return pd.NA\n",
    "    elif (not pd.isnull(perturbed_word_appears_in_new_trans)) and \\\n",
    "        (pd.isnull(original_word_appears_in_old_trans)):\n",
    "        if perturbed_word_appears_in_new_trans:\n",
    "            return True\n",
    "        else:\n",
    "            return pd.NA\n",
    "    else:\n",
    "        return pd.NA\n",
    "    \n",
    "    \n",
    "def filter_changes(group_df):\n",
    "    changes = []\n",
    "    \n",
    "    for index, row in group_df.iterrows():\n",
    "        for change in row['changes']:\n",
    "            # Filter out the changes caused by perturbation\n",
    "            is_due_to_perturbation_out = is_due_to_perturbation(\n",
    "                                            change, \n",
    "                                            row['original_word'], \n",
    "                                            row['perturbed_word'], \n",
    "                                            row['perturbed_trans_alignment'],\n",
    "                                            row['original_trans_alignment']\n",
    "                                        )\n",
    "            if pd.isnull(is_due_to_perturbation_out) or is_due_to_perturbation_out:\n",
    "                continue\n",
    "                \n",
    "            # Filter out the weird <unk>\n",
    "            if change == ('delete', '< unk >', '') or change == ('insert', '', '< unk >'):\n",
    "                continue\n",
    "                \n",
    "            # Filter out the changes that are not content-related\n",
    "            all_pos_tags = [t.pos_ for t in spacy_model(change[1])] + [t.pos_ for t in spacy_model(change[2])]\n",
    "            content_related_tags = 'NOUN', 'VERB', 'ADJ', 'PRON'\n",
    "            overlap = not set(all_pos_tags).isdisjoint(content_related_tags)\n",
    "            if not overlap:\n",
    "                continue\n",
    "                \n",
    "            changes.append(change)\n",
    "            \n",
    "            \n",
    "    return changes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def find_max_freq_change(group_df):\n",
    "    \"\"\"\n",
    "    Params: \n",
    "        group_df: the group of results that has the same original_word and perturbed_word\n",
    "    \"\"\"\n",
    "    assert group_df['original_word'].value_counts().shape[0] == 1  # Because this function is for a single group\n",
    "    assert group_df['perturbed_word'].value_counts().shape[0] == 1  # Because this function is for a single group\n",
    "    \n",
    "    # Filter out the changes that are not directly due to perturbation\n",
    "    all_changes = filter_changes(group_df)\n",
    "    \n",
    "    freq_changes = Counter(all_changes)\n",
    "    \n",
    "    if len(freq_changes.most_common()) == 0:\n",
    "        return 0\n",
    "    return freq_changes.most_common(1)[0][1]\n",
    "\n",
    "change_freq = output.groupby(\n",
    "    ['original_word', 'perturbed_word'], as_index=False\n",
    ").apply(find_max_freq_change).rename(columns={None: 'max_change_freq'}).sort_values(\n",
    "    by='max_change_freq', ascending=False)\n",
    "    \n",
    "\n",
    "change_freq = change_freq[change_freq['perturbed_word'].apply(lambda x: x.isalpha())]\n",
    "\n",
    "change_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cca6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = output.groupby(['original_word', 'perturbed_word'])\n",
    "groups_as_list = [(original_perturb, group) for original_perturb, group in groups]\n",
    "re_ordered_groupes = [groups_as_list[i] for i in change_freq.index.values]\n",
    "\n",
    "for original_perturb, group in re_ordered_groupes:\n",
    "    print(\"----------------------\")\n",
    "    print(f\"original SRC word: {original_perturb[0]}\")\n",
    "    print(f\"perturbed SRC word: {original_perturb[1]}\")\n",
    "    all_changes = filter_changes(group)\n",
    "    freq_changes = Counter(all_changes)\n",
    "    print(freq_changes.most_common(2))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c1316b0",
   "metadata": {},
   "source": [
    "original SRC word: excuse\n",
    "perturbed SRC word: Trust\n",
    "[(('insert', '', 'mir'), 11), (('insert', '', 'uns'), 4)]\n",
    "\n",
    "original SRC word: communist\n",
    "perturbed SRC word: Nationalist\n",
    "[(('delete', Chinas, ''), 11),\n",
    "\n",
    "\n",
    "\n",
    "original SRC word: usa\n",
    "perturbed SRC word: is\n",
    "[(('insert', '', 'kalifornischen'), 10),\n",
    "\n",
    "\n",
    "original SRC word: please\n",
    "perturbed SRC word: you\n",
    "[(('delete', 'Sie', ''), 7), \n",
    "\n",
    "\n",
    "original SRC word: restaurant\n",
    "perturbed SRC word: bar\n",
    "[(('replace', 'es', 'sie'), 5), (('replace', 'einem', 'einer'), 2)]\n",
    "\n",
    "original SRC word: hurry\n",
    "perturbed SRC word: shut\n",
    "[(('replace', 'sich', 'den Mund'), 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1363d5bb",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "--> starts to make sense, yet have not seen bias (even gender bias)\n",
    "\n",
    "--> A bigger dataset for inference could help?\n",
    "\n",
    "Some correlation is good, some correlation is bad. Is it a good idea to prevent these correlation??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42568741",
   "metadata": {},
   "source": [
    "# Filter per sentence with different replacements\n",
    "\n",
    "\n",
    "**Note**: can use [sequence alignments](https://stackoverflow.com/questions/5055839/word-level-edit-distance-of-a-sentence) to align the sentences on the target side only. ([code](https://gist.github.com/slowkow/06c6dba9180d013dfd82bec217d22eb5))\n",
    "\n",
    "Pros: could be easier than SRC-TGT alignment\n",
    "\n",
    "Cons: in the case where more output different sentence structure yet same meaning. <br>\n",
    "E.g., \"Today I think the cat is nice\" -- \"I think the cat is nice today\"\n",
    "SRC-TGT alignment would probably see these as the same, but edit distance cannot, bc it only has del, insert, substitute operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f50bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cast_to_index(string_index):\n",
    "    \"\"\"\n",
    "    In a aligned tuple, the items could either be the index of a word, or the character '-' denoting \n",
    "    \"\"\"\n",
    "    # removes blank spaces\n",
    "    string_index = string_index.strip()\n",
    "    \n",
    "    if string_index == '-':\n",
    "        return pd.NA\n",
    "    else:\n",
    "        return int(string_index)\n",
    "\n",
    "def edist_alignment(tokenized_sentence1, tokenized_sentence2):\n",
    "    \"\"\"\n",
    "    Return the list of tuples of aligned indices\n",
    "    \"\"\"\n",
    "    \n",
    "    alignment = sed.standard_sed_backtrace(tokenized_sentence1, tokenized_sentence2)\n",
    "    # Reformat the output from editst\n",
    "    alignment = str(alignment).replace('[', '').replace(']', '').split(', ')\n",
    "    alignment = [x.split('vs.') for x in alignment]\n",
    "    alignment = [(cast_to_index(x[0]), cast_to_index(x[1])) for x in alignment]\n",
    "    \n",
    "    return alignment\n",
    "\n",
    "def reorder_according_to_alignment(tokenized_sentence1, tokenized_sentence2, alignment):\n",
    "    \"\"\"\n",
    "    Given the alignment tuples, reorder the second sentence to align to the first sentence\n",
    "    \"\"\"\n",
    "    reordered_tokenized_sentence2 = [pd.NA] * len(tokenized_sentence1)\n",
    "    for alignment_tuple in alignment:\n",
    "        sentence1_idx, sentence2_idx = alignment_tuple\n",
    "        if (not pd.isnull(sentence1_idx)) and (not pd.isnull(sentence2_idx)):\n",
    "            reordered_tokenized_sentence2[sentence1_idx] = tokenized_sentence2[sentence2_idx]\n",
    "    return reordered_tokenized_sentence2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_pos_tag(word):\n",
    "    return nltk.pos_tag([word])[0][1]\n",
    "\n",
    "def is_content_tag(nltk_pos):\n",
    "    content_tags_prefix = ['NN', 'V', 'JJ', 'PRP']  # Noun, verb, adj, adv (RB, but removed), pronoun\n",
    "    for prefix in content_tags_prefix:\n",
    "        if nltk_pos.startswith(prefix):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def uniquify(df_columns):\n",
    "    \"\"\"\n",
    "    Add suffix to distinguish duplicated colunms' names\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "\n",
    "    for item in df_columns:\n",
    "        fudge = 1\n",
    "        newitem = item\n",
    "\n",
    "        while newitem in seen:\n",
    "            fudge += 1\n",
    "            newitem = \"{}_{}\".format(item, fudge)\n",
    "\n",
    "        yield newitem\n",
    "        seen.add(newitem)\n",
    "        \n",
    "        \n",
    "def align_src_tgt_translations(sentence_df):\n",
    "    # Convert everything to lowercase\n",
    "    sentence_df = sentence_df.copy()\n",
    "    sentence_df['SRC'] = sentence_df['SRC'].apply(lambda x: x.lower())\n",
    "    sentence_df['original_trans_alignment'] = sentence_df['original_trans_alignment'].apply(\n",
    "        lambda x: dict(\n",
    "            (k.lower(), v.lower()) for k,v in x.items()\n",
    "        )\n",
    "    )\n",
    "    sentence_df['perturbed_trans_alignment'] = sentence_df['perturbed_trans_alignment'].apply(\n",
    "        lambda x: dict(\n",
    "            (k.lower(), v.lower()) for k,v in x.items()\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    original_word = sentence_df['original_word'].values[0]\n",
    "    original_src = sentence_df['SRC'].values[0]\n",
    "    original_trans_alignment = sentence_df['original_trans_alignment'].values[0]\n",
    "    \n",
    "    original_src_tokenized = sentence_df['tokenized_SRC'].values[0]\n",
    "    original_word_index = original_src_tokenized.index(original_word)\n",
    "    original_src_tokenized[original_word_index] = '[MASK]'\n",
    "\n",
    "    result_df = pd.DataFrame(\n",
    "        index=[original_word]+sentence_df['perturbed_word'].tolist(), \n",
    "        columns=original_src_tokenized\n",
    "    )\n",
    "    \n",
    "    # Add the original translation \n",
    "    result_df.loc[original_word] = original_trans_alignment\n",
    "    result_df.loc[original_word, '[MASK]'] = \\\n",
    "        original_trans_alignment[original_word] if original_word in original_trans_alignment.keys() else pd.NA\n",
    "    \n",
    "    # Add the perturbed translation\n",
    "    for index, row in sentence_df.iterrows():\n",
    "        perturbed_word = row['perturbed_word']\n",
    "        perturbed_trans_alignment = row['perturbed_trans_alignment']\n",
    "        result_df.loc[perturbed_word] = perturbed_trans_alignment\n",
    "        result_df.loc[perturbed_word, '[MASK]'] = \\\n",
    "            perturbed_trans_alignment[perturbed_word] if perturbed_word in perturbed_trans_alignment.keys() else pd.NA\n",
    "    \n",
    "    # Fix columns with same name (due to word occurs twice in a sentence)\n",
    "    result_df.columns = uniquify(result_df.columns)\n",
    "    \n",
    "    return result_df\n",
    "    \n",
    "    \n",
    "def align_translations_tgt_only(sentence_df):\n",
    "    \"\"\"\n",
    "    Align all perturbed translations with the original translation\n",
    "    \"\"\"\n",
    "    original_word = sentence_df['original_word'].values[0]\n",
    "    original_trans_tokenized = sentence_df['tokenized_SRC-Trans'].values[0]\n",
    "    \n",
    "    result_df = pd.DataFrame(\n",
    "        index=[original_word]+sentence_df['perturbed_word'].tolist(), columns=original_trans_tokenized\n",
    "    )\n",
    "    \n",
    "    # Add the original translation \n",
    "    result_df.loc[original_word] = original_trans_tokenized\n",
    "    \n",
    "    # Add the perturbed translation\n",
    "    for index, row in sentence_df.iterrows():\n",
    "        perturbed_word = row['perturbed_word']\n",
    "        alignment = edist_alignment(original_trans_tokenized, row['tokenized_SRC_perturbed-Trans'])\n",
    "        result_df.loc[perturbed_word] = reorder_according_to_alignment(\n",
    "            original_trans_tokenized, row['tokenized_SRC_perturbed-Trans'], alignment\n",
    "        )\n",
    "    \n",
    "    # Fix columns with same name (due to word occurs twice in a sentence)\n",
    "    result_df.columns = uniquify(result_df.columns)\n",
    "    \n",
    "    return result_df\n",
    "        \n",
    "        \n",
    "def align_translations(sentence_df, align_type=\"src-trans\"):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        sentence_df: df containing the different unmasking results of a masked sentence, along with the translations\n",
    "        align_type: \"src-trans\" align the translations with the source sentence, using awesome-align\n",
    "                    \"trans-only\" align the translations with eachother, using edit distance\n",
    "    Returns:\n",
    "        result_df: the aligned translations of different perturbed src\n",
    "    \"\"\"\n",
    "    \n",
    "    count_original_word = sentence_df['original_word'].value_counts()\n",
    "    assert count_original_word.shape[0] == 1  # Because this function is for a single group\n",
    "\n",
    "    if align_type == \"src-trans\":\n",
    "        return align_src_tgt_translations(sentence_df)\n",
    "    elif align_type == \"trans-only\":\n",
    "        return align_translations_tgt_only(sentence_df)\n",
    "    else:\n",
    "        raise RuntimeError('Invalid alignment type')\n",
    "    \n",
    "    \n",
    "def analyse_single_sentence_perturbed_word(sentence_perturbed_word_df, align_type=\"trans-only\", filter_content_word=True, return_tgt_word_index=False):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        sentence_perturbed_word_df: df containing the different unmasking results of a masked sentence, along with the translations\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    nr_replacements = sentence_perturbed_word_df.shape[0]\n",
    "    \n",
    "    \n",
    "    aligned_trans = align_translations(sentence_perturbed_word_df, align_type=\"trans-only\")\n",
    "    \n",
    "    result = {'perturbed_or_noise_words': [], \n",
    "              'words_with_clustered_trans': {}, \n",
    "              'words_with_single_trans': {}\n",
    "             }\n",
    "    \n",
    "    for col_idx, col in enumerate(aligned_trans.columns):\n",
    "        word = col.split('_')[0]\n",
    "        \n",
    "        if filter_content_word and align_type == \"trans-only\":\n",
    "#             print('NLTK pos tag only available for English, skip filtering content words.')\n",
    "            filter_content_word = False\n",
    "            \n",
    "        if (not filter_content_word) or is_content_tag(nltk_pos_tag(word)):\n",
    "            count_unique_translated_words = aligned_trans[col].value_counts()\n",
    "            nr_unique_words = count_unique_translated_words.shape[0]\n",
    "            \n",
    "            if nr_unique_words >= 5:\n",
    "                # If number of unique translations are large,\n",
    "                # then this is the column of the perturbed word or noise\n",
    "                if return_tgt_word_index:\n",
    "                    result['perturbed_or_noise_words'].append(col_idx)\n",
    "                else:\n",
    "                    result['perturbed_or_noise_words'].append(col)\n",
    "            elif 2 <= nr_unique_words and nr_unique_words < 5:\n",
    "                # TODO: TEMPORARYLY LEAVING OUT SIMILARITY CALCULATION\n",
    "#                 # Report the word and the minimum similarity between pair-wise unique translations\n",
    "#                 unique_words = count_unique_translated_words.index.tolist()\n",
    "#                 all_similarities = []\n",
    "#                 for i in range(0, len(unique_words)):\n",
    "#                     for j in range(i, len(unique_words)):\n",
    "#                         all_similarities.append(de_model.similarity(unique_words[i], unique_words[j]))\n",
    "                if return_tgt_word_index:\n",
    "                    result['words_with_clustered_trans'][col_idx] = count_unique_translated_words.to_dict()\n",
    "                else:\n",
    "                    result['words_with_clustered_trans'][col] = count_unique_translated_words.to_dict()\n",
    "            elif nr_unique_words == 1:\n",
    "                if return_tgt_word_index:\n",
    "                    result['words_with_single_trans'][col_idx] = count_unique_translated_words.index[0]\n",
    "                else:\n",
    "                    result['words_with_single_trans'][col] = count_unique_translated_words.index[0]\n",
    "            \n",
    "            \n",
    "    return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027559c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea226b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_single_sentence(sentence_df, \n",
    "                            align_type=\"trans-only\", \n",
    "                            filter_content_word=True, \n",
    "                            return_tgt_word_index=False):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        sentence_df: df contaning the different translations of different perturbed version of a sentence\n",
    "        align_type: whether to align the perturbed translations to the original translation, or to the source sentence\n",
    "        filter_content_word: whether to filter out the non-content words\n",
    "        return_tgt_word_index: whether to return the word index rather than the actual word itself\n",
    "    \"\"\"\n",
    "    count_original_sentence_idx = sentence_df['SRC_original_idx'].value_counts()\n",
    "    assert count_original_sentence_idx.shape[0] == 1  # Because this function is for a single group\n",
    "    \n",
    "    groups_by_perturbed_word = sentence_df.groupby(\"original_word\", as_index=False)\n",
    "    \n",
    "\n",
    "    collect_results = {}\n",
    "    for original_word, group_by_perturbed_word in groups_by_perturbed_word:\n",
    "        collect_results[original_word] = analyse_single_sentence_perturbed_word(group_by_perturbed_word, \n",
    "                                                                                align_type=\"trans-only\",\n",
    "                                                                                filter_content_word=filter_content_word,\n",
    "                                                                                return_tgt_word_index=return_tgt_word_index)\n",
    "        \n",
    "    \n",
    "    # For ambiguous words, find the perturbed words that makes its trans ambiguous,\n",
    "    # and the perturbed words that makes its trans consistence\n",
    "    ambiguous_words = set(\n",
    "        sum([list(x['words_with_clustered_trans'].keys()) for x in collect_results.values()],\n",
    "            [])\n",
    "    )\n",
    "    \n",
    "    result = {}\n",
    "    for ambiguous_word in ambiguous_words:\n",
    "        no_effect_words = []\n",
    "        effect_words = []\n",
    "        \n",
    "        for original_word, collected_result in collect_results.items():\n",
    "            if ambiguous_word in collected_result['words_with_clustered_trans']:\n",
    "                effect_words.append(original_word)\n",
    "            elif ambiguous_word in collected_result['words_with_single_trans']:\n",
    "                no_effect_words.append(original_word)\n",
    "    \n",
    "        \n",
    "        result[ambiguous_word] = {'no_effecting_words': no_effect_words,\n",
    "                                  'effecting_words': effect_words}\n",
    "    \n",
    "    \n",
    "    return result\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ee30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecafdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis = output.groupby('SRC_masked_index').apply(lambda x: analyse_single_sentence_perturbed_word(x))  #.rename(columns={None: 'influenced_words'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.to_pickle('tmp_storages/analyse_winoMT.pkl')\n",
    "# output = pd.read_pickle('tmp_storages/analyse_winoMT.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fd55ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some missing info samples from mustSHE\n",
    "# output[output['CATEGORY']=='1F'][['SRC', 'SRC_original_idx']].drop_duplicates() #.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8da3da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 9999999)\n",
    "\n",
    "sentence_idx = 0\n",
    "print(f\"Original SRC sentence: \\n {output[['SRC', 'SRC_original_idx']].drop_duplicates().set_index('SRC_original_idx').loc[sentence_idx]}\")\n",
    "print()\n",
    "\n",
    "pprint.pprint(analyse_single_sentence(output[output['SRC_original_idx'] == sentence_idx], align_type=\"trans-only\", return_tgt_word_index=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce851487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_word = 'general'\n",
    "\n",
    "\n",
    "sentence_df = output[output['SRC_original_idx'] == sentence_idx]\n",
    "sentence_single_perturbed_word_df = sentence_df[sentence_df['original_word'] == original_word]\n",
    "\n",
    "\n",
    "pprint.pprint(analyse_single_sentence_perturbed_word(sentence_single_perturbed_word_df, align_type=\"trans-only\"))\n",
    "align_translations(sentence_single_perturbed_word_df, align_type=\"trans-only\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dda942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b591961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56a767f2",
   "metadata": {},
   "source": [
    "# Quality analysis\n",
    "\n",
    "- Have to use WMT21 data, bc models for 2021 is available. Also they have clear evaluation script\n",
    "- Have to do some manual fix so that the translation tokenization match completely with the tokenization of the labeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5d1aad",
   "metadata": {},
   "source": [
    "### Word-level\n",
    "\n",
    "A translated word is uncertain if changing other words in the SRC sentence affect its translations. The assumption is the the translation of one word should only depends on a few others word, but not too many.\n",
    "\n",
    "E.g., My mother, who had a difficult childhood, is a great doctor.\n",
    "\n",
    "The gender form of \"doctor\" should only change if we change the word \"mother\".\n",
    "\n",
    "Hyperparam: The number of SRC words that effect the translations of the target word\n",
    "\n",
    "Currently: If a translated word has 3 or more effecting SRC word, mark as \"BAD\"\n",
    "\n",
    "Metrics: Matthews correlation coefficient \n",
    "\"It takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes. The MCC is in essence a correlation coefficient value between -1 and +1. A coefficient of +1 represents a perfect prediction, 0 an average random prediction and -1 an inverse prediction.\"\n",
    "\n",
    "Current score: 0.267\n",
    "\n",
    "\n",
    "Score of WMT21 shared task: baseline 0.370, best 0.510\n",
    "\n",
    "WMT21 baseline: multilingual transformer-based Predictor-Estimator approach for both sentence level and word level\n",
    "\n",
    "\n",
    "**How to do hyperparameter tuning if our goal is not to use the training data? Or just using the dev set is oke?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab99f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_tokenization(tokenized_sentence):\n",
    "    # Some of the sentences is tokenized differently in the labeled data. I.e., the last dot is not tokenized\n",
    "    # Fix in order to syncronize with the labeled data\n",
    "    if tokenized_sentence[-1] != '.':\n",
    "        str_sentence = ' '.join(tokenized_sentence)\n",
    "        str_sentence = str_sentence[:-1] + ' .'\n",
    "        return str_sentence.split()\n",
    "    else:\n",
    "        return tokenized_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d94b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_analysed_file = \"tmp_storages/analyse_WMT21_DA_en2de_MultiplePerSentence_allWords.pkl\"\n",
    "output = pd.read_pickle(trans_analysed_file)\n",
    "\n",
    "# Fix tokenization\n",
    "errornous_idxs = [80,86,109,122,143,285,306,314,427,430,528,560,760,884,908,924,940]\n",
    "\n",
    "output['tokenized_SRC-Trans'] = output.apply(\n",
    "    lambda x: fix_tokenization(\n",
    "        x['tokenized_SRC-Trans']\n",
    "    ) if x['SRC_original_idx'] in errornous_idxs else x['tokenized_SRC-Trans'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "output['tokenized_SRC_perturbed-Trans'] = output.apply(\n",
    "    lambda x: fix_tokenization(\n",
    "        x['tokenized_SRC_perturbed-Trans']\n",
    "    ) if x['SRC_original_idx'] in errornous_idxs else x['tokenized_SRC_perturbed-Trans'],\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0def06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the gold labels (OK/BAD word-level tags)\n",
    "\n",
    "# with open(\"../data/wmt-qe-2022-data/test_data-gold_labels/task1_word-level/en-de/test.2022.en-de.tags\", 'r') as f:\n",
    "#     gold_labels = f.readlines()\n",
    "#     gold_labels = [line.replace('\\n', '').split() for line in gold_labels]\n",
    "    \n",
    "gold_labels = pd.read_csv(\n",
    "    '../data/wmt-qe-2021-data/en-de-test21/goldlabels/task2_wordlevel_mt.tags',\n",
    "    header=None, sep='\\t', quoting=3\n",
    ")\n",
    "gold_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f53ac6",
   "metadata": {},
   "source": [
    "If a translated word has 3 or more effecting SRC word, mark as \"BAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d749036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_word(tgt_src_effects):\n",
    "    bad_tgt_words = []\n",
    "    for tgt_word, src_effects in tgt_src_effects.items():\n",
    "        if len(src_effects['effecting_words']) > 2:\n",
    "            bad_tgt_words.append(tgt_word)\n",
    "    return bad_tgt_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c42fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag = []\n",
    "SRC_original_indices = output['SRC_original_idx'].unique()\n",
    "\n",
    "for SRC_original_idx in SRC_original_indices:\n",
    "    sentence_df = output[output['SRC_original_idx'] == SRC_original_idx]\n",
    "    original_trans_length = len(sentence_df['tokenized_SRC-Trans'].values[0])\n",
    "    tgt_src_effects = analyse_single_sentence(sentence_df, \n",
    "                                              align_type=\"trans-only\", return_tgt_word_index=True)\n",
    "    bad_words = find_bad_word(tgt_src_effects)\n",
    "    sentence_word_tags = ['BAD' if x in bad_words else 'OK' for x in range(0, original_trans_length)]\n",
    "    word_tag.append(sentence_word_tags)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd769e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "flat_gold_labels = gold_labels.iloc[:, -1]\n",
    "flat_pred_labels = [item for sublist in word_tag for item in sublist]\n",
    "\n",
    "matthews_corrcoef(y_true=flat_gold_labels, y_pred=flat_pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e642f401",
   "metadata": {},
   "source": [
    "## Sentence level\n",
    "\n",
    "Approximations:\n",
    "- Negative corr with DA:\n",
    "    - Changes edit distance \n",
    "    - Changes edit distance / length\n",
    "    - Changes spread\n",
    "    - Changes spread / length\n",
    "    - Number of BAD tokens\n",
    "   \n",
    "Metrics: Pearson correlation coefficient: \"Correlations of -1 or +1 imply an exact linear relationship\"\n",
    "\n",
    "DA scores:\n",
    "Scores: highest 0.18\n",
    "WMT21 scores: baseline 0.403, best 0.584\n",
    "\n",
    "\n",
    "HTER scores: \n",
    "Scores: highest 0.28\n",
    "WMT21 scores: baseline 0.529, best 0.653\n",
    "\n",
    "**Can try to apply some function to the prediction, but then that's not unsupervised anymore**\n",
    "\n",
    "**Can use as feature for QE model, but again not unsupervised anymore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e3aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans_analysed_file = \"analyse_WMT22_MQM_en2de.pkl\"\n",
    "# output = pd.read_pickle(trans_analysed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ef9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "\n",
    "approximations = output[\n",
    "    [\"SRC_original_idx\", \n",
    "     \"Trans-edit_distance\", \n",
    "     \"#TransChanges/SentenceLength\",\n",
    "     \"ChangesSpread\",\n",
    "     \"ChangesSpread/SentenceLength\"\n",
    "    ]\n",
    "].groupby(\"SRC_original_idx\").mean()\n",
    "\n",
    "approximations['word_level_agg'] = [x.count('BAD') for x in word_tag]\n",
    "\n",
    "\n",
    "for col in approximations.columns:\n",
    "    # Normalize the apporximations, invert the sign\n",
    "    approximations[col] = -approximations[col]\n",
    "    approximations[col] = zscore(approximations[col].values)\n",
    "    \n",
    "    \n",
    "approximations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29433315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ecd4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ccb08e1",
   "metadata": {},
   "source": [
    "Gold labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019f6cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'WMT21_DA' in trans_analysed_file:\n",
    "    with open(\"../data/wmt-qe-2021-data/en-de-test21/goldlabels/test21.hter\", 'r') as f:\n",
    "        da_scores = f.readlines()\n",
    "        da_scores = [float(da_score.replace('\\n', '')) for da_score in da_scores]\n",
    "    gold_lables = da_scores\n",
    "elif 'WMT22_MQM' in trans_analysed_file:\n",
    "    with open(\"../data/wmt-qe-2022-data/test_data-gold_labels/task1_mqm/en-de/test.2022.en-de.mqm_z_score\", 'r') as f:\n",
    "        mqm_scores = f.readlines()\n",
    "        mqm_scores = [float(mqm_score.replace('\\n', '')) for mqm_score in mqm_scores]\n",
    "    gold_lables = mqm_scores\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52c3d69",
   "metadata": {},
   "source": [
    "Evaluation on gold labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d08bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in approximations.columns:\n",
    "    print(f\"-----------------{col}-----------------\")\n",
    "    print(pearsonr(gold_lables, approximations[col].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17193a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in approximations.columns:\n",
    "    plot_df = pd.DataFrame({'true': gold_lables, 'pred': approximations[col].values})\n",
    "#     plot_df = plot_df.sort_values('pred')\n",
    "    \n",
    "    X = plot_df['pred']\n",
    "    Y = plot_df['true']\n",
    "    \n",
    "    plt.figure()\n",
    "    hist = plt.hist(Y, bins=20)\n",
    "    bin_boundaries = hist[1]\n",
    "    \n",
    "#     # Remove bins with too few samples\n",
    "#     cut_point = 99999\n",
    "#     for i, value in enumerate(hist[0]):\n",
    "#         if value < 5:\n",
    "#             cut_point = i\n",
    "#             break\n",
    "\n",
    "#     bin_boundaries = bin_boundaries[:cut_point]\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    x_plot = [(bin_boundaries[i] + bin_boundaries[i+1])/2 for i in range(0, len(bin_boundaries)-1)]\n",
    "    y_plot = [stats.trim_mean(Y[(bin_boundaries[i] < X) & (X < bin_boundaries[i+1])], 0.1) for i in range(0, len(bin_boundaries)-1)]\n",
    "    plt.plot(x_plot, y_plot)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('gold_lables')\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6c2efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toks = output.groupby('SRC_original_idx').first()['tokenized_SRC-Trans'].tolist()\n",
    "# toks = [' '.join(tok) for tok in toks]\n",
    "\n",
    "# with open('test/tmp.txt', 'w') as f:\n",
    "#     for x in toks:\n",
    "#         f.writelines(x + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020e200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63c618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b087f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965bd11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12471047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ea104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8108a525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f0871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225343d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189fbab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ce163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test to see if SRC_similarity is higher than Trans_similarity\n",
    "print(output[\"Trans-edit_distance\"].mean() - output[\"SRC-edit_distance\"].mean())\n",
    "stats.ttest_rel(output[\"SRC-edit_distance\"], \n",
    "                output[\"Trans-edit_distance\"], \n",
    "                alternative='less')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4187eb64",
   "metadata": {},
   "source": [
    "Tiny pvalue --> Indeed SRC-edit_distance is significantly lower than Trans-edit_distance\n",
    "\n",
    "\n",
    "(Careful with this tho, bc with number of samples too large then statistical test does not make sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada80a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(output[\"#TransChanges-#SrcChanges\"], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49917779",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"ChangesSpread/SentenceLength\"].describe())\n",
    "output[\"ChangesSpread/SentenceLength\"].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c12040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bfa2ffb",
   "metadata": {},
   "source": [
    "Some changes seems to have the same meaning but different phrasing, e.g., noun index 24, 36, 47\n",
    "\n",
    "Both for en-de and en-vi\n",
    "\n",
    "\n",
    "Kind of bias: en-vi adjective sample 82\n",
    "\n",
    "Should we cherry-pick examples? Or cherry-pick the replacement?\n",
    "\n",
    "\n",
    "Or narrow down scope of perturbation? (e.g., on countries, jobs, gender, ...?)\n",
    "\n",
    "\n",
    "\n",
    "Some cherry-picked examples anyway:\n",
    "\n",
    "- He comes from England --> Ông ấy đến từ Anh\n",
    "- He comes from Vietnam --> Hắn đến từ Việt Nam\n",
    "- He comes from North Korea --> Hắn đến từ Bắc Triều Tiên\n",
    "\n",
    "\n",
    "\n",
    "- He is european --> Hắn là người Châu Âu\n",
    "- He is asian --> Anh ấy là người châu Á.\n",
    "\n",
    "\n",
    "\n",
    "- He has black hair --> Hắn có tóc đen.\n",
    "- He has blonde hair --> Anh ấy có tóc vàng\n",
    "\n",
    "\n",
    "But if we limit this then it would hurt the model overal performance as well? \n",
    "\n",
    "*Jan: some kind of loss to minimize the number of changes, but not completely forbidden the changes*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e35e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ca514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755682c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be18d809",
   "metadata": {},
   "source": [
    "# Translation quality vs #changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848d704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "output[\"OriginalTran_Quality\"] = output.apply(\n",
    "    lambda x: sentence_gleu([x['tokenized_REF']], x['tokenized_SRC-Trans']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866fb6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.plot.scatter(x='OriginalTran_Quality', y=\"#TransChanges-#SrcChanges/SentenceLength\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f9d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(output['OriginalTran_Quality'], output[\"#TransChanges-#SrcChanges/SentenceLength\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(output[\"OriginalTran_Quality\"], bins='sturges')\n",
    "bin_boundaries = hist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f74bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use bins with same number of samples instead of equal-sized bins\n",
    "\n",
    "# results, bin_boundaries = pd.qcut(output[\"OriginalTran_Quality\"], q=5, retbins=True)\n",
    "# bin_boundaries\n",
    "\n",
    "\n",
    "# Remove bins with too few samples\n",
    "cut_point = 99999\n",
    "for i, value in enumerate(hist[0]):\n",
    "    if value < 5:\n",
    "        cut_point = i\n",
    "        break\n",
    "        \n",
    "bin_boundaries = bin_boundaries[:cut_point]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299dec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_boundaries\n",
    "\n",
    "X = output['OriginalTran_Quality']\n",
    "Y = output[\"#TransChanges-#SrcChanges/SentenceLength\"]\n",
    "\n",
    "x_plot = [(bin_boundaries[i] + bin_boundaries[i+1])/2 for i in range(0, len(bin_boundaries)-1)]\n",
    "y_plot = [stats.trim_mean(Y[(bin_boundaries[i] < X) & (X < bin_boundaries[i+1])], 0.1) for i in range(0, len(bin_boundaries)-1)]\n",
    "plt.plot(x_plot, y_plot)\n",
    "plt.xlabel('OriginalTrans_Quality')\n",
    "plt.ylabel('Avg_changes')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4cb6e1ad",
   "metadata": {},
   "source": [
    "bins = [(bin_boundaries[i], bin_boundaries[i+1]) for i in range(0, len(bin_boundaries)-1)]\n",
    "\n",
    "X = output['OriginalTran_Quality']\n",
    "Y = output[\"#TransChanges-#SrcChanges\"]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.boxplot([Y[(bin_i[0] < X) & (X < bin_i[1])] for bin_i in bins])\n",
    "# ax.set_xticklabels(bins)\n",
    "ax.set_xticklabels('')\n",
    "ax.set_xlabel('OriginalTran_Quality')\n",
    "ax.set_ylabel('#changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd6f40",
   "metadata": {},
   "source": [
    "Most of the time downward trend (not as clear for en-de with verb, adverb, pronoun; en-vi adverb, pronoun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a602006a",
   "metadata": {},
   "source": [
    "**Note**: the plot has outliers removed in both X and Y dimensions, by removing too small bins (X) and trimmed-mean (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f10e72",
   "metadata": {},
   "source": [
    "# #changes vs translation quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce6e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(output[\"#TransChanges-#SrcChanges\"], bins=20)\n",
    "bin_boundaries = hist[1]\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3529f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use bins with same number of samples instead of equal-sized bins\n",
    "# results, bin_boundaries = pd.qcut(output[\"#TransChanges-#SrcChanges\"], q=5, retbins=True)\n",
    "# bin_boundaries\n",
    "\n",
    "\n",
    "# Remove bins with too few samples\n",
    "cut_point = 99999\n",
    "for i, value in enumerate(hist[0]):\n",
    "    if value < 10:\n",
    "        cut_point = i\n",
    "        break\n",
    "        \n",
    "bin_boundaries = bin_boundaries[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb682d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_boundaries\n",
    "\n",
    "X = output['#TransChanges-#SrcChanges']\n",
    "Y = output[\"OriginalTran_Quality\"]\n",
    "\n",
    "x_plot = [(bin_boundaries[i] + bin_boundaries[i+1])/2 for i in range(0, len(bin_boundaries)-1)]\n",
    "\n",
    "y_plot = [stats.trim_mean(Y[(bin_boundaries[i] <= X) & (X <= bin_boundaries[i+1])], 0.1) for i in range(0, len(bin_boundaries)-1)]\n",
    "plt.plot(x_plot, y_plot)\n",
    "plt.xlabel('Avg_changes')\n",
    "plt.ylabel('OriginalTran_Quality')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edfd7c1d",
   "metadata": {},
   "source": [
    "bins = [(bin_boundaries[i], bin_boundaries[i+1]) for i in range(0, len(bin_boundaries)-1)]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.boxplot([Y[(bin_i[0] < X) & (X < bin_i[1])] for bin_i in bins])\n",
    "# ax.set_xticklabels(bins)\n",
    "ax.set_xticklabels('')\n",
    "ax.set_xlabel('#changes')\n",
    "ax.set_ylabel('OriginalTran_Quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c740f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30078a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55ac724c",
   "metadata": {},
   "source": [
    "# SentenceLength vs #changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d29f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['SRC-length'] = output.apply(\n",
    "    lambda x: len(x['tokenized_SRC']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.plot.scatter(x='SRC-length', y=\"#TransChanges-#SrcChanges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f0011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65022c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(output['SRC-length'], output[\"#TransChanges-#SrcChanges\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f3790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(output[\"SRC-length\"], bins=20)\n",
    "bin_boundaries = hist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192befe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove bins with too few samples\n",
    "cut_point = 99999\n",
    "for i, value in enumerate(hist[0]):\n",
    "    if value < 10:\n",
    "        cut_point = i\n",
    "        break\n",
    "        \n",
    "bin_boundaries = bin_boundaries[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ad438",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = output['SRC-length']\n",
    "Y = output[\"#TransChanges-#SrcChanges\"]\n",
    "\n",
    "x_plot = [(bin_boundaries[i] + bin_boundaries[i+1])/2 for i in range(0, len(bin_boundaries)-1)]\n",
    "y_plot = [stats.trim_mean(Y[(bin_boundaries[i] < X) & (X < bin_boundaries[i+1])], 0.1) for i in range(0, len(bin_boundaries)-1)]\n",
    "plt.plot(x_plot, y_plot)\n",
    "plt.xlabel('SRC-length')\n",
    "plt.ylabel('Avg_changes')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c18891ee",
   "metadata": {},
   "source": [
    "bins = [(bin_boundaries[i], bin_boundaries[i+1]) for i in range(0, len(bin_boundaries)-1)]\n",
    "\n",
    "X = output['SRC-length']\n",
    "Y = output[\"#TransChanges-#SrcChanges\"]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.boxplot([Y[(bin_i[0] < X) & (X < bin_i[1])] for bin_i in bins])\n",
    "# ax.set_xticklabels(bins)\n",
    "ax.set_xticklabels('')\n",
    "ax.set_xlabel('SRC-length')\n",
    "ax.set_ylabel('#changes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5a948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7635704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bc35529",
   "metadata": {},
   "source": [
    "# Beam_size vs #changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf8ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_dict = {}\n",
    "beam_values = [1,2,3,4,5]\n",
    "for beam in beam_values:\n",
    "    beam_dict[beam] = read_output_df(dataset, perturb_type, beam, replacement_strategy)\n",
    "    # Make sure the df all have the same index\n",
    "    if beam > 1:\n",
    "        assert beam_dict[beam].index.equals(beam_dict[beam].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63368394",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(beam_values,\n",
    "              [stats.trim_mean(beam_dict[x]['#TransChanges-#SrcChanges'], 0.1) for x in beam_values])\n",
    "plt.xlabel('beam')\n",
    "plt.ylabel('mean_changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5ff79",
   "metadata": {},
   "source": [
    "The mean might not saying anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76076635",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.boxplot([beam_dict[x]['#TransChanges-#SrcChanges'] for x in beam_values])\n",
    "ax.set_xticklabels(beam_values)\n",
    "ax.set_xlabel('beam')\n",
    "ax.set_ylabel('#changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34085167",
   "metadata": {},
   "source": [
    "# Perturbed word type vs #changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40211a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_type_dict = {}\n",
    "word_type_values = [\"noun\", \"verb\", \"adjective\", \"adverb\", \"pronoun\"]\n",
    "for word_type in word_type_values:\n",
    "    word_type_dict[word_type] = read_output_df(dataset, perturb_type=word_type, beam=beam, replacement_strategy=replacement_strategy)\n",
    "\n",
    "    \n",
    "print('--------------------------------')\n",
    "print('word type    -   trimmed-mean #changes')\n",
    "\n",
    "for word_type in word_type_values:\n",
    "    print(f\"{word_type} - {stats.trim_mean(word_type_dict[word_type]['#TransChanges-#SrcChanges'], 0.1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.boxplot([word_type_dict[x]['#TransChanges-#SrcChanges'] for x in word_type_values])\n",
    "ax.set_xticklabels(word_type_values)\n",
    "ax.set_xlabel('word_type')\n",
    "ax.set_ylabel('#changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b06547",
   "metadata": {},
   "source": [
    "# #Changes per sentence across word types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ceef7",
   "metadata": {},
   "source": [
    "See if the chaos changes are sentence-specific. Excluding perturbing pronouns bc not many samples have pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c13866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sentences that has multiple word types perturbed\n",
    "word_type_values = [\"noun\", \"verb\", \"adjective\", \"adverb\"]\n",
    "index_intersection = word_type_dict[word_type_values[0]].index\n",
    "for i in range(1, len(word_type_values)):\n",
    "    index_intersection = \\\n",
    "        index_intersection.intersection(word_type_dict[word_type_values[i]].index)\n",
    "\n",
    "len(index_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3094f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_per_word_type = pd.DataFrame()\n",
    "for word_type in word_type_values:\n",
    "    changes_per_word_type[word_type] = word_type_dict[word_type][\"#TransChanges-#SrcChanges\"].loc[index_intersection]\n",
    "    \n",
    "# Count the number of samples where the changes in trans always bigger than changes in SRC\n",
    "changes_per_word_type[(changes_per_word_type['noun'] > 0) & (changes_per_word_type['verb'] > 0) & \\\n",
    "                      (changes_per_word_type['adjective'] > 0) & (changes_per_word_type['adverb'] > 0)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba41e95",
   "metadata": {},
   "source": [
    "Small portion of rows --> not sentence-specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ace820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy import displacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentence = \"He is from Vietnam\"\n",
    "doc = nlp(sentence)\n",
    "\n",
    "print(f\"{'Node (from)-->':<15} {'Relation':^10} {'-->Node (to)':>15}\\n\")\n",
    "\n",
    "for token in doc:\n",
    "    print(\"{:<15} {:^10} {:>15}\".format(str(token.head.text), str(token.dep_), str(token.text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42699574",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(f\"Token: {token.text}\")\n",
    "    print(f\"Ancestors: {list(token.ancestors)}\")\n",
    "    print(f\"Children: {list(token.children)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce4e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy import displacy \n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "sentence = \"Er kommt aus Vietnam\"\n",
    "doc = nlp(sentence)\n",
    "\n",
    "print(f\"{'Node (from)-->':<15} {'Relation':^10} {'-->Node (to)':>15}\\n\")\n",
    "\n",
    "for token in doc:\n",
    "    print(\"{:<15} {:^10} {:>15}\".format(str(token.head.text), str(token.dep_), str(token.text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47c9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347d716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f080ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9975e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
