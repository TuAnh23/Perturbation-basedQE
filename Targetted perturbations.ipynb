{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c5cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import tarfile\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189b7d6",
   "metadata": {},
   "source": [
    "# Use EN samples from covost2 data \n",
    "\n",
    "(all data except for the pairs that has DE, just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ea70e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "original_data = pd.DataFrame(columns=['SRC'])\n",
    "\n",
    "data_dir = \"data/covost2/EN-translations\"\n",
    "\n",
    "deduplicated_each_dataset = 0\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".tar.gz\") and ('de' not in filename):\n",
    "        unzipped_file_name = filename.replace(\".tar.gz\", \"\")\n",
    "        \n",
    "        # Extract the file if not yet done so\n",
    "        if not os.path.exists(os.path.join(data_dir, unzipped_file_name)):\n",
    "            tar = tarfile.open(os.path.join(data_dir, filename))\n",
    "            tar.extractall(data_dir)\n",
    "            tar.close()\n",
    "            \n",
    "        tmp_df = pd.DataFrame()\n",
    "        tmp_df['SRC'] = pd.read_csv(os.path.join(data_dir, unzipped_file_name), sep='\\t')['translation']\n",
    "\n",
    "        deduplicated_each_dataset = deduplicated_each_dataset + tmp_df.drop_duplicates(subset='SRC').shape[0]\n",
    "        \n",
    "        original_data = pd.concat([original_data, tmp_df], axis=0, ignore_index=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "print(f\"all: {original_data.shape}\")\n",
    "print(f\"deduplicated_each_dataset: {deduplicated_each_dataset}\")\n",
    "print(f\"deduplicated all: {original_data.drop_duplicates(subset='SRC').shape}\")\n",
    "\n",
    "original_data = original_data.drop_duplicates(subset='SRC')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c20da",
   "metadata": {},
   "source": [
    "Filter out the errornously long sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84136d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_lengths = original_data['SRC'].apply(lambda x: len(x))\n",
    "\n",
    "length_stats = sentence_lengths.describe(percentiles=[.25, .5, .75, .99])\n",
    "\n",
    "original_data = original_data[sentence_lengths < length_stats['99%']]\n",
    "\n",
    "original_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97de2fee",
   "metadata": {},
   "source": [
    "Remove empty sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d554c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = original_data[original_data['SRC'] != \"\"]\n",
    "original_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a5d214",
   "metadata": {},
   "source": [
    "Remove the begining and end quotes for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda843b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Remove the begining and end quotes \n",
    "    \"\"\"\n",
    "    if (sentence.startswith('\\\"') and sentence.endswith('\\\"')) or \\\n",
    "        (sentence.startswith('“') and sentence.endswith('”')):\n",
    "        return sentence[1:-1]\n",
    "    return sentence\n",
    "\n",
    "\n",
    "original_data['SRC'] = original_data['SRC'].apply(lambda x: prepare_sentence(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502d2b93",
   "metadata": {},
   "source": [
    "Reindex after filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ff3438",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data['SRC'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c3de20",
   "metadata": {},
   "source": [
    "# Use EN samples from winoMT data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b5fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('data/winoMT_src.csv', index_col=0)\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7fee04",
   "metadata": {},
   "source": [
    "# Use EN samples from Must-SHE data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e37a15d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fr-0001</th>\n",
       "      <td>Now, I thought, \"How could I really capture this?</td>\n",
       "      <td>1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr-0002</th>\n",
       "      <td>I mean, from this entry, it would seem that I was born into a world that perceived someone like me to have nothing positive whatsoever going for them, when in fact, today I'm celebrated for the opportunities and adventures my life has procured.</td>\n",
       "      <td>1F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr-0003</th>\n",
       "      <td>So, I immediately went to look up the 2009 online edition, expecting to find a revision worth noting.</td>\n",
       "      <td>1F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr-0004</th>\n",
       "      <td>His name was Dr. Pizzutillo, an Italian American, whose name, apparently, was too difficult for most Americans to pronounce, so he went by Dr. P. And Dr. P always wore really colorful bow ties and had the very perfect disposition to work with children.</td>\n",
       "      <td>2M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr-0005</th>\n",
       "      <td>And, one day, he came in to my session — exhaustive and unforgiving, these sessions — and he said to me, \"Wow.</td>\n",
       "      <td>2M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                  SRC  \\\n",
       "ID                                                                                                                                                                                                                                                                      \n",
       "fr-0001                                                                                                                                                                                                             Now, I thought, \"How could I really capture this?   \n",
       "fr-0002          I mean, from this entry, it would seem that I was born into a world that perceived someone like me to have nothing positive whatsoever going for them, when in fact, today I'm celebrated for the opportunities and adventures my life has procured.   \n",
       "fr-0003                                                                                                                                                         So, I immediately went to look up the 2009 online edition, expecting to find a revision worth noting.   \n",
       "fr-0004  His name was Dr. Pizzutillo, an Italian American, whose name, apparently, was too difficult for most Americans to pronounce, so he went by Dr. P. And Dr. P always wore really colorful bow ties and had the very perfect disposition to work with children.   \n",
       "fr-0005                                                                                                                                                And, one day, he came in to my session — exhaustive and unforgiving, these sessions — and he said to me, \"Wow.   \n",
       "\n",
       "        CATEGORY  \n",
       "ID                \n",
       "fr-0001       1M  \n",
       "fr-0002       1F  \n",
       "fr-0003       1F  \n",
       "fr-0004       2M  \n",
       "fr-0005       2M  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = pd.read_csv(\n",
    "    f\"data/MuST-SHE_v1.2/MuST-SHE-v1.2-data/tsv/MONOLINGUAL.fr_v1.2.tsv\",\n",
    "    sep='\\t', index_col=0\n",
    ")[['SRC', 'CATEGORY']]\n",
    "print(original_data.shape)\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec10c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da031451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2760e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e7085a9",
   "metadata": {},
   "source": [
    "### Perform stemming on the data\n",
    "\n",
    "This would help reduce the vocab size, easier to later on choose the word to perturb\n",
    "\n",
    "ABORT: it reduce the vocab from 88066 to 71362, so not that much, so doesnt worth it. Also stemming makes the word invalid, so cannot use POS afterward to filter it out.\n",
    "\n",
    "Lemmatization would require defining POS --> not preferable, since we would want chinese and china to be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c5fcf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stem_sentence(stemmer, sentence):\n",
    "#     \"\"\" \n",
    "#     Return the stemmed sentence and \n",
    "#     a dictionary mapping the stem to the original word in the sentence\n",
    "#     \"\"\"\n",
    "#     tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "#     stem_word_dict = {}\n",
    "#     stemmed_tokenized_sentence = []\n",
    "    \n",
    "#     for word in tokenized_sentence:\n",
    "#         stem = stemmer.stem(word)\n",
    "#         stemmed_tokenized_sentence.append(stem)\n",
    "#         stem_word_dict[stem] = word\n",
    "        \n",
    "#     return ' '.join(stemmed_tokenized_sentence), stem_word_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73131ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "# original_data['StemSRC'], original_data['StemDict'] = \\\n",
    "#     zip(*original_data.apply(lambda x: stem_sentence(stemmer, x['SRC']), axis=1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd28fa",
   "metadata": {},
   "source": [
    "### Invesitigate in the frequencies of words across sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f77e3f",
   "metadata": {},
   "source": [
    "Count the number of occurance in sentence of each word. Here we **only use the sentences where the words only occurs 1 time**, which is convenient to analyse on the influence of the word on the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a9c305d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1108, 4596)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import find, csr_matrix\n",
    "\n",
    "corpus = original_data['SRC'].values\n",
    "vectorizer = CountVectorizer(tokenizer=nltk.word_tokenize, lowercase=True)\n",
    "count_fit = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Only consider the single occurance of a word in a sentence\n",
    "count_fit[count_fit > 1] = 0\n",
    "\n",
    "count_fit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ba29f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging execution time: 0.4570791721343994 seconds\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import time \n",
    "\n",
    "\n",
    "word_df = pd.DataFrame()\n",
    "word_df['word'] = vectorizer.get_feature_names_out()\n",
    "word_df['freq'] = np.asarray(count_fit.sum(axis=0)).flatten()\n",
    "\n",
    "\n",
    "spacy_model = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def spacy_pos_tag(word, spacy_model):\n",
    "    doc = spacy_model(word)\n",
    "    return [t.pos_ for t in doc][0]\n",
    "\n",
    "def nltk_pos_tag(word):\n",
    "    return nltk.pos_tag([word])[0][1]\n",
    "\n",
    "def get_entity_name(word, spacy_model):\n",
    "    \"\"\"\n",
    "    Function returning the NER output from spacy on a word\n",
    "    Return None if the word does not have any entity name\n",
    "    Labels and there descriptions:\n",
    "    ```\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    labels = nlp.get_pipe('ner').labels\n",
    "    for label in labels:\n",
    "        print(f'{label}: {spacy.explain(label)}')\n",
    "    ```\n",
    "        CARDINAL: Numerals that do not fall under another type\n",
    "        DATE: Absolute or relative dates or periods\n",
    "        EVENT: Named hurricanes, battles, wars, sports events, etc.\n",
    "        FAC: Buildings, airports, highways, bridges, etc.\n",
    "        GPE: Countries, cities, states\n",
    "        LANGUAGE: Any named language\n",
    "        LAW: Named documents made into laws.\n",
    "        LOC: Non-GPE locations, mountain ranges, bodies of water\n",
    "        MONEY: Monetary values, including unit\n",
    "        NORP: Nationalities or religious or political groups\n",
    "        ORDINAL: \"first\", \"second\", etc.\n",
    "        ORG: Companies, agencies, institutions, etc.\n",
    "        PERCENT: Percentage, including \"%\"\n",
    "        PERSON: People, including fictional\n",
    "        PRODUCT: Objects, vehicles, foods, etc. (not services)\n",
    "        QUANTITY: Measurements, as of weight or distance\n",
    "        TIME: Times smaller than a day\n",
    "        WORK_OF_ART: Titles of books, songs, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = spacy_model(word)\n",
    "    for w in doc.ents:\n",
    "        return w.label_\n",
    "\n",
    "start = time.time()\n",
    "word_df['POS'] = word_df['word'].apply(lambda x: nltk_pos_tag(x))\n",
    "print(f\"POS tagging execution time: {time.time() - start} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc84c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8851bcd7",
   "metadata": {},
   "source": [
    "Have a look at the most frequent content words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "916fd5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>i</td>\n",
       "      <td>399</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>my</td>\n",
       "      <td>219</td>\n",
       "      <td>PRP$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>me</td>\n",
       "      <td>156</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'m</td>\n",
       "      <td>143</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>it</td>\n",
       "      <td>142</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>you</td>\n",
       "      <td>132</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>he</td>\n",
       "      <td>111</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>we</td>\n",
       "      <td>89</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>she</td>\n",
       "      <td>85</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>do</td>\n",
       "      <td>81</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  freq   POS\n",
       "2070    i   399    NN\n",
       "2763   my   219  PRP$\n",
       "2599   me   156   PRP\n",
       "8      'm   143   VBP\n",
       "2229   it   142   PRP\n",
       "4580  you   132   PRP\n",
       "1948   he   111   PRP\n",
       "4448   we    89   PRP\n",
       "3707  she    85   PRP\n",
       "1257   do    81    VB"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 9999999)\n",
    "\n",
    "def is_content_tag(nltk_pos):\n",
    "    content_tags_prefix = ['NN', 'V', 'JJ', 'PRP']  # Noun, verb, adj, adv (RB, but removed), pronoun\n",
    "    for prefix in content_tags_prefix:\n",
    "        if nltk_pos.startswith(prefix):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_stopword(word):\n",
    "    # Manually define some stopwords (words that dont contain much content, or errornous)\n",
    "    stopwords = ['is', 'are', 'was', 'were', 'am', 'be', \n",
    "                 'not', 'let',\n",
    "                 'have', 'has', 'had', \n",
    "                 'de', 'la', 'du', 're', 'sur', 'des', 'le', 'll', \n",
    "                 'oh', 'lot', 'les', 'ah', 'en', 've',\n",
    "                 'didn', 'bois']\n",
    "    return word in stopwords\n",
    "\n",
    "\n",
    "content_word_bool = word_df['POS'].apply(lambda x: is_content_tag(x)) \\\n",
    "    & (~word_df['word'].apply(lambda x: is_stopword(x)))\n",
    "\n",
    "word_df[content_word_bool].sort_values(\n",
    "    by='freq', ascending=False\n",
    ").head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461e66a8",
   "metadata": {},
   "source": [
    "### Create input data where we mask a set of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b85a7e5",
   "metadata": {},
   "source": [
    "#### Set of regional words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3c959e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_regional_tag(spacy_ner):\n",
    "#     regional_tags = ['GPE', 'LANGUAGE', 'NORP']\n",
    "#     return spacy_ner in regional_tags\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "# word_df['NER'] = word_df['word'].apply(lambda x: get_entity_name(x, spacy_model))\n",
    "# print(f\"NER execution time: {time.time() - start} seconds\")\n",
    "\n",
    "\n",
    "# regional_word_bool = word_df['NER'].apply(lambda x: is_regional_tag(x)) \\\n",
    "#     & (~word_df['word'].apply(lambda x: is_stopword(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f987d",
   "metadata": {},
   "source": [
    "#### Set of all content words that is frequent in the inference data\n",
    "\n",
    "We select the words that appears in over 50 sentences.\n",
    "\n",
    "When we dont need to group sentences with the same masked word, we keep the word freq over sentences lower (10) just to filter out the weird rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "570e704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_OF_SENTENCES = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7cbd543b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/10_vywcj3lb14yk3sn91jn3c0000gn/T/ipykernel_65976/3411812722.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  word_df[content_word_bool][word_df['freq'] > NR_OF_SENTENCES].sort_values('freq', ascending=False).head()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>i</td>\n",
       "      <td>399</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>my</td>\n",
       "      <td>219</td>\n",
       "      <td>PRP$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>me</td>\n",
       "      <td>156</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'m</td>\n",
       "      <td>143</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>it</td>\n",
       "      <td>142</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  freq   POS\n",
       "2070    i   399    NN\n",
       "2763   my   219  PRP$\n",
       "2599   me   156   PRP\n",
       "8      'm   143   VBP\n",
       "2229   it   142   PRP"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df[content_word_bool][word_df['freq'] > NR_OF_SENTENCES].sort_values('freq', ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b76d13",
   "metadata": {},
   "source": [
    "Filter out the strange words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b6cc73a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "def is_valid_word(word):\n",
    "    # Filter out the words that has all punctuations in it\n",
    "    \n",
    "    all_puncts = string.punctuation + '—'\n",
    "    contains_all_puncts = True\n",
    "    for char in word:\n",
    "        if char not in all_puncts:\n",
    "            contains_all_puncts = False\n",
    "            break\n",
    "    if contains_all_puncts:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    # Filter out the words with strange characters in it\n",
    "    # Strange characters are punctuations, except ' . -\n",
    "    strange_characters = all_puncts.replace(\"\\'\", '').replace(\".\", '').replace(\"-\", '').replace(\"—\", '')\n",
    "    for char in strange_characters:\n",
    "        if char in word:\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "valid_word_bool = word_df['word'].apply(is_valid_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9d069c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_word_bool = content_word_bool & (word_df['freq'] > NR_OF_SENTENCES) & valid_word_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83baf82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4115"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(filtered_word_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e423c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded953c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6ea6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5e80ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def mask_sentence(sentence, masked_word):\n",
    "    \"\"\"\n",
    "        sentence: the original sentence without preprocessing\n",
    "        masked_word: the word to be masked (in lowercase)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the location of the word in the sentence\n",
    "    word_locations = [m.start() for m in re.finditer(masked_word, sentence.lower())]\n",
    "\n",
    "    \n",
    "    # Make sure that it is actually a standalone word (e.g., 'HE' and not 'tHE')\n",
    "    final_word_location = None\n",
    "    for x in word_locations:\n",
    "        # Make sure the character before and after the word is not alphabet\n",
    "        if (x == 0 or (not sentence.lower()[x-1].isalpha())) and \\\n",
    "            (x + len(masked_word) == len(sentence) or (not sentence.lower()[x + len(masked_word)].isalpha())):\n",
    "            final_word_location = x\n",
    "            break\n",
    "\n",
    "    if final_word_location is None:\n",
    "        # Not an independent word, pass\n",
    "        return pd.NA\n",
    "\n",
    "    \n",
    "    return sentence[:final_word_location] + '[MASK]' + sentence[final_word_location+len(masked_word):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "17cb3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_data = pd.DataFrame(columns=['SRC', 'SRC_masked', 'original_word'])\n",
    "\n",
    "filtered_word_df = word_df[filtered_word_bool]\n",
    "\n",
    "for word_index, filtered_word_row in filtered_word_df.iterrows():\n",
    "    # Indices of the sentences that contains the word\n",
    "    sentence_indices = original_data.index[count_fit.transpose()[word_index].nonzero()[1]]\n",
    "    \n",
    "#     # Randomly select a fixed number of sentences\n",
    "#     sentence_indices = np.random.choice(a=sentence_indices, \n",
    "#                                         size=NR_OF_SENTENCES, \n",
    "#                                         replace=False)\n",
    "    \n",
    "    # Create a temporary df to store the sentences for this word\n",
    "    tmp_df = pd.DataFrame()\n",
    "    tmp_df['SRC_original_idx'] = sentence_indices\n",
    "    tmp_df['SRC'] = original_data.loc[sentence_indices, 'SRC'].values\n",
    "    tmp_df['original_word'] = filtered_word_row['word']\n",
    "    \n",
    "    # Mask the word in those sentences\n",
    "    tmp_df['SRC_masked'] = \\\n",
    "        original_data.loc[sentence_indices, 'SRC'].apply(\n",
    "        lambda x: mask_sentence(sentence=x, masked_word=filtered_word_row['word'])\n",
    "        ).values\n",
    "    \n",
    "    # Concat to the whole df\n",
    "    masked_data = pd.concat([masked_data, tmp_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dace7cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12240, 4)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_data = masked_data.dropna()\n",
    "masked_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cba1033c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC</th>\n",
       "      <th>SRC_masked</th>\n",
       "      <th>original_word</th>\n",
       "      <th>SRC_original_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>And I suppose I could mention from one of the very earliest computer scientists, whose name was Norbert Wiener, and he wrote a book back in the '50s, from before I was even born, called \"The Human Use of Human Beings.\" And in the book, he described the potential to create a computer system that would be gathering data from people and providing feedback to those people in real time in order to put them kind of partially, statistically, in a Skinner box, in a behaviorist system, and he has this amazing line where he says, one could imagine, as a thought experiment — and I'm paraphrasing, this isn't a quote — one could imagine a global computer system where everybody has devices on them all the time, and the devices are giving them feedback based on what they did, and the whole population is subject to a degree of behavior modification.</td>\n",
       "      <td>And I suppose I could mention from one of the very earliest computer scientists, whose name was Norbert Wiener, and he wrote a book back in the [MASK], from before I was even born, called \"The Human Use of Human Beings.\" And in the book, he described the potential to create a computer system that would be gathering data from people and providing feedback to those people in real time in order to put them kind of partially, statistically, in a Skinner box, in a behaviorist system, and he has this amazing line where he says, one could imagine, as a thought experiment — and I'm paraphrasing, this isn't a quote — one could imagine a global computer system where everybody has devices on them all the time, and the devices are giving them feedback based on what they did, and the whole population is subject to a degree of behavior modification.</td>\n",
       "      <td>'50s</td>\n",
       "      <td>fr-0383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And I suppose I could mention from one of the very earliest computer scientists, whose name was Norbert Wiener, and he wrote a book back in the '50s, from before I was even born, called \"The Human Use of Human Beings.\" And in the book, he described the potential to create a computer system that would be gathering data from people and providing feedback to those people in real time in order to put them kind of partially, statistically, in a Skinner box, in a behaviorist system, and he has this amazing line where he says, one could imagine, as a thought experiment — and I'm paraphrasing, this isn't a quote — one could imagine a global computer system where everybody has devices on them all the time, and the devices are giving them feedback based on what they did, and the whole population is subject to a degree of behavior modification.</td>\n",
       "      <td>And I suppose I could mention from one of the very earliest computer scientists, whose name was Norbert Wiener, and he wrote a book back in the [MASK], from before I was even born, called \"The Human Use of Human Beings.\" And in the book, he described the potential to create a computer system that would be gathering data from people and providing feedback to those people in real time in order to put them kind of partially, statistically, in a Skinner box, in a behaviorist system, and he has this amazing line where he says, one could imagine, as a thought experiment — and I'm paraphrasing, this isn't a quote — one could imagine a global computer system where everybody has devices on them all the time, and the devices are giving them feedback based on what they did, and the whole population is subject to a degree of behavior modification.</td>\n",
       "      <td>'50s</td>\n",
       "      <td>fr-0384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had a thumb, I had 85 dollars, and I ended up in San Francisco, California — met a lover — and back in the '80s, found it necessary to begin work on AIDS organizations.</td>\n",
       "      <td>I had a thumb, I had 85 dollars, and I ended up in San Francisco, California — met a lover — and back in the [MASK], found it necessary to begin work on AIDS organizations.</td>\n",
       "      <td>'80s</td>\n",
       "      <td>fr-0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>I think you do have too much trouble about this flag. \"\" I think that the artist should be returned to his heritage, i.e., the jungles of Africa, and then he can shovel manure in his artistic way. \"\" This flag I'm standing on stands for everything oppressive in this system: the murder of the Indians and all the oppressed around the world, including my brother who was shot by a pig, who kicked over his body to 'make sure the nigger was dead.' That pig was wearing the flag.</td>\n",
       "      <td>I think you do have too much trouble about this flag. \"\" I think that the artist should be returned to his heritage, i.e., the jungles of Africa, and then he can shovel manure in his artistic way. \"\" This flag I'm standing on stands for everything oppressive in this system: the murder of the Indians and all the oppressed around the world, including my brother who was shot by a pig, who kicked over his body to [MASK] sure the nigger was dead.' That pig was wearing the flag.</td>\n",
       "      <td>'make</td>\n",
       "      <td>fr-0725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>I got a phone call from a 30-something friend, a woman, she said, \"So, my partner and I were in the middle of doing some things and I was like, 'I want you right now.' And he said, 'No, you're still dry, you're just being nice.' And I was so ready.</td>\n",
       "      <td>I got a phone call from a 30-something friend, a woman, she said, \"So, my partner and I were in the middle of doing some things and I was like, 'I want you right now.' And he said, [MASK], you're still dry, you're just being nice.' And I was so ready.</td>\n",
       "      <td>'no</td>\n",
       "      <td>fr-0506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               SRC  \\\n",
       "0    And I suppose I could mention from one of the very earliest computer scientists, whose name was Norbert Wiener, and he wrote a book back in the '50s, from before I was even born, called \"The Human Use of Human Beings.\" And in the book, he described the potential to create a computer system that would be gathering data from people and providing feedback to those people in real time in order to put them kind of partially, statistically, in a Skinner box, in a behaviorist system, and he has this amazing line where he says, one could imagine, as a thought experiment — and I'm paraphrasing, this isn't a quote — one could imagine a global computer system where everybody has devices on them all the time, and the devices are giving them feedback based on what they did, and the whole population is subject to a degree of behavior modification.   \n",
       "1    And I suppose I could mention from one of the very earliest computer scientists, whose name was Norbert Wiener, and he wrote a book back in the '50s, from before I was even born, called \"The Human Use of Human Beings.\" And in the book, he described the potential to create a computer system that would be gathering data from people and providing feedback to those people in real time in order to put them kind of partially, statistically, in a Skinner box, in a behaviorist system, and he has this amazing line where he says, one could imagine, as a thought experiment — and I'm paraphrasing, this isn't a quote — one could imagine a global computer system where everybody has devices on them all the time, and the devices are giving them feedback based on what they did, and the whole population is subject to a degree of behavior modification.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       I had a thumb, I had 85 dollars, and I ended up in San Francisco, California — met a lover — and back in the '80s, found it necessary to begin work on AIDS organizations.   \n",
       "146                                                                                                                                                                                                                                                                                                                                                                                   I think you do have too much trouble about this flag. \"\" I think that the artist should be returned to his heritage, i.e., the jungles of Africa, and then he can shovel manure in his artistic way. \"\" This flag I'm standing on stands for everything oppressive in this system: the murder of the Indians and all the oppressed around the world, including my brother who was shot by a pig, who kicked over his body to 'make sure the nigger was dead.' That pig was wearing the flag.   \n",
       "147                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       I got a phone call from a 30-something friend, a woman, she said, \"So, my partner and I were in the middle of doing some things and I was like, 'I want you right now.' And he said, 'No, you're still dry, you're just being nice.' And I was so ready.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          SRC_masked  \\\n",
       "0    And I suppose I could mention from one of the very earliest computer scientists, whose name was Norbert Wiener, and he wrote a book back in the [MASK], from before I was even born, called \"The Human Use of Human Beings.\" And in the book, he described the potential to create a computer system that would be gathering data from people and providing feedback to those people in real time in order to put them kind of partially, statistically, in a Skinner box, in a behaviorist system, and he has this amazing line where he says, one could imagine, as a thought experiment — and I'm paraphrasing, this isn't a quote — one could imagine a global computer system where everybody has devices on them all the time, and the devices are giving them feedback based on what they did, and the whole population is subject to a degree of behavior modification.   \n",
       "1    And I suppose I could mention from one of the very earliest computer scientists, whose name was Norbert Wiener, and he wrote a book back in the [MASK], from before I was even born, called \"The Human Use of Human Beings.\" And in the book, he described the potential to create a computer system that would be gathering data from people and providing feedback to those people in real time in order to put them kind of partially, statistically, in a Skinner box, in a behaviorist system, and he has this amazing line where he says, one could imagine, as a thought experiment — and I'm paraphrasing, this isn't a quote — one could imagine a global computer system where everybody has devices on them all the time, and the devices are giving them feedback based on what they did, and the whole population is subject to a degree of behavior modification.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       I had a thumb, I had 85 dollars, and I ended up in San Francisco, California — met a lover — and back in the [MASK], found it necessary to begin work on AIDS organizations.   \n",
       "146                                                                                                                                                                                                                                                                                                                                                                                    I think you do have too much trouble about this flag. \"\" I think that the artist should be returned to his heritage, i.e., the jungles of Africa, and then he can shovel manure in his artistic way. \"\" This flag I'm standing on stands for everything oppressive in this system: the murder of the Indians and all the oppressed around the world, including my brother who was shot by a pig, who kicked over his body to [MASK] sure the nigger was dead.' That pig was wearing the flag.   \n",
       "147                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      I got a phone call from a 30-something friend, a woman, she said, \"So, my partner and I were in the middle of doing some things and I was like, 'I want you right now.' And he said, [MASK], you're still dry, you're just being nice.' And I was so ready.   \n",
       "\n",
       "    original_word SRC_original_idx  \n",
       "0            '50s          fr-0383  \n",
       "1            '50s          fr-0384  \n",
       "2            '80s          fr-0145  \n",
       "146         'make          fr-0725  \n",
       "147           'no          fr-0506  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cdc66bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_data.to_csv('data/masked_content_covost2_for_en2de_no_sentence_group.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "505c78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_data.to_csv('data/masked_content_winoMT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5d8e49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_data.to_csv('data/masked_content_mustSHE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab31ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
