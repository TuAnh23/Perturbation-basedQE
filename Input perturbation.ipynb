{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "03046c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "import random\n",
    "from difflib import SequenceMatcher\n",
    "from scipy import stats\n",
    "import sacrebleu\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "import spacy\n",
    "\n",
    "\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac6c851",
   "metadata": {},
   "source": [
    "German word2vec model Facebook https://fasttext.cc/docs/en/crawl-vectors.html (cc.de.300.bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2415041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein_distance#Python\n",
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f222dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/difflib.html\n",
    "    \n",
    "def changes_spread(original_tokenized, changed_tokenized, opcodes):\n",
    "    start_change = -1\n",
    "    end_change = -1\n",
    "    for opcode in opcodes:\n",
    "        if opcode[0] != 'equal':\n",
    "            start_change = opcode[1]\n",
    "            break\n",
    "    for opcode in reversed(opcodes):\n",
    "        if opcode[0] != 'equal':\n",
    "            end_change = opcode[2]\n",
    "            break\n",
    "    return max(0, end_change-start_change)/len(changed_tokenized)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8464b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_in_capital(sentence_tokenized, highlight_positions):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        sentence_tokenized: tokenzied sentence\n",
    "        highlight_positions: list of 2-sized tuples: [(p1, p2), (p3,p4), ...]\n",
    "            where we want to highlight sentence[p1:p2], sentence[p3:p4]\n",
    "    \"\"\"\n",
    "    highlighted_sentence = []\n",
    "    \n",
    "    last = 0  # index of the last position added to the new sentence\n",
    "    for (start, stop) in highlight_positions:\n",
    "        highlighted_sentence.extend(\n",
    "            sentence_tokenized[last:start] + \\\n",
    "            [w.upper() for w in sentence_tokenized[start:stop]]\n",
    "        )\n",
    "        last = stop\n",
    "    if last < len(sentence_tokenized):\n",
    "        highlighted_sentence.extend(\n",
    "            sentence_tokenized[last:]\n",
    "        )\n",
    "    return ' '.join(highlighted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3de55b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_chunk_changed(original_tokenized, changed_tokenized, opcodes, \n",
    "                      chunk_max_length=1, spacy_model=None, w2v_model=None):\n",
    "    # Return the original and changed sentences with the chunk highlighted in capital\n",
    "    # Return whether this sentence has only two chunk changes within the max length. \n",
    "    # And return the distance between the two changed chunks\n",
    "    \n",
    "    is_two_chunk_changed = False\n",
    "    chunk_distance = pd.NA\n",
    "    is_same_subtree = pd.NA\n",
    "    changes_similarity = pd.NA\n",
    "    \n",
    "    \n",
    "    \n",
    "    changes_types = [o[0] for o in opcodes]\n",
    "    \n",
    "    # If not exactly two changes, return\n",
    "    if not (all(changes_type == 'replace' or changes_type == 'equal' for changes_type in changes_types) and \\\n",
    "        changes_types.count('replace') == 2):\n",
    "        return is_two_chunk_changed, chunk_distance, is_same_subtree, changes_similarity\n",
    "    \n",
    "    # Find the positions of the two changed chunks\n",
    "    i_replace = [i for i, change in enumerate(changes_types) if change == \"replace\"]\n",
    "    \n",
    "    # If two changed chunks not have length less than chunk_max_length, return\n",
    "    if not (opcodes[i_replace[0]][2] - opcodes[i_replace[0]][1] <= chunk_max_length and \\\n",
    "            opcodes[i_replace[1]][2] - opcodes[i_replace[1]][1] <= chunk_max_length):\n",
    "        return is_two_chunk_changed, chunk_distance, is_same_subtree, changes_similarity\n",
    "    \n",
    "    # At this point, this should be a valid two_chunk within length change\n",
    "    is_two_chunk_changed = True\n",
    "    \n",
    "    # Check if there is indeed an equal chunks in between of the two changed chunk\n",
    "    # Calculate the distance between two chunks = the equal chunk in between\n",
    "    i_equal_in_between = (i_replace[1] + i_replace[0]) // 2\n",
    "    assert opcodes[i_equal_in_between][0] == 'equal'\n",
    "    chunk_distance = opcodes[i_equal_in_between][2] - opcodes[i_equal_in_between][1]\n",
    "\n",
    "\n",
    "    if spacy_model is not None: \n",
    "        # In the two_chunk_changed case when chunk_max_length=1, i.e., only two words are changed \n",
    "        # comparing to the original translation\n",
    "        # Check if the two changed words are in the same sub tree of the dependency tree\n",
    "        if (opcodes[i_replace[0]][4] - opcodes[i_replace[0]][3] == 1 and \\\n",
    "            opcodes[i_replace[1]][4] - opcodes[i_replace[1]][3] == 1):\n",
    "            # Find the ancestors and children of the two changed words\n",
    "            doc = spacy_model(' '.join(changed_tokenized))\n",
    "            token1, token2 = None, None\n",
    "            family1, family2 = None, None\n",
    "            for token in doc:\n",
    "                if token.text == changed_tokenized[opcodes[i_replace[0]][3]]:\n",
    "                    token1 = token.text\n",
    "                    family1 = list(token.ancestors) + list(token.children)\n",
    "                    family1 = [t.text for t in family1]\n",
    "                elif token.text == changed_tokenized[opcodes[i_replace[1]][3]]:\n",
    "                    token2 = token.text\n",
    "                    family2 = list(token.ancestors) + list(token.children)\n",
    "                    family2 = [t.text for t in family2]\n",
    "\n",
    "            if token1 is None or token2 is None:\n",
    "                is_same_subtree = pd.NA\n",
    "            else:\n",
    "                if token1 in family2 or token2 in family1:\n",
    "                    is_same_subtree = True\n",
    "                else:\n",
    "                    is_same_subtree = False\n",
    "\n",
    "\n",
    "    # Calculate the senmatic similarity of the two changed words (cosine similarity in [-1, 1])\n",
    "    if w2v_model is not None:\n",
    "        # Can only calculate when only two single tokens are changed\n",
    "        if (opcodes[i_replace[0]][4] - opcodes[i_replace[0]][3] == 1 and \\\n",
    "            opcodes[i_replace[1]][4] - opcodes[i_replace[1]][3] == 1 and \\\n",
    "            opcodes[i_replace[0]][2] - opcodes[i_replace[0]][1] == 1 and \\\n",
    "            opcodes[i_replace[1]][2] - opcodes[i_replace[1]][1] == 1):\n",
    "\n",
    "            original_word_1 = original_tokenized[opcodes[i_replace[0]][1]]\n",
    "            changed_word_1 = changed_tokenized[opcodes[i_replace[0]][3]]\n",
    "\n",
    "            original_word_2 = original_tokenized[opcodes[i_replace[1]][1]]\n",
    "            changed_word_2 = changed_tokenized[opcodes[i_replace[1]][3]]\n",
    "\n",
    "            if original_word_1 in w2v_model.index_to_key and original_word_2 in w2v_model.index_to_key and \\\n",
    "                changed_word_1 in w2v_model.index_to_key and changed_word_2 in w2v_model.index_to_key:\n",
    "                changes_similarity = [{'original_word': original_word_1, \n",
    "                                       'changed_word': changed_word_1, \n",
    "                                       'semantic_similarity': w2v_model.similarity(original_word_1, changed_word_1)},\n",
    "                                      {'original_word': original_word_2,\n",
    "                                       'changed_word': changed_word_2,\n",
    "                                       'semantic_similarity': w2v_model.similarity(original_word_2, changed_word_2)}]\n",
    "\n",
    "\n",
    "    return is_two_chunk_changed, chunk_distance, is_same_subtree, changes_similarity\n",
    "    \n",
    "    \n",
    "def highlight_changes(original_tokenized, changed_tokenized, opcodes):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        original_tokenized: tokenized original sentence\n",
    "        changed_tokenized: tokenized changed sentence\n",
    "        opcodes: changes to get from `original_tokenized` to `changed_tokenized`\n",
    "    Returns:\n",
    "        original_sentence and changed_sentence with the changes highlighted in capital\n",
    "    \"\"\"\n",
    "    \n",
    "    highlighted_original_sentence_positions = []\n",
    "    highlighted_changed_sentence_positions = []\n",
    "    \n",
    "    for opcode in opcodes:\n",
    "        tag, i1, i2, j1, j2 = opcode[0], opcode[1], opcode[2], opcode[3], opcode[4]\n",
    "        \n",
    "        if tag != 'equal':\n",
    "            highlighted_original_sentence_positions.append((i1, i2))\n",
    "            highlighted_changed_sentence_positions.append((j1, j2))\n",
    "            \n",
    "    original_sentence_highlighted = highlight_in_capital(\n",
    "        sentence_tokenized=original_tokenized, \n",
    "        highlight_positions=highlighted_original_sentence_positions\n",
    "    )\n",
    "    \n",
    "    changed_sentence_highlighted = highlight_in_capital(\n",
    "        sentence_tokenized=changed_tokenized, \n",
    "        highlight_positions=highlighted_changed_sentence_positions\n",
    "    )\n",
    "    \n",
    "    return original_sentence_highlighted, changed_sentence_highlighted\n",
    "    \n",
    "    \n",
    "def calculate_change(original, changed):\n",
    "    # Return the original and changed sentences with the changes highlighted in capital\n",
    "    \n",
    "    original_tokenized = nltk.word_tokenize(original)\n",
    "    changed_tokenized = nltk.word_tokenize(changed)\n",
    "    \n",
    "    opcodes = SequenceMatcher(None, original_tokenized, changed_tokenized).get_opcodes()\n",
    "    \n",
    "    \n",
    "    return original_tokenized, changed_tokenized, opcodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b46ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alignment(path_prefix):\n",
    "    alignment_file_path = f\"{path_prefix}_word_alignment.txt\"\n",
    "    if not os.path.isfile(alignment_file_path):\n",
    "        raise RuntimeError(\"Alignment file not exist.\")\n",
    "        \n",
    "    else:\n",
    "        with open(alignment_file_path) as f:\n",
    "            lines = [line.rstrip() for line in f]\n",
    "            \n",
    "        translation_alignment = []\n",
    "        for line in lines:\n",
    "            word_pairs = line.split()\n",
    "            word_pairs = [word_pair.split('<sep>') for word_pair in word_pairs]\n",
    "            translation_alignment.append(dict(word_pairs))\n",
    "        return translation_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d9c162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reason_of_change(alignment, changes, perturbed_src_word):\n",
    "    if type(changes) != list:\n",
    "        return pd.NA\n",
    "    elif perturbed_src_word not in alignment.keys():\n",
    "        changes[0]['change_type'] = None\n",
    "        changes[1]['change_type'] = None\n",
    "    elif alignment[perturbed_src_word] == changes[0]['changed_word'] and alignment[perturbed_src_word] == changes[1]['changed_word']:\n",
    "        # Both changes are due to perturbation --> weird --> pass\n",
    "        changes[0]['change_type'] = None\n",
    "        changes[1]['change_type'] = None\n",
    "    elif alignment[perturbed_src_word] != changes[0]['changed_word'] and alignment[perturbed_src_word] != changes[1]['changed_word']:\n",
    "        # Both changes NOT due to perturbation --> weird --> pass\n",
    "        changes[0]['change_type'] = None\n",
    "        changes[1]['change_type'] = None\n",
    "    elif alignment[perturbed_src_word] == changes[0]['changed_word']:\n",
    "        changes[0]['change_type'] = \"perturbed\"\n",
    "        changes[1]['change_type'] = \"not_perturbed\"\n",
    "    elif alignment[perturbed_src_word] == changes[1]['changed_word']:\n",
    "        changes[0]['change_type'] = \"not_perturbed\"\n",
    "        changes[1]['change_type'] = \"perturbed\"\n",
    "        \n",
    "    return changes\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "842ed6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag_not_perturbed_change(changes, spacy_model):\n",
    "    if type(changes) != list:\n",
    "        return pd.NA\n",
    "    elif changes[0]['change_type'] == \"not_perturbed\":\n",
    "        doc = spacy_model(changes[0]['changed_word'])\n",
    "        return [t.pos_ for t in doc][0]\n",
    "    elif changes[1]['change_type'] == \"not_perturbed\":\n",
    "        doc = spacy_model(changes[1]['changed_word'])\n",
    "        return [t.pos_ for t in doc][0]\n",
    "    return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7b8355ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output_df(dataset, perturb_type, beam, replacement_strategy, analyse_feature=True, \n",
    "                   ignore_case=False, no_of_replacements=1, chunk_max_length=1, spacy_model=None, \n",
    "                   w2v_model=None, use_alignment=False, winoMT=False, ref_available=False):\n",
    "    if winoMT:\n",
    "        path_prefix = \"output/winoMT_asmetric/wmt19_winoMT_perturbed\"\n",
    "        output_df = pd.read_csv('output/winoMT_asmetric/wmt19_winoMT_perturbed_format.csv', index_col=0)  \n",
    "    else:\n",
    "        if no_of_replacements == 1:\n",
    "            path_prefix = f\"output/{dataset}/{replacement_strategy}/beam{beam}_perturb{perturb_type}/seed0/translations\"\n",
    "        else:\n",
    "            path_prefix = f\"output/{dataset}/{replacement_strategy}/beam{beam}_perturb{perturb_type}/seed0/translations_5replacements\"\n",
    "\n",
    "        output_df = pd.read_csv(f\"{path_prefix}.csv\", index_col=0)\n",
    "\n",
    "        # Join to get the translation of the original sentences as well\n",
    "        output_df = output_df.join(pd.read_csv(\n",
    "            f\"output/{dataset}/{replacement_strategy}/beam{beam}_perturbNone/seed0/translations.csv\", index_col=0\n",
    "        )['OriginalSRC-Trans'])\n",
    "        \n",
    "    \n",
    "    # Convert columns with sentences to str type\n",
    "    cols = ['SRC', 'REF', 'SRC_perturbed', 'SRC_perturbed-Trans', 'OriginalSRC-Trans']\n",
    "    if not ref_available:\n",
    "        cols.remove('REF')\n",
    "    output_df[cols] = output_df[cols].astype(str)\n",
    "    \n",
    "    if ignore_case:\n",
    "        output_df[cols] = output_df[cols].applymap(lambda x: x.lower())\n",
    "    \n",
    "    # Reorder the columns\n",
    "    if winoMT:\n",
    "        cols = ['SRC', 'REF', 'original_word', 'perturbed_word', 'SRC_perturbed', 'OriginalSRC-Trans', 'SRC_perturbed-Trans', 'Bias_sample']\n",
    "    elif no_of_replacements == 1:\n",
    "        cols = ['SRC', 'REF', 'original_word', 'perturbed_word', 'SRC_perturbed', 'OriginalSRC-Trans', 'SRC_perturbed-Trans']\n",
    "    else:\n",
    "        cols = ['SRC_index', 'SRC', 'REF', 'original_word', 'perturbed_word', 'SRC_perturbed', 'OriginalSRC-Trans', 'SRC_perturbed-Trans']\n",
    "    if not ref_available:\n",
    "        cols.remove('REF')\n",
    "    output_df = output_df[cols]\n",
    "    \n",
    "    if analyse_feature:\n",
    "        print(f\"Original df shape: {output_df.shape}\")\n",
    "        output_df = output_df.dropna()\n",
    "        print(f\"After dropping none-perturbed sentences: {output_df.dropna().shape}\")\n",
    "        \n",
    "        \n",
    "        # Calculate the changes, i.e., how to get from the original trans sentence \n",
    "        # to the changed trans sentence\n",
    "        output_df['tokenized_OriginalSRC-Trans'], output_df['tokenized_SRC_perturbed-Trans'], output_df['opcodes'] \\\n",
    "            = zip(*output_df.apply(\n",
    "                lambda x: calculate_change(x['OriginalSRC-Trans'], \n",
    "                                           x['SRC_perturbed-Trans']), axis=1\n",
    "            ))\n",
    "        \n",
    "        \n",
    "        # Highlight the changes in the trans sentences\n",
    "        output_df[\"OriginalSRC-Trans\"], output_df['SRC_perturbed-Trans'] \\\n",
    "            = zip(*output_df.apply(\n",
    "                lambda x: highlight_changes(\n",
    "                    x['tokenized_OriginalSRC-Trans'], \n",
    "                    x['tokenized_SRC_perturbed-Trans'], \n",
    "                    x['opcodes']), axis=1\n",
    "            ))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if replacement_strategy == 'word2vec_similarity':\n",
    "            # SRC difference is the number of occurances of the word we perturb\n",
    "            output_df[\"SRC-edit_distance\"] = output_df.apply(lambda x: x['tokenized_OriginalSRC-Trans'].count(x['original_word']), axis=1)\n",
    "        else:\n",
    "            output_df[\"SRC-edit_distance\"] = 1\n",
    "        output_df['Trans-edit_distance'] =  output_df.apply(\n",
    "            lambda x: levenshtein(x['tokenized_OriginalSRC-Trans'], x['tokenized_SRC_perturbed-Trans']), axis=1)\n",
    "        output_df[\"#TransChanges-#SrcChanges\"] = output_df['Trans-edit_distance'] - output_df['SRC-edit_distance']\n",
    "        \n",
    "        output_df[\"#TransChanges-#SrcChanges/SentenceLength\"] = (output_df['Trans-edit_distance'] - output_df['SRC-edit_distance']) / output_df['SRC'].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "        \n",
    "        output_df[\"ChangesSpread/SentenceLength\"] = output_df.apply(\n",
    "            lambda x: changes_spread(x['tokenized_OriginalSRC-Trans'], \n",
    "                                     x['tokenized_SRC_perturbed-Trans'], \n",
    "                                     x['opcodes']), axis=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # See if only two chunks within given max size are changed, \n",
    "        # and do some analysis on this special case\n",
    "        output_df['TwoChunksChanged'], output_df['ChunkDistance'], \\\n",
    "        output_df[\"is_same_subtree\"], output_df['changes_similarity'] \\\n",
    "            = zip(*output_df.apply(\n",
    "                lambda x: two_chunk_changed(x['tokenized_OriginalSRC-Trans'],\n",
    "                                            x['tokenized_SRC_perturbed-Trans'],\n",
    "                                            x['opcodes'],\n",
    "                                            chunk_max_length=chunk_max_length,\n",
    "                                            spacy_model=spacy_model,\n",
    "                                            w2v_model=w2v_model), axis=1\n",
    "            ))\n",
    "\n",
    "        \n",
    "        \n",
    "        if use_alignment:\n",
    "            # In the case where two changes occurs and the two similarities is calculated, \n",
    "            # find out which change is due to the perturbation\n",
    "            output_df['perturbed_trans_alignment'] = load_alignment(path_prefix)\n",
    "            output_df['changes_similarity'] = output_df.apply(\n",
    "                lambda x: add_reason_of_change(\n",
    "                    alignment=x['perturbed_trans_alignment'],\n",
    "                    changes=x['changes_similarity'],\n",
    "                    perturbed_src_word=x['perturbed_word']\n",
    "                ),\n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            if spacy_model is not None:\n",
    "                # Add POS tagging of the not-perturbed change\n",
    "                output_df['not_perturbed_TGT_change_type'] = output_df['changes_similarity'].apply(\n",
    "                    lambda x: pos_tag_not_perturbed_change(x, spacy_model))\n",
    "            \n",
    "        \n",
    "        # Analyse on group of changes on the same sentence\n",
    "        if no_of_replacements > 1:\n",
    "            additional_col_1 = output_df.groupby(by=\"SRC_index\", axis=0)[['Trans-edit_distance', '#TransChanges-#SrcChanges']].std()\n",
    "            additional_col_2 = output_df.groupby(by=\"SRC_index\", axis=0)[['TwoChunksChanged']].sum()\n",
    "            \n",
    "            output_df = output_df.join(additional_col_1, rsuffix='--SD')\n",
    "            output_df = output_df.join(additional_col_2, rsuffix='--total')\n",
    "        \n",
    "    return output_df\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6b86d1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_type = 'content'\n",
    "dataset = f'masked_{perturb_type}_covost2_for_en2de'  # 'MuST-SHE-en2fr' 'IWSLT15-en2vi' 'wmt19-newstest2019-en2de'\n",
    "beam = 5\n",
    "replacement_strategy = 'masking_language_model'\n",
    "no_of_replacements = 5\n",
    "ignore_case = False  # Only Europarls needs ignore case\n",
    "chunk_max_length=1\n",
    "spacy_model = spacy.load(\"de_core_news_sm\")\n",
    "# Loading these models in is time consuming\n",
    "# de_model = load_facebook_model(\"data/cc.de.300.bin\").wv\n",
    "# vi_model = load_facebook_model(\"data/cc.vi.300.bin\").wv\n",
    "winoMT = False\n",
    "\n",
    "# # This overwrite the above params\n",
    "# winoMT = True\n",
    "# perturb_type = 'pronoun'\n",
    "# no_of_replacements = 1\n",
    "\n",
    "output = read_output_df(dataset=dataset, perturb_type=perturb_type, beam=beam, \n",
    "                        replacement_strategy=replacement_strategy, ignore_case=ignore_case,\n",
    "                        no_of_replacements=no_of_replacements, chunk_max_length=chunk_max_length,\n",
    "                        spacy_model=spacy_model, w2v_model=de_model, use_alignment=True, \n",
    "                        winoMT=winoMT, analyse_feature=False)\n",
    "\n",
    "# print('BLEU score: ')\n",
    "# sacrebleu.corpus_bleu(output['OriginalSRC-Trans'].tolist(), [output['REF'].tolist()]).score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee09478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656b009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd93d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0048b3d1",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "- On `wmt19-newstest2019-en2de, chunk_max_length=2`\n",
    "    - 902: change to 1 SRC word leads to fixed changes of an irrelevant word\n",
    "    - In many cases, the form of the verb (e.g., current or past tense) are changed --> harmful in the sense that it hurt performance score?\n",
    "    - Word not being translated \n",
    "    - Spoken/written style\n",
    "    - Time\n",
    "    \n",
    "    \n",
    "- On `IWSLT15-en2vi, adjective`\n",
    "    - 1003: change of 1 words consistently leads to change in subject\n",
    "    \n",
    "    - 1003, 145, 990 noun: same\n",
    "    - 236 noun: same, funny but not sure if it is wrong\n",
    "    - 308 verb same \n",
    "    \n",
    "--> Quantify the verb form change by stemming/lemmatization\n",
    "    \n",
    "Chúng, họ, gã, cô ấy, cô ta, anh ta, hắn\n",
    "\n",
    "Changes in the word \"you\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3442d9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 9999999)\n",
    "# output[output['#TransChanges-#SrcChanges'] > 10].head(5)\n",
    "# output[output[\"ChangesSpread/SentenceLength\"] > 0.85].head(20)\n",
    "\n",
    "\n",
    "\n",
    "# Two chunks changed that consistently changed over the different replacement of a word\n",
    "\n",
    "\n",
    "# output[(output[\"TwoChunksChanged\"] == True) & (output[\"TwoChunksChanged--total\"] == 5)].sort_values(by='ChunkDistance', axis=0, ascending=False).head(1)\n",
    "# output[(output[\"TwoChunksChanged\"] == True)].sort_values(by='ChunkDistance', axis=0, ascending=False).head(100)\n",
    "\n",
    "# Two words changed that are not in the same subtree\n",
    "# output[(output[\"TwoChunksChanged\"] == True) & (output[\"is_same_subtree\"] == False) & (output[\"TwoChunksChanged--total\"] == 5)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# IWSLT15-en2vi, noun\n",
    "# output.loc[[1003, 145, 990, 236]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976bde7",
   "metadata": {},
   "source": [
    "Sort the samples by the least similarity in changed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e93bccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/10_vywcj3lb14yk3sn91jn3c0000gn/T/ipykernel_22756/1034888174.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  analyse_df['similarity_not_perturbed'] = analyse_df['changes_similarity'].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC</th>\n",
       "      <th>original_word</th>\n",
       "      <th>perturbed_word</th>\n",
       "      <th>OriginalSRC-Trans</th>\n",
       "      <th>SRC_perturbed-Trans</th>\n",
       "      <th>ChunkDistance</th>\n",
       "      <th>changes_similarity</th>\n",
       "      <th>similarity_not_perturbed</th>\n",
       "      <th>not_perturbed_TGT_change_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219367</th>\n",
       "      <td>There is neither customs nor police.</td>\n",
       "      <td>police</td>\n",
       "      <td>religion</td>\n",
       "      <td>Es gibt weder ZOLL noch POLIZEI .</td>\n",
       "      <td>Es gibt weder BRÄUCHE noch RELIGION .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Zoll', 'changed_word': 'Bräuche', 'semantic_similarity': 0.035544515, 'change_type': 'not_perturbed'}, {'original_word': 'Polizei', 'changed_word': 'Religion', 'semantic_similarity': 0.29982835, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.035545</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141244</th>\n",
       "      <td>He has wanted to become an accountant since he was a toddler, for he has always loved numbers.</td>\n",
       "      <td>accountant</td>\n",
       "      <td>astronaut</td>\n",
       "      <td>BUCHHALTER wollte ER werden , seit er ein Kleinkind war , denn Zahlen hat er schon immer geliebt .</td>\n",
       "      <td>ER wollte ASTRONAUT werden , seit er ein Kleinkind war , denn Zahlen hat er schon immer geliebt .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Buchhalter', 'changed_word': 'Er', 'semantic_similarity': 0.04772758, 'change_type': 'not_perturbed'}, {'original_word': 'er', 'changed_word': 'Astronaut', 'semantic_similarity': 0.10002759, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.047728</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219367</th>\n",
       "      <td>There is neither customs nor police.</td>\n",
       "      <td>police</td>\n",
       "      <td>language</td>\n",
       "      <td>Es gibt weder ZOLL noch POLIZEI .</td>\n",
       "      <td>Es gibt weder SITTEN noch SPRACHE .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Zoll', 'changed_word': 'Sitten', 'semantic_similarity': 0.089041315, 'change_type': 'not_perturbed'}, {'original_word': 'Polizei', 'changed_word': 'Sprache', 'semantic_similarity': 0.19356343, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.089041</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219367</th>\n",
       "      <td>There is neither customs nor police.</td>\n",
       "      <td>police</td>\n",
       "      <td>customs</td>\n",
       "      <td>Es gibt weder ZOLL noch POLIZEI .</td>\n",
       "      <td>Es gibt weder SITTEN noch GEBRÄUCHE .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Zoll', 'changed_word': 'Sitten', 'semantic_similarity': 0.089041315, 'change_type': 'not_perturbed'}, {'original_word': 'Polizei', 'changed_word': 'Gebräuche', 'semantic_similarity': 0.17014045, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.089041</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219367</th>\n",
       "      <td>There is neither customs nor police.</td>\n",
       "      <td>police</td>\n",
       "      <td>custom</td>\n",
       "      <td>Es gibt weder ZOLL noch POLIZEI .</td>\n",
       "      <td>Es gibt weder SITTEN noch GEBRÄUCHE .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Zoll', 'changed_word': 'Sitten', 'semantic_similarity': 0.089041315, 'change_type': 'not_perturbed'}, {'original_word': 'Polizei', 'changed_word': 'Gebräuche', 'semantic_similarity': 0.17014045, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.089041</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39174</th>\n",
       "      <td>“Do some of these fingerprints still exist?” Cyrus Smith asked.</td>\n",
       "      <td>smith</td>\n",
       "      <td>had</td>\n",
       "      <td>`` Gibt es noch einige dieser Fingerabdrücke ? `` , FRAGTE Cyrus SMITH .</td>\n",
       "      <td>`` Gibt es noch einige dieser Fingerabdrücke ? `` , HATTE Cyrus GEFRAGT .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'fragte', 'changed_word': 'hatte', 'semantic_similarity': 0.44320464, 'change_type': 'perturbed'}, {'original_word': 'Smith', 'changed_word': 'gefragt', 'semantic_similarity': 0.11342771, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.113428</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32968</th>\n",
       "      <td>“Is this man your servant?” Added the policeman, pointing at Passepartout.</td>\n",
       "      <td>policeman</td>\n",
       "      <td>man</td>\n",
       "      <td>`` Ist dieser Mann dein Diener ? `` , fügte der POLIZIST hinzu und zeigte auf den MANN .</td>\n",
       "      <td>`` Ist dieser Mann dein Diener ? `` , fügte der MANN hinzu und zeigte auf den PASSEPARTOUT .</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[{'original_word': 'Polizist', 'changed_word': 'Mann', 'semantic_similarity': 0.5838175, 'change_type': 'perturbed'}, {'original_word': 'Mann', 'changed_word': 'Passepartout', 'semantic_similarity': 0.16116506, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.161165</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156736</th>\n",
       "      <td>He is different from the mayor of Lice.</td>\n",
       "      <td>mayor</td>\n",
       "      <td>King</td>\n",
       "      <td>Er ist anders als der BÜRGERMEISTER von LICE .</td>\n",
       "      <td>Er ist anders als der KÖNIG von LÄUSEN .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Bürgermeister', 'changed_word': 'König', 'semantic_similarity': 0.41626397, 'change_type': 'perturbed'}, {'original_word': 'Lice', 'changed_word': 'Läusen', 'semantic_similarity': 0.18970576, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.189706</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156736</th>\n",
       "      <td>He is different from the mayor of Lice.</td>\n",
       "      <td>mayor</td>\n",
       "      <td>Prince</td>\n",
       "      <td>Er ist anders als der BÜRGERMEISTER von LICE .</td>\n",
       "      <td>Er ist anders als der PRINZ von LÄUSEN .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Bürgermeister', 'changed_word': 'Prinz', 'semantic_similarity': 0.35455632, 'change_type': 'perturbed'}, {'original_word': 'Lice', 'changed_word': 'Läusen', 'semantic_similarity': 0.18970576, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.189706</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48720</th>\n",
       "      <td>The wretch is a marvelous actress.</td>\n",
       "      <td>actress</td>\n",
       "      <td>species</td>\n",
       "      <td>Der BÖSEWICHT ist eine wunderbare SCHAUSPIELERIN .</td>\n",
       "      <td>Der WRACK ist eine wunderbare SPEZIES .</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{'original_word': 'Bösewicht', 'changed_word': 'Wrack', 'semantic_similarity': 0.19097787, 'change_type': 'not_perturbed'}, {'original_word': 'Schauspielerin', 'changed_word': 'Spezies', 'semantic_similarity': 0.15966544, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.190978</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64810</th>\n",
       "      <td>The wretch is a marvelous actress.</td>\n",
       "      <td>actress</td>\n",
       "      <td>species</td>\n",
       "      <td>Der BÖSEWICHT ist eine wunderbare SCHAUSPIELERIN .</td>\n",
       "      <td>Der WRACK ist eine wunderbare SPEZIES .</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{'original_word': 'Bösewicht', 'changed_word': 'Wrack', 'semantic_similarity': 0.19097787, 'change_type': 'not_perturbed'}, {'original_word': 'Schauspielerin', 'changed_word': 'Spezies', 'semantic_similarity': 0.15966544, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.190978</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98837</th>\n",
       "      <td>The wretch is a marvelous actress.</td>\n",
       "      <td>actress</td>\n",
       "      <td>species</td>\n",
       "      <td>Der BÖSEWICHT ist eine wunderbare SCHAUSPIELERIN .</td>\n",
       "      <td>Der WRACK ist eine wunderbare SPEZIES .</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{'original_word': 'Bösewicht', 'changed_word': 'Wrack', 'semantic_similarity': 0.19097787, 'change_type': 'not_perturbed'}, {'original_word': 'Schauspielerin', 'changed_word': 'Spezies', 'semantic_similarity': 0.15966544, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.190978</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>Orson Wells was the producer, editor, and often the cameraman.</td>\n",
       "      <td>producer</td>\n",
       "      <td>writer</td>\n",
       "      <td>Orson Wells war PRODUZENT , CUTTER und oft Kameramann .</td>\n",
       "      <td>Orson Wells war AUTOR , HERAUSGEBER und oft Kameramann .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Produzent', 'changed_word': 'Autor', 'semantic_similarity': 0.54234153, 'change_type': 'perturbed'}, {'original_word': 'Cutter', 'changed_word': 'Herausgeber', 'semantic_similarity': 0.19277786, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.192778</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137996</th>\n",
       "      <td>Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.</td>\n",
       "      <td>private</td>\n",
       "      <td>military</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom MILITÄRISCHEN Arsenal unabhängig waren .</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'militärischen', 'semantic_similarity': 0.5256801, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.206182</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137996</th>\n",
       "      <td>Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.</td>\n",
       "      <td>private</td>\n",
       "      <td>national</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom NATIONALEN Arsenal unabhängig waren .</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'nationalen', 'semantic_similarity': 0.528353, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.206182</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235217</th>\n",
       "      <td>Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.</td>\n",
       "      <td>private</td>\n",
       "      <td>national</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom NATIONALEN Arsenal unabhängig waren .</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'nationalen', 'semantic_similarity': 0.528353, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.206182</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235217</th>\n",
       "      <td>Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.</td>\n",
       "      <td>private</td>\n",
       "      <td>local</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom ÖRTLICHEN Arsenal unabhängig waren .</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'örtlichen', 'semantic_similarity': 0.5380845, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.206182</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80602</th>\n",
       "      <td>Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.</td>\n",
       "      <td>private</td>\n",
       "      <td>national</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom NATIONALEN Arsenal unabhängig waren .</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'nationalen', 'semantic_similarity': 0.528353, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.206182</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80602</th>\n",
       "      <td>Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.</td>\n",
       "      <td>private</td>\n",
       "      <td>military</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom MILITÄRISCHEN Arsenal unabhängig waren .</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'militärischen', 'semantic_similarity': 0.5256801, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.206182</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80602</th>\n",
       "      <td>Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.</td>\n",
       "      <td>private</td>\n",
       "      <td>local</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom ÖRTLICHEN Arsenal unabhängig waren .</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'örtlichen', 'semantic_similarity': 0.5380845, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.206182</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137996</th>\n",
       "      <td>Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.</td>\n",
       "      <td>private</td>\n",
       "      <td>local</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom ÖRTLICHEN Arsenal unabhängig waren .</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'örtlichen', 'semantic_similarity': 0.5380845, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.206182</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235217</th>\n",
       "      <td>Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.</td>\n",
       "      <td>private</td>\n",
       "      <td>military</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .</td>\n",
       "      <td>Vier Gênes &lt; unk &gt; KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom MILITÄRISCHEN Arsenal unabhängig waren .</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'militärischen', 'semantic_similarity': 0.5256801, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.206182</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>This model has a V-shaped front end with five horizontal bars.</td>\n",
       "      <td>model</td>\n",
       "      <td>car</td>\n",
       "      <td>Dieses MODELL hat eine V-förmige Front mit fünf horizontalen BALKEN .</td>\n",
       "      <td>Dieses AUTO hat eine V-förmige Front mit fünf horizontalen LENKER .</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[{'original_word': 'Modell', 'changed_word': 'Auto', 'semantic_similarity': 0.36193982, 'change_type': 'perturbed'}, {'original_word': 'Balken', 'changed_word': 'Lenker', 'semantic_similarity': 0.20761059, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.207611</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>This model has a V-shaped front end with five horizontal bars.</td>\n",
       "      <td>model</td>\n",
       "      <td>bike</td>\n",
       "      <td>Dieses MODELL hat eine V-förmige Front mit fünf horizontalen BALKEN .</td>\n",
       "      <td>Dieses FAHRRAD hat eine V-förmige Front mit fünf horizontalen LENKER .</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[{'original_word': 'Modell', 'changed_word': 'Fahrrad', 'semantic_similarity': 0.297343, 'change_type': 'perturbed'}, {'original_word': 'Balken', 'changed_word': 'Lenker', 'semantic_similarity': 0.20761059, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.207611</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48505</th>\n",
       "      <td>He was the one who introduced the singer Jain to music programming.</td>\n",
       "      <td>singer</td>\n",
       "      <td>director</td>\n",
       "      <td>Er war DERJENIGE , der den SÄNGER Jain in die Musikprogrammierung einführte .</td>\n",
       "      <td>Er war ES , der den REGISSEUR Jain in die Musikprogrammierung einführte .</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{'original_word': 'derjenige', 'changed_word': 'es', 'semantic_similarity': 0.22881213, 'change_type': 'not_perturbed'}, {'original_word': 'Sänger', 'changed_word': 'Regisseur', 'semantic_similarity': 0.5436518, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.228812</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212140</th>\n",
       "      <td>The chair therefore becomes the first industrial model of Thonet.</td>\n",
       "      <td>model</td>\n",
       "      <td>center</td>\n",
       "      <td>Der STUHL wird somit zum ersten industriellen MODELL von Thonet .</td>\n",
       "      <td>Der LEHRSTUHL wird somit zum ersten industriellen ZENTRUM von Thonet .</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[{'original_word': 'Stuhl', 'changed_word': 'Lehrstuhl', 'semantic_similarity': 0.24348769, 'change_type': 'not_perturbed'}, {'original_word': 'Modell', 'changed_word': 'Zentrum', 'semantic_similarity': 0.31339288, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.243488</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212140</th>\n",
       "      <td>The chair therefore becomes the first industrial model of Thonet.</td>\n",
       "      <td>model</td>\n",
       "      <td>centre</td>\n",
       "      <td>Der STUHL wird somit zum ersten industriellen MODELL von Thonet .</td>\n",
       "      <td>Der LEHRSTUHL wird somit zum ersten industriellen ZENTRUM von Thonet .</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[{'original_word': 'Stuhl', 'changed_word': 'Lehrstuhl', 'semantic_similarity': 0.24348769, 'change_type': 'not_perturbed'}, {'original_word': 'Modell', 'changed_word': 'Zentrum', 'semantic_similarity': 0.31339288, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.243488</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152269</th>\n",
       "      <td>He had no kindness, no sweetness, and followed this poor human game as a hunter.</td>\n",
       "      <td>hunter</td>\n",
       "      <td>friend</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als FREUND .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Freund', 'semantic_similarity': 0.38383695, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152269</th>\n",
       "      <td>He had no kindness, no sweetness, and followed this poor human game as a hunter.</td>\n",
       "      <td>hunter</td>\n",
       "      <td>man</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als MANN .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Mann', 'semantic_similarity': 0.43878055, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152269</th>\n",
       "      <td>He had no kindness, no sweetness, and followed this poor human game as a hunter.</td>\n",
       "      <td>hunter</td>\n",
       "      <td>child</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als KIND .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Kind', 'semantic_similarity': 0.21219897, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49876</th>\n",
       "      <td>He had no kindness, no sweetness, and followed this poor human game as a hunter.</td>\n",
       "      <td>hunter</td>\n",
       "      <td>friend</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als FREUND .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Freund', 'semantic_similarity': 0.38383695, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49876</th>\n",
       "      <td>He had no kindness, no sweetness, and followed this poor human game as a hunter.</td>\n",
       "      <td>hunter</td>\n",
       "      <td>man</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als MANN .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Mann', 'semantic_similarity': 0.43878055, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85658</th>\n",
       "      <td>He had no kindness, no sweetness, and followed this poor human game as a hunter.</td>\n",
       "      <td>hunter</td>\n",
       "      <td>child</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als KIND .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Kind', 'semantic_similarity': 0.21219897, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85658</th>\n",
       "      <td>He had no kindness, no sweetness, and followed this poor human game as a hunter.</td>\n",
       "      <td>hunter</td>\n",
       "      <td>man</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als MANN .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Mann', 'semantic_similarity': 0.43878055, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49876</th>\n",
       "      <td>He had no kindness, no sweetness, and followed this poor human game as a hunter.</td>\n",
       "      <td>hunter</td>\n",
       "      <td>human</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als MENSCH .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Mensch', 'semantic_similarity': 0.40144265, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85658</th>\n",
       "      <td>He had no kindness, no sweetness, and followed this poor human game as a hunter.</td>\n",
       "      <td>hunter</td>\n",
       "      <td>human</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als MENSCH .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Mensch', 'semantic_similarity': 0.40144265, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85658</th>\n",
       "      <td>He had no kindness, no sweetness, and followed this poor human game as a hunter.</td>\n",
       "      <td>hunter</td>\n",
       "      <td>friend</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als FREUND .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Freund', 'semantic_similarity': 0.38383695, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49876</th>\n",
       "      <td>He had no kindness, no sweetness, and followed this poor human game as a hunter.</td>\n",
       "      <td>hunter</td>\n",
       "      <td>child</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als KIND .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Kind', 'semantic_similarity': 0.21219897, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152269</th>\n",
       "      <td>He had no kindness, no sweetness, and followed this poor human game as a hunter.</td>\n",
       "      <td>hunter</td>\n",
       "      <td>human</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .</td>\n",
       "      <td>Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als MENSCH .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Mensch', 'semantic_similarity': 0.40144265, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254987</th>\n",
       "      <td>During his escapade, Tiger accidentally kills a policeman and succeeds in running away.</td>\n",
       "      <td>policeman</td>\n",
       "      <td>tiger</td>\n",
       "      <td>Während seiner FLUCHT tötet Tiger versehentlich einen POLIZISTEN und gelingt die Flucht .</td>\n",
       "      <td>Während seiner ESKAPADE tötet Tiger versehentlich einen TIGER und gelingt die Flucht .</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[{'original_word': 'Flucht', 'changed_word': 'Eskapade', 'semantic_similarity': 0.25353754, 'change_type': 'not_perturbed'}, {'original_word': 'Polizisten', 'changed_word': 'Tiger', 'semantic_similarity': 0.22833425, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.253538</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242017</th>\n",
       "      <td>Indeed, the United Kingdom being at war, we had to protect the ambassador and his suite.</td>\n",
       "      <td>ambassador</td>\n",
       "      <td>king</td>\n",
       "      <td>Da sich das Vereinigte Königreich im Krieg befand , mussten wir den BOTSCHAFTER und seine SUITE schützen .</td>\n",
       "      <td>Da sich das Vereinigte Königreich im Krieg befand , mussten wir den KÖNIG und seine FAMILIE schützen .</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[{'original_word': 'Botschafter', 'changed_word': 'König', 'semantic_similarity': 0.3978361, 'change_type': 'perturbed'}, {'original_word': 'Suite', 'changed_word': 'Familie', 'semantic_similarity': 0.26191437, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.261914</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242017</th>\n",
       "      <td>Indeed, the United Kingdom being at war, we had to protect the ambassador and his suite.</td>\n",
       "      <td>ambassador</td>\n",
       "      <td>King</td>\n",
       "      <td>Da sich das Vereinigte Königreich im Krieg befand , mussten wir den BOTSCHAFTER und seine SUITE schützen .</td>\n",
       "      <td>Da sich das Vereinigte Königreich im Krieg befand , mussten wir den KÖNIG und seine FAMILIE schützen .</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[{'original_word': 'Botschafter', 'changed_word': 'König', 'semantic_similarity': 0.3978361, 'change_type': 'perturbed'}, {'original_word': 'Suite', 'changed_word': 'Familie', 'semantic_similarity': 0.26191437, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.261914</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242017</th>\n",
       "      <td>Indeed, the United Kingdom being at war, we had to protect the ambassador and his suite.</td>\n",
       "      <td>ambassador</td>\n",
       "      <td>Prince</td>\n",
       "      <td>Da sich das Vereinigte Königreich im Krieg befand , mussten wir den BOTSCHAFTER und seine SUITE schützen .</td>\n",
       "      <td>Da sich das Vereinigte Königreich im Krieg befand , mussten wir den PRINZEN und seine FAMILIE schützen .</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[{'original_word': 'Botschafter', 'changed_word': 'Prinzen', 'semantic_similarity': 0.36753076, 'change_type': 'perturbed'}, {'original_word': 'Suite', 'changed_word': 'Familie', 'semantic_similarity': 0.26191437, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.261914</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242017</th>\n",
       "      <td>Indeed, the United Kingdom being at war, we had to protect the ambassador and his suite.</td>\n",
       "      <td>ambassador</td>\n",
       "      <td>duke</td>\n",
       "      <td>Da sich das Vereinigte Königreich im Krieg befand , mussten wir den BOTSCHAFTER und seine SUITE schützen .</td>\n",
       "      <td>Da sich das Vereinigte Königreich im Krieg befand , mussten wir den HERZOG und seine FAMILIE schützen .</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[{'original_word': 'Botschafter', 'changed_word': 'Herzog', 'semantic_similarity': 0.29214278, 'change_type': 'perturbed'}, {'original_word': 'Suite', 'changed_word': 'Familie', 'semantic_similarity': 0.26191437, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.261914</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189004</th>\n",
       "      <td>The soldier had started to desert.</td>\n",
       "      <td>soldier</td>\n",
       "      <td>sky</td>\n",
       "      <td>Der SOLDAT hatte begonnen zu DESERTIEREN .</td>\n",
       "      <td>Der HIMMEL hatte begonnen zu VERÖDEN .</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{'original_word': 'Soldat', 'changed_word': 'Himmel', 'semantic_similarity': 0.24751253, 'change_type': 'perturbed'}, {'original_word': 'desertieren', 'changed_word': 'veröden', 'semantic_similarity': 0.26221445, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.262214</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228972</th>\n",
       "      <td>The Captain isn’t up yet.</td>\n",
       "      <td>captain</td>\n",
       "      <td>moon</td>\n",
       "      <td>Der KAPITÄN ist noch nicht DURCH .</td>\n",
       "      <td>Der MOND ist noch nicht AUFGEGANGEN .</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{'original_word': 'Kapitän', 'changed_word': 'Mond', 'semantic_similarity': 0.2114605, 'change_type': 'perturbed'}, {'original_word': 'durch', 'changed_word': 'aufgegangen', 'semantic_similarity': 0.26565823, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.265658</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70696</th>\n",
       "      <td>The Brussels Historian, Mr Thierry Demey, the famous Guides Badeaux‘s author, is from his lineage.</td>\n",
       "      <td>author</td>\n",
       "      <td>historian</td>\n",
       "      <td>Der Brüsseler Historiker Thierry Demey , der berühmte AUTOR des RATGEBERS Badeaux , stammt aus seiner Abstammung .</td>\n",
       "      <td>Der Brüsseler Historiker Thierry Demey , der berühmte HISTORIKER des GUIDES Badeaux , stammt aus seiner Abstammung .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'original_word': 'Autor', 'changed_word': 'Historiker', 'semantic_similarity': 0.5524365, 'change_type': 'perturbed'}, {'original_word': 'Ratgebers', 'changed_word': 'Guides', 'semantic_similarity': 0.26626778, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>0.266268</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172289</th>\n",
       "      <td>Each stage is touched up by the artist.</td>\n",
       "      <td>artist</td>\n",
       "      <td>controller</td>\n",
       "      <td>Jede BÜHNE wird vom KÜNSTLER bearbeitet .</td>\n",
       "      <td>Jede STUFE wird vom CONTROLLER bearbeitet .</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[{'original_word': 'Bühne', 'changed_word': 'Stufe', 'semantic_similarity': 0.2781669, 'change_type': 'not_perturbed'}, {'original_word': 'Künstler', 'changed_word': 'Controller', 'semantic_similarity': 0.17256585, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.278167</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172289</th>\n",
       "      <td>Each stage is touched up by the artist.</td>\n",
       "      <td>artist</td>\n",
       "      <td>player</td>\n",
       "      <td>Jede BÜHNE wird vom KÜNSTLER bearbeitet .</td>\n",
       "      <td>Jede STUFE wird vom SPIELER bearbeitet .</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[{'original_word': 'Bühne', 'changed_word': 'Stufe', 'semantic_similarity': 0.2781669, 'change_type': 'not_perturbed'}, {'original_word': 'Künstler', 'changed_word': 'Spieler', 'semantic_similarity': 0.40883952, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.278167</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172289</th>\n",
       "      <td>Each stage is touched up by the artist.</td>\n",
       "      <td>artist</td>\n",
       "      <td>computer</td>\n",
       "      <td>Jede BÜHNE wird vom KÜNSTLER bearbeitet .</td>\n",
       "      <td>Jede STUFE wird vom COMPUTER bearbeitet .</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[{'original_word': 'Bühne', 'changed_word': 'Stufe', 'semantic_similarity': 0.2781669, 'change_type': 'not_perturbed'}, {'original_word': 'Künstler', 'changed_word': 'Computer', 'semantic_similarity': 0.24020451, 'change_type': 'perturbed'}]</td>\n",
       "      <td>0.278167</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       SRC  \\\n",
       "219367                                                                There is neither customs nor police.   \n",
       "141244      He has wanted to become an accountant since he was a toddler, for he has always loved numbers.   \n",
       "219367                                                                There is neither customs nor police.   \n",
       "219367                                                                There is neither customs nor police.   \n",
       "219367                                                                There is neither customs nor police.   \n",
       "39174                                      “Do some of these fingerprints still exist?” Cyrus Smith asked.   \n",
       "32968                           “Is this man your servant?” Added the policeman, pointing at Passepartout.   \n",
       "156736                                                             He is different from the mayor of Lice.   \n",
       "156736                                                             He is different from the mayor of Lice.   \n",
       "48720                                                                   The wretch is a marvelous actress.   \n",
       "64810                                                                   The wretch is a marvelous actress.   \n",
       "98837                                                                   The wretch is a marvelous actress.   \n",
       "3783                                        Orson Wells was the producer, editor, and often the cameraman.   \n",
       "137996  Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.   \n",
       "137996  Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.   \n",
       "235217  Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.   \n",
       "235217  Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.   \n",
       "80602   Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.   \n",
       "80602   Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.   \n",
       "80602   Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.   \n",
       "137996  Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.   \n",
       "235217  Four Gênes’ commune had, then, six hundred and seventy sails independent from the private arsenal.   \n",
       "4739                                        This model has a V-shaped front end with five horizontal bars.   \n",
       "4739                                        This model has a V-shaped front end with five horizontal bars.   \n",
       "48505                                  He was the one who introduced the singer Jain to music programming.   \n",
       "212140                                   The chair therefore becomes the first industrial model of Thonet.   \n",
       "212140                                   The chair therefore becomes the first industrial model of Thonet.   \n",
       "152269                    He had no kindness, no sweetness, and followed this poor human game as a hunter.   \n",
       "152269                    He had no kindness, no sweetness, and followed this poor human game as a hunter.   \n",
       "152269                    He had no kindness, no sweetness, and followed this poor human game as a hunter.   \n",
       "49876                     He had no kindness, no sweetness, and followed this poor human game as a hunter.   \n",
       "49876                     He had no kindness, no sweetness, and followed this poor human game as a hunter.   \n",
       "85658                     He had no kindness, no sweetness, and followed this poor human game as a hunter.   \n",
       "85658                     He had no kindness, no sweetness, and followed this poor human game as a hunter.   \n",
       "49876                     He had no kindness, no sweetness, and followed this poor human game as a hunter.   \n",
       "85658                     He had no kindness, no sweetness, and followed this poor human game as a hunter.   \n",
       "85658                     He had no kindness, no sweetness, and followed this poor human game as a hunter.   \n",
       "49876                     He had no kindness, no sweetness, and followed this poor human game as a hunter.   \n",
       "152269                    He had no kindness, no sweetness, and followed this poor human game as a hunter.   \n",
       "254987             During his escapade, Tiger accidentally kills a policeman and succeeds in running away.   \n",
       "242017            Indeed, the United Kingdom being at war, we had to protect the ambassador and his suite.   \n",
       "242017            Indeed, the United Kingdom being at war, we had to protect the ambassador and his suite.   \n",
       "242017            Indeed, the United Kingdom being at war, we had to protect the ambassador and his suite.   \n",
       "242017            Indeed, the United Kingdom being at war, we had to protect the ambassador and his suite.   \n",
       "189004                                                                  The soldier had started to desert.   \n",
       "228972                                                                           The Captain isn’t up yet.   \n",
       "70696   The Brussels Historian, Mr Thierry Demey, the famous Guides Badeaux‘s author, is from his lineage.   \n",
       "172289                                                             Each stage is touched up by the artist.   \n",
       "172289                                                             Each stage is touched up by the artist.   \n",
       "172289                                                             Each stage is touched up by the artist.   \n",
       "\n",
       "       original_word perturbed_word  \\\n",
       "219367        police       religion   \n",
       "141244    accountant      astronaut   \n",
       "219367        police       language   \n",
       "219367        police        customs   \n",
       "219367        police         custom   \n",
       "39174          smith            had   \n",
       "32968      policeman            man   \n",
       "156736         mayor           King   \n",
       "156736         mayor         Prince   \n",
       "48720        actress        species   \n",
       "64810        actress        species   \n",
       "98837        actress        species   \n",
       "3783        producer         writer   \n",
       "137996       private       military   \n",
       "137996       private       national   \n",
       "235217       private       national   \n",
       "235217       private          local   \n",
       "80602        private       national   \n",
       "80602        private       military   \n",
       "80602        private          local   \n",
       "137996       private          local   \n",
       "235217       private       military   \n",
       "4739           model            car   \n",
       "4739           model           bike   \n",
       "48505         singer       director   \n",
       "212140         model         center   \n",
       "212140         model         centre   \n",
       "152269        hunter         friend   \n",
       "152269        hunter            man   \n",
       "152269        hunter          child   \n",
       "49876         hunter         friend   \n",
       "49876         hunter            man   \n",
       "85658         hunter          child   \n",
       "85658         hunter            man   \n",
       "49876         hunter          human   \n",
       "85658         hunter          human   \n",
       "85658         hunter         friend   \n",
       "49876         hunter          child   \n",
       "152269        hunter          human   \n",
       "254987     policeman          tiger   \n",
       "242017    ambassador           king   \n",
       "242017    ambassador           King   \n",
       "242017    ambassador         Prince   \n",
       "242017    ambassador           duke   \n",
       "189004       soldier            sky   \n",
       "228972       captain           moon   \n",
       "70696         author      historian   \n",
       "172289        artist     controller   \n",
       "172289        artist         player   \n",
       "172289        artist       computer   \n",
       "\n",
       "                                                                                                               OriginalSRC-Trans  \\\n",
       "219367                                                                                         Es gibt weder ZOLL noch POLIZEI .   \n",
       "141244                        BUCHHALTER wollte ER werden , seit er ein Kleinkind war , denn Zahlen hat er schon immer geliebt .   \n",
       "219367                                                                                         Es gibt weder ZOLL noch POLIZEI .   \n",
       "219367                                                                                         Es gibt weder ZOLL noch POLIZEI .   \n",
       "219367                                                                                         Es gibt weder ZOLL noch POLIZEI .   \n",
       "39174                                                   `` Gibt es noch einige dieser Fingerabdrücke ? `` , FRAGTE Cyrus SMITH .   \n",
       "32968                                   `` Ist dieser Mann dein Diener ? `` , fügte der POLIZIST hinzu und zeigte auf den MANN .   \n",
       "156736                                                                            Er ist anders als der BÜRGERMEISTER von LICE .   \n",
       "156736                                                                            Er ist anders als der BÜRGERMEISTER von LICE .   \n",
       "48720                                                                         Der BÖSEWICHT ist eine wunderbare SCHAUSPIELERIN .   \n",
       "64810                                                                         Der BÖSEWICHT ist eine wunderbare SCHAUSPIELERIN .   \n",
       "98837                                                                         Der BÖSEWICHT ist eine wunderbare SCHAUSPIELERIN .   \n",
       "3783                                                                     Orson Wells war PRODUZENT , CUTTER und oft Kameramann .   \n",
       "137996  Vier Gênes < unk > COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .   \n",
       "137996  Vier Gênes < unk > COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .   \n",
       "235217  Vier Gênes < unk > COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .   \n",
       "235217  Vier Gênes < unk > COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .   \n",
       "80602   Vier Gênes < unk > COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .   \n",
       "80602   Vier Gênes < unk > COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .   \n",
       "80602   Vier Gênes < unk > COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .   \n",
       "137996  Vier Gênes < unk > COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .   \n",
       "235217  Vier Gênes < unk > COMMUNE verfügten damals über sechshundertsiebzig Segel , die vom PRIVATEN Arsenal unabhängig waren .   \n",
       "4739                                                       Dieses MODELL hat eine V-förmige Front mit fünf horizontalen BALKEN .   \n",
       "4739                                                       Dieses MODELL hat eine V-förmige Front mit fünf horizontalen BALKEN .   \n",
       "48505                                              Er war DERJENIGE , der den SÄNGER Jain in die Musikprogrammierung einführte .   \n",
       "212140                                                         Der STUHL wird somit zum ersten industriellen MODELL von Thonet .   \n",
       "212140                                                         Der STUHL wird somit zum ersten industriellen MODELL von Thonet .   \n",
       "152269                                   Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .   \n",
       "152269                                   Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .   \n",
       "152269                                   Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .   \n",
       "49876                                    Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .   \n",
       "49876                                    Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .   \n",
       "85658                                    Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .   \n",
       "85658                                    Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .   \n",
       "49876                                    Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .   \n",
       "85658                                    Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .   \n",
       "85658                                    Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .   \n",
       "49876                                    Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .   \n",
       "152269                                   Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche WILD als JÄGER .   \n",
       "254987                                 Während seiner FLUCHT tötet Tiger versehentlich einen POLIZISTEN und gelingt die Flucht .   \n",
       "242017                Da sich das Vereinigte Königreich im Krieg befand , mussten wir den BOTSCHAFTER und seine SUITE schützen .   \n",
       "242017                Da sich das Vereinigte Königreich im Krieg befand , mussten wir den BOTSCHAFTER und seine SUITE schützen .   \n",
       "242017                Da sich das Vereinigte Königreich im Krieg befand , mussten wir den BOTSCHAFTER und seine SUITE schützen .   \n",
       "242017                Da sich das Vereinigte Königreich im Krieg befand , mussten wir den BOTSCHAFTER und seine SUITE schützen .   \n",
       "189004                                                                                Der SOLDAT hatte begonnen zu DESERTIEREN .   \n",
       "228972                                                                                        Der KAPITÄN ist noch nicht DURCH .   \n",
       "70696         Der Brüsseler Historiker Thierry Demey , der berühmte AUTOR des RATGEBERS Badeaux , stammt aus seiner Abstammung .   \n",
       "172289                                                                                 Jede BÜHNE wird vom KÜNSTLER bearbeitet .   \n",
       "172289                                                                                 Jede BÜHNE wird vom KÜNSTLER bearbeitet .   \n",
       "172289                                                                                 Jede BÜHNE wird vom KÜNSTLER bearbeitet .   \n",
       "\n",
       "                                                                                                                   SRC_perturbed-Trans  \\\n",
       "219367                                                                                           Es gibt weder BRÄUCHE noch RELIGION .   \n",
       "141244                               ER wollte ASTRONAUT werden , seit er ein Kleinkind war , denn Zahlen hat er schon immer geliebt .   \n",
       "219367                                                                                             Es gibt weder SITTEN noch SPRACHE .   \n",
       "219367                                                                                           Es gibt weder SITTEN noch GEBRÄUCHE .   \n",
       "219367                                                                                           Es gibt weder SITTEN noch GEBRÄUCHE .   \n",
       "39174                                                        `` Gibt es noch einige dieser Fingerabdrücke ? `` , HATTE Cyrus GEFRAGT .   \n",
       "32968                                     `` Ist dieser Mann dein Diener ? `` , fügte der MANN hinzu und zeigte auf den PASSEPARTOUT .   \n",
       "156736                                                                                        Er ist anders als der KÖNIG von LÄUSEN .   \n",
       "156736                                                                                        Er ist anders als der PRINZ von LÄUSEN .   \n",
       "48720                                                                                          Der WRACK ist eine wunderbare SPEZIES .   \n",
       "64810                                                                                          Der WRACK ist eine wunderbare SPEZIES .   \n",
       "98837                                                                                          Der WRACK ist eine wunderbare SPEZIES .   \n",
       "3783                                                                          Orson Wells war AUTOR , HERAUSGEBER und oft Kameramann .   \n",
       "137996  Vier Gênes < unk > KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom MILITÄRISCHEN Arsenal unabhängig waren .   \n",
       "137996     Vier Gênes < unk > KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom NATIONALEN Arsenal unabhängig waren .   \n",
       "235217     Vier Gênes < unk > KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom NATIONALEN Arsenal unabhängig waren .   \n",
       "235217      Vier Gênes < unk > KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom ÖRTLICHEN Arsenal unabhängig waren .   \n",
       "80602      Vier Gênes < unk > KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom NATIONALEN Arsenal unabhängig waren .   \n",
       "80602   Vier Gênes < unk > KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom MILITÄRISCHEN Arsenal unabhängig waren .   \n",
       "80602       Vier Gênes < unk > KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom ÖRTLICHEN Arsenal unabhängig waren .   \n",
       "137996      Vier Gênes < unk > KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom ÖRTLICHEN Arsenal unabhängig waren .   \n",
       "235217  Vier Gênes < unk > KOMMUNEN verfügten damals über sechshundertsiebzig Segel , die vom MILITÄRISCHEN Arsenal unabhängig waren .   \n",
       "4739                                                               Dieses AUTO hat eine V-förmige Front mit fünf horizontalen LENKER .   \n",
       "4739                                                            Dieses FAHRRAD hat eine V-förmige Front mit fünf horizontalen LENKER .   \n",
       "48505                                                        Er war ES , der den REGISSEUR Jain in die Musikprogrammierung einführte .   \n",
       "212140                                                          Der LEHRSTUHL wird somit zum ersten industriellen ZENTRUM von Thonet .   \n",
       "212140                                                          Der LEHRSTUHL wird somit zum ersten industriellen ZENTRUM von Thonet .   \n",
       "152269                                       Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als FREUND .   \n",
       "152269                                         Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als MANN .   \n",
       "152269                                         Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als KIND .   \n",
       "49876                                        Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als FREUND .   \n",
       "49876                                          Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als MANN .   \n",
       "85658                                          Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als KIND .   \n",
       "85658                                          Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als MANN .   \n",
       "49876                                        Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als MENSCH .   \n",
       "85658                                        Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als MENSCH .   \n",
       "85658                                        Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als FREUND .   \n",
       "49876                                          Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als KIND .   \n",
       "152269                                       Er hatte keine Güte , keine Süße und verfolgte dieses arme menschliche SPIEL als MENSCH .   \n",
       "254987                                          Während seiner ESKAPADE tötet Tiger versehentlich einen TIGER und gelingt die Flucht .   \n",
       "242017                          Da sich das Vereinigte Königreich im Krieg befand , mussten wir den KÖNIG und seine FAMILIE schützen .   \n",
       "242017                          Da sich das Vereinigte Königreich im Krieg befand , mussten wir den KÖNIG und seine FAMILIE schützen .   \n",
       "242017                        Da sich das Vereinigte Königreich im Krieg befand , mussten wir den PRINZEN und seine FAMILIE schützen .   \n",
       "242017                         Da sich das Vereinigte Königreich im Krieg befand , mussten wir den HERZOG und seine FAMILIE schützen .   \n",
       "189004                                                                                          Der HIMMEL hatte begonnen zu VERÖDEN .   \n",
       "228972                                                                                           Der MOND ist noch nicht AUFGEGANGEN .   \n",
       "70696             Der Brüsseler Historiker Thierry Demey , der berühmte HISTORIKER des GUIDES Badeaux , stammt aus seiner Abstammung .   \n",
       "172289                                                                                     Jede STUFE wird vom CONTROLLER bearbeitet .   \n",
       "172289                                                                                        Jede STUFE wird vom SPIELER bearbeitet .   \n",
       "172289                                                                                       Jede STUFE wird vom COMPUTER bearbeitet .   \n",
       "\n",
       "        ChunkDistance  \\\n",
       "219367            1.0   \n",
       "141244            1.0   \n",
       "219367            1.0   \n",
       "219367            1.0   \n",
       "219367            1.0   \n",
       "39174             1.0   \n",
       "32968             5.0   \n",
       "156736            1.0   \n",
       "156736            1.0   \n",
       "48720             3.0   \n",
       "64810             3.0   \n",
       "98837             3.0   \n",
       "3783              1.0   \n",
       "137996            8.0   \n",
       "137996            8.0   \n",
       "235217            8.0   \n",
       "235217            8.0   \n",
       "80602             8.0   \n",
       "80602             8.0   \n",
       "80602             8.0   \n",
       "137996            8.0   \n",
       "235217            8.0   \n",
       "4739              7.0   \n",
       "4739              7.0   \n",
       "48505             3.0   \n",
       "212140            5.0   \n",
       "212140            5.0   \n",
       "152269            1.0   \n",
       "152269            1.0   \n",
       "152269            1.0   \n",
       "49876             1.0   \n",
       "49876             1.0   \n",
       "85658             1.0   \n",
       "85658             1.0   \n",
       "49876             1.0   \n",
       "85658             1.0   \n",
       "85658             1.0   \n",
       "49876             1.0   \n",
       "152269            1.0   \n",
       "254987            4.0   \n",
       "242017            2.0   \n",
       "242017            2.0   \n",
       "242017            2.0   \n",
       "242017            2.0   \n",
       "189004            3.0   \n",
       "228972            3.0   \n",
       "70696             1.0   \n",
       "172289            2.0   \n",
       "172289            2.0   \n",
       "172289            2.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                 changes_similarity  \\\n",
       "219367          [{'original_word': 'Zoll', 'changed_word': 'Bräuche', 'semantic_similarity': 0.035544515, 'change_type': 'not_perturbed'}, {'original_word': 'Polizei', 'changed_word': 'Religion', 'semantic_similarity': 0.29982835, 'change_type': 'perturbed'}]   \n",
       "141244              [{'original_word': 'Buchhalter', 'changed_word': 'Er', 'semantic_similarity': 0.04772758, 'change_type': 'not_perturbed'}, {'original_word': 'er', 'changed_word': 'Astronaut', 'semantic_similarity': 0.10002759, 'change_type': 'perturbed'}]   \n",
       "219367            [{'original_word': 'Zoll', 'changed_word': 'Sitten', 'semantic_similarity': 0.089041315, 'change_type': 'not_perturbed'}, {'original_word': 'Polizei', 'changed_word': 'Sprache', 'semantic_similarity': 0.19356343, 'change_type': 'perturbed'}]   \n",
       "219367          [{'original_word': 'Zoll', 'changed_word': 'Sitten', 'semantic_similarity': 0.089041315, 'change_type': 'not_perturbed'}, {'original_word': 'Polizei', 'changed_word': 'Gebräuche', 'semantic_similarity': 0.17014045, 'change_type': 'perturbed'}]   \n",
       "219367          [{'original_word': 'Zoll', 'changed_word': 'Sitten', 'semantic_similarity': 0.089041315, 'change_type': 'not_perturbed'}, {'original_word': 'Polizei', 'changed_word': 'Gebräuche', 'semantic_similarity': 0.17014045, 'change_type': 'perturbed'}]   \n",
       "39174               [{'original_word': 'fragte', 'changed_word': 'hatte', 'semantic_similarity': 0.44320464, 'change_type': 'perturbed'}, {'original_word': 'Smith', 'changed_word': 'gefragt', 'semantic_similarity': 0.11342771, 'change_type': 'not_perturbed'}]   \n",
       "32968           [{'original_word': 'Polizist', 'changed_word': 'Mann', 'semantic_similarity': 0.5838175, 'change_type': 'perturbed'}, {'original_word': 'Mann', 'changed_word': 'Passepartout', 'semantic_similarity': 0.16116506, 'change_type': 'not_perturbed'}]   \n",
       "156736         [{'original_word': 'Bürgermeister', 'changed_word': 'König', 'semantic_similarity': 0.41626397, 'change_type': 'perturbed'}, {'original_word': 'Lice', 'changed_word': 'Läusen', 'semantic_similarity': 0.18970576, 'change_type': 'not_perturbed'}]   \n",
       "156736         [{'original_word': 'Bürgermeister', 'changed_word': 'Prinz', 'semantic_similarity': 0.35455632, 'change_type': 'perturbed'}, {'original_word': 'Lice', 'changed_word': 'Läusen', 'semantic_similarity': 0.18970576, 'change_type': 'not_perturbed'}]   \n",
       "48720   [{'original_word': 'Bösewicht', 'changed_word': 'Wrack', 'semantic_similarity': 0.19097787, 'change_type': 'not_perturbed'}, {'original_word': 'Schauspielerin', 'changed_word': 'Spezies', 'semantic_similarity': 0.15966544, 'change_type': 'perturbed'}]   \n",
       "64810   [{'original_word': 'Bösewicht', 'changed_word': 'Wrack', 'semantic_similarity': 0.19097787, 'change_type': 'not_perturbed'}, {'original_word': 'Schauspielerin', 'changed_word': 'Spezies', 'semantic_similarity': 0.15966544, 'change_type': 'perturbed'}]   \n",
       "98837   [{'original_word': 'Bösewicht', 'changed_word': 'Wrack', 'semantic_similarity': 0.19097787, 'change_type': 'not_perturbed'}, {'original_word': 'Schauspielerin', 'changed_word': 'Spezies', 'semantic_similarity': 0.15966544, 'change_type': 'perturbed'}]   \n",
       "3783        [{'original_word': 'Produzent', 'changed_word': 'Autor', 'semantic_similarity': 0.54234153, 'change_type': 'perturbed'}, {'original_word': 'Cutter', 'changed_word': 'Herausgeber', 'semantic_similarity': 0.19277786, 'change_type': 'not_perturbed'}]   \n",
       "137996   [{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'militärischen', 'semantic_similarity': 0.5256801, 'change_type': 'perturbed'}]   \n",
       "137996       [{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'nationalen', 'semantic_similarity': 0.528353, 'change_type': 'perturbed'}]   \n",
       "235217       [{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'nationalen', 'semantic_similarity': 0.528353, 'change_type': 'perturbed'}]   \n",
       "235217       [{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'örtlichen', 'semantic_similarity': 0.5380845, 'change_type': 'perturbed'}]   \n",
       "80602        [{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'nationalen', 'semantic_similarity': 0.528353, 'change_type': 'perturbed'}]   \n",
       "80602    [{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'militärischen', 'semantic_similarity': 0.5256801, 'change_type': 'perturbed'}]   \n",
       "80602        [{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'örtlichen', 'semantic_similarity': 0.5380845, 'change_type': 'perturbed'}]   \n",
       "137996       [{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'örtlichen', 'semantic_similarity': 0.5380845, 'change_type': 'perturbed'}]   \n",
       "235217   [{'original_word': 'commune', 'changed_word': 'kommunen', 'semantic_similarity': 0.2061818, 'change_type': 'not_perturbed'}, {'original_word': 'privaten', 'changed_word': 'militärischen', 'semantic_similarity': 0.5256801, 'change_type': 'perturbed'}]   \n",
       "4739                 [{'original_word': 'Modell', 'changed_word': 'Auto', 'semantic_similarity': 0.36193982, 'change_type': 'perturbed'}, {'original_word': 'Balken', 'changed_word': 'Lenker', 'semantic_similarity': 0.20761059, 'change_type': 'not_perturbed'}]   \n",
       "4739                [{'original_word': 'Modell', 'changed_word': 'Fahrrad', 'semantic_similarity': 0.297343, 'change_type': 'perturbed'}, {'original_word': 'Balken', 'changed_word': 'Lenker', 'semantic_similarity': 0.20761059, 'change_type': 'not_perturbed'}]   \n",
       "48505             [{'original_word': 'derjenige', 'changed_word': 'es', 'semantic_similarity': 0.22881213, 'change_type': 'not_perturbed'}, {'original_word': 'Sänger', 'changed_word': 'Regisseur', 'semantic_similarity': 0.5436518, 'change_type': 'perturbed'}]   \n",
       "212140          [{'original_word': 'Stuhl', 'changed_word': 'Lehrstuhl', 'semantic_similarity': 0.24348769, 'change_type': 'not_perturbed'}, {'original_word': 'Modell', 'changed_word': 'Zentrum', 'semantic_similarity': 0.31339288, 'change_type': 'perturbed'}]   \n",
       "212140          [{'original_word': 'Stuhl', 'changed_word': 'Lehrstuhl', 'semantic_similarity': 0.24348769, 'change_type': 'not_perturbed'}, {'original_word': 'Modell', 'changed_word': 'Zentrum', 'semantic_similarity': 0.31339288, 'change_type': 'perturbed'}]   \n",
       "152269                  [{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Freund', 'semantic_similarity': 0.38383695, 'change_type': 'perturbed'}]   \n",
       "152269                    [{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Mann', 'semantic_similarity': 0.43878055, 'change_type': 'perturbed'}]   \n",
       "152269                    [{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Kind', 'semantic_similarity': 0.21219897, 'change_type': 'perturbed'}]   \n",
       "49876                   [{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Freund', 'semantic_similarity': 0.38383695, 'change_type': 'perturbed'}]   \n",
       "49876                     [{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Mann', 'semantic_similarity': 0.43878055, 'change_type': 'perturbed'}]   \n",
       "85658                     [{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Kind', 'semantic_similarity': 0.21219897, 'change_type': 'perturbed'}]   \n",
       "85658                     [{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Mann', 'semantic_similarity': 0.43878055, 'change_type': 'perturbed'}]   \n",
       "49876                   [{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Mensch', 'semantic_similarity': 0.40144265, 'change_type': 'perturbed'}]   \n",
       "85658                   [{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Mensch', 'semantic_similarity': 0.40144265, 'change_type': 'perturbed'}]   \n",
       "85658                   [{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Freund', 'semantic_similarity': 0.38383695, 'change_type': 'perturbed'}]   \n",
       "49876                     [{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Kind', 'semantic_similarity': 0.21219897, 'change_type': 'perturbed'}]   \n",
       "152269                  [{'original_word': 'Wild', 'changed_word': 'Spiel', 'semantic_similarity': 0.2450445, 'change_type': 'not_perturbed'}, {'original_word': 'Jäger', 'changed_word': 'Mensch', 'semantic_similarity': 0.40144265, 'change_type': 'perturbed'}]   \n",
       "254987        [{'original_word': 'Flucht', 'changed_word': 'Eskapade', 'semantic_similarity': 0.25353754, 'change_type': 'not_perturbed'}, {'original_word': 'Polizisten', 'changed_word': 'Tiger', 'semantic_similarity': 0.22833425, 'change_type': 'perturbed'}]   \n",
       "242017          [{'original_word': 'Botschafter', 'changed_word': 'König', 'semantic_similarity': 0.3978361, 'change_type': 'perturbed'}, {'original_word': 'Suite', 'changed_word': 'Familie', 'semantic_similarity': 0.26191437, 'change_type': 'not_perturbed'}]   \n",
       "242017          [{'original_word': 'Botschafter', 'changed_word': 'König', 'semantic_similarity': 0.3978361, 'change_type': 'perturbed'}, {'original_word': 'Suite', 'changed_word': 'Familie', 'semantic_similarity': 0.26191437, 'change_type': 'not_perturbed'}]   \n",
       "242017       [{'original_word': 'Botschafter', 'changed_word': 'Prinzen', 'semantic_similarity': 0.36753076, 'change_type': 'perturbed'}, {'original_word': 'Suite', 'changed_word': 'Familie', 'semantic_similarity': 0.26191437, 'change_type': 'not_perturbed'}]   \n",
       "242017        [{'original_word': 'Botschafter', 'changed_word': 'Herzog', 'semantic_similarity': 0.29214278, 'change_type': 'perturbed'}, {'original_word': 'Suite', 'changed_word': 'Familie', 'semantic_similarity': 0.26191437, 'change_type': 'not_perturbed'}]   \n",
       "189004       [{'original_word': 'Soldat', 'changed_word': 'Himmel', 'semantic_similarity': 0.24751253, 'change_type': 'perturbed'}, {'original_word': 'desertieren', 'changed_word': 'veröden', 'semantic_similarity': 0.26221445, 'change_type': 'not_perturbed'}]   \n",
       "228972           [{'original_word': 'Kapitän', 'changed_word': 'Mond', 'semantic_similarity': 0.2114605, 'change_type': 'perturbed'}, {'original_word': 'durch', 'changed_word': 'aufgegangen', 'semantic_similarity': 0.26565823, 'change_type': 'not_perturbed'}]   \n",
       "70696         [{'original_word': 'Autor', 'changed_word': 'Historiker', 'semantic_similarity': 0.5524365, 'change_type': 'perturbed'}, {'original_word': 'Ratgebers', 'changed_word': 'Guides', 'semantic_similarity': 0.26626778, 'change_type': 'not_perturbed'}]   \n",
       "172289          [{'original_word': 'Bühne', 'changed_word': 'Stufe', 'semantic_similarity': 0.2781669, 'change_type': 'not_perturbed'}, {'original_word': 'Künstler', 'changed_word': 'Controller', 'semantic_similarity': 0.17256585, 'change_type': 'perturbed'}]   \n",
       "172289             [{'original_word': 'Bühne', 'changed_word': 'Stufe', 'semantic_similarity': 0.2781669, 'change_type': 'not_perturbed'}, {'original_word': 'Künstler', 'changed_word': 'Spieler', 'semantic_similarity': 0.40883952, 'change_type': 'perturbed'}]   \n",
       "172289            [{'original_word': 'Bühne', 'changed_word': 'Stufe', 'semantic_similarity': 0.2781669, 'change_type': 'not_perturbed'}, {'original_word': 'Künstler', 'changed_word': 'Computer', 'semantic_similarity': 0.24020451, 'change_type': 'perturbed'}]   \n",
       "\n",
       "        similarity_not_perturbed not_perturbed_TGT_change_type  \n",
       "219367                  0.035545                          NOUN  \n",
       "141244                  0.047728                          PRON  \n",
       "219367                  0.089041                          NOUN  \n",
       "219367                  0.089041                          NOUN  \n",
       "219367                  0.089041                          NOUN  \n",
       "39174                   0.113428                          VERB  \n",
       "32968                   0.161165                          NOUN  \n",
       "156736                  0.189706                          NOUN  \n",
       "156736                  0.189706                          NOUN  \n",
       "48720                   0.190978                          NOUN  \n",
       "64810                   0.190978                          NOUN  \n",
       "98837                   0.190978                          NOUN  \n",
       "3783                    0.192778                          NOUN  \n",
       "137996                  0.206182                          NOUN  \n",
       "137996                  0.206182                          NOUN  \n",
       "235217                  0.206182                          NOUN  \n",
       "235217                  0.206182                          NOUN  \n",
       "80602                   0.206182                          NOUN  \n",
       "80602                   0.206182                          NOUN  \n",
       "80602                   0.206182                          NOUN  \n",
       "137996                  0.206182                          NOUN  \n",
       "235217                  0.206182                          NOUN  \n",
       "4739                    0.207611                          NOUN  \n",
       "4739                    0.207611                          NOUN  \n",
       "48505                   0.228812                          PRON  \n",
       "212140                  0.243488                          NOUN  \n",
       "212140                  0.243488                          NOUN  \n",
       "152269                  0.245044                          NOUN  \n",
       "152269                  0.245044                          NOUN  \n",
       "152269                  0.245044                          NOUN  \n",
       "49876                   0.245044                          NOUN  \n",
       "49876                   0.245044                          NOUN  \n",
       "85658                   0.245044                          NOUN  \n",
       "85658                   0.245044                          NOUN  \n",
       "49876                   0.245044                          NOUN  \n",
       "85658                   0.245044                          NOUN  \n",
       "85658                   0.245044                          NOUN  \n",
       "49876                   0.245044                          NOUN  \n",
       "152269                  0.245044                          NOUN  \n",
       "254987                  0.253538                          NOUN  \n",
       "242017                  0.261914                          NOUN  \n",
       "242017                  0.261914                          NOUN  \n",
       "242017                  0.261914                          NOUN  \n",
       "242017                  0.261914                          NOUN  \n",
       "189004                  0.262214                           ADJ  \n",
       "228972                  0.265658                          VERB  \n",
       "70696                   0.266268                          NOUN  \n",
       "172289                  0.278167                          NOUN  \n",
       "172289                  0.278167                          NOUN  \n",
       "172289                  0.278167                          NOUN  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out the 2-word-changed cases and similarity can be calculated\n",
    "def get_not_perturbed_change_similarity(changes):\n",
    "    for change in changes:\n",
    "        if change['change_type'] == 'not_perturbed':\n",
    "            return change['semantic_similarity']\n",
    "    return pd.NA\n",
    "\n",
    "analyse_df = output[\n",
    "    (output[\"TwoChunksChanged\"] == True) & output['changes_similarity'].notna() & output['not_perturbed_TGT_change_type'].isin(['NOUN', 'VERB', 'ADJ', 'PRON'])\n",
    "]\n",
    "analyse_df['similarity_not_perturbed'] = analyse_df['changes_similarity'].apply(\n",
    "    lambda x: get_not_perturbed_change_similarity(x)\n",
    ")\n",
    "analyse_df.sort_values(by='similarity_not_perturbed')[['SRC', \n",
    "                                                f'original_word', \n",
    "                                                f'perturbed_word',\n",
    "                                                'OriginalSRC-Trans',\n",
    "                                                f'SRC_perturbed-Trans',\n",
    "                                                'ChunkDistance',\n",
    "                                                'changes_similarity',\n",
    "                                                'similarity_not_perturbed',\n",
    "                                                'not_perturbed_TGT_change_type',\n",
    "#                                                 'Bias_sample'\n",
    "                                                      ]].head(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c53bf",
   "metadata": {},
   "source": [
    "### Calculate metrics for detecting the bias samples\n",
    "\n",
    "High precision --> higher chance that the returned samples are bias --> save human time\n",
    "\n",
    "High recall --> more bias samples are retreat --> can detect more type of bias\n",
    "\n",
    "We focus on precision then (save human cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a53a5dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------- Most-changes filter -------------------- \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.87      0.68       898\n",
      "        True       0.34      0.09      0.14       683\n",
      "\n",
      "    accuracy                           0.53      1581\n",
      "   macro avg       0.45      0.48      0.41      1581\n",
      "weighted avg       0.46      0.53      0.45      1581\n",
      "\n",
      " -------------------- Most-spreaded_changes filter -------------------- \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.53      0.75      0.63       898\n",
      "        True       0.30      0.14      0.19       683\n",
      "\n",
      "    accuracy                           0.49      1581\n",
      "   macro avg       0.42      0.45      0.41      1581\n",
      "weighted avg       0.43      0.49      0.44      1581\n",
      "\n",
      " -------------------- Two-changes filter -------------------- \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.49      0.43      0.46       898\n",
      "        True       0.36      0.41      0.38       683\n",
      "\n",
      "    accuracy                           0.42      1581\n",
      "   macro avg       0.42      0.42      0.42      1581\n",
      "weighted avg       0.43      0.42      0.43      1581\n",
      "\n",
      " -------------------- Two-faraway-changes filter -------------------- \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      0.93      0.71       898\n",
      "        True       0.47      0.08      0.14       683\n",
      "\n",
      "    accuracy                           0.56      1581\n",
      "   macro avg       0.52      0.51      0.43      1581\n",
      "weighted avg       0.53      0.56      0.46      1581\n",
      "\n",
      " -------------------- Two-changes-different-subtree filter -------------------- \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.99      0.73       898\n",
      "        True       0.84      0.06      0.10       683\n",
      "\n",
      "    accuracy                           0.59      1581\n",
      "   macro avg       0.71      0.52      0.42      1581\n",
      "weighted avg       0.69      0.59      0.46      1581\n",
      "\n",
      " -------------------- Two-change-dissimilar filter -------------------- \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      1.00      0.73       898\n",
      "        True       0.93      0.04      0.07       683\n",
      "\n",
      "    accuracy                           0.58      1581\n",
      "   macro avg       0.75      0.52      0.40      1581\n",
      "weighted avg       0.73      0.58      0.45      1581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(' -------------------- Most-changes filter -------------------- ')\n",
    "q = 20  # Take the q% sentences with the highest changes\n",
    "no_changes_thresthold = np.percentile(output['#TransChanges-#SrcChanges'], 100-q)\n",
    "bias_prediction = output['#TransChanges-#SrcChanges'] > no_changes_thresthold\n",
    "results = classification_report(\n",
    "    y_true=output['Bias_sample'], y_pred=bias_prediction, \n",
    ")\n",
    "print(results)\n",
    "\n",
    "print(' -------------------- Most-spreaded_changes filter -------------------- ')\n",
    "q = 20  # Take the q% sentences with the highest spread\n",
    "spread_thresthold = np.percentile(output['ChangesSpread/SentenceLength'], 100-q)\n",
    "bias_prediction = output['ChangesSpread/SentenceLength'] > spread_thresthold\n",
    "results = classification_report(\n",
    "    y_true=output['Bias_sample'], y_pred=bias_prediction, \n",
    ")\n",
    "print(results)\n",
    "\n",
    "print(' -------------------- Two-changes filter -------------------- ')\n",
    "bias_prediction = output[\"TwoChunksChanged\"]\n",
    "results = classification_report(\n",
    "    y_true=output['Bias_sample'], y_pred=bias_prediction, \n",
    ")\n",
    "print(results)\n",
    "\n",
    "\n",
    "print(' -------------------- Two-faraway-changes filter -------------------- ')\n",
    "q = 20  # Take the q% sentences with the furthest distance between 2 changes \n",
    "distance_thresthold = np.nanpercentile(output['ChunkDistance'], 100-q)\n",
    "bias_prediction = output[\"TwoChunksChanged\"] & (output['ChunkDistance'] > distance_thresthold)\n",
    "results = classification_report(\n",
    "    y_true=output['Bias_sample'], y_pred=bias_prediction, \n",
    ")\n",
    "print(results)\n",
    "\n",
    "print(' -------------------- Two-changes-different-subtree filter -------------------- ')\n",
    "bias_prediction = output[\"TwoChunksChanged\"] & (output[\"is_same_subtree\"] == False)\n",
    "results = classification_report(\n",
    "    y_true=output['Bias_sample'], y_pred=bias_prediction, \n",
    ")\n",
    "print(results)\n",
    "\n",
    "\n",
    "print(' -------------------- Two-change-dissimilar filter -------------------- ')\n",
    "q = 90  # Take the q% sentences with the lowest similarity of the not-perturbed change\n",
    "output = output.join(analyse_df['similarity_not_perturbed'])\n",
    "similiarity_threshold = np.nanpercentile(output['similarity_not_perturbed'], q)\n",
    "\n",
    "bias_prediction = output[\"TwoChunksChanged\"] & (output['similarity_not_perturbed'] < similiarity_threshold)\n",
    "results = classification_report(\n",
    "    y_true=output['Bias_sample'], y_pred=bias_prediction, \n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ab5c4",
   "metadata": {},
   "source": [
    "### Analyse on same original_word accross sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f00533b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC_index</th>\n",
       "      <th>SRC-edit_distance</th>\n",
       "      <th>Trans-edit_distance</th>\n",
       "      <th>#TransChanges-#SrcChanges</th>\n",
       "      <th>#TransChanges-#SrcChanges/SentenceLength</th>\n",
       "      <th>ChangesSpread/SentenceLength</th>\n",
       "      <th>TwoChunksChanged</th>\n",
       "      <th>ChunkDistance</th>\n",
       "      <th>Trans-edit_distance--SD</th>\n",
       "      <th>#TransChanges-#SrcChanges--SD</th>\n",
       "      <th>TwoChunksChanged--total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accountant</th>\n",
       "      <td>144062.850000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.660000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>0.109156</td>\n",
       "      <td>0.283355</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.261833</td>\n",
       "      <td>1.261833</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor</th>\n",
       "      <td>125710.946746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.052071</td>\n",
       "      <td>1.052071</td>\n",
       "      <td>0.089356</td>\n",
       "      <td>0.228125</td>\n",
       "      <td>0.050888</td>\n",
       "      <td>2.488372</td>\n",
       "      <td>0.735556</td>\n",
       "      <td>0.735556</td>\n",
       "      <td>0.254438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actress</th>\n",
       "      <td>118696.210526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.115789</td>\n",
       "      <td>1.115789</td>\n",
       "      <td>0.093629</td>\n",
       "      <td>0.234790</td>\n",
       "      <td>0.084211</td>\n",
       "      <td>2.839286</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advisor</th>\n",
       "      <td>133874.583333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.894444</td>\n",
       "      <td>0.894444</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.230821</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.991124</td>\n",
       "      <td>0.991124</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aide</th>\n",
       "      <td>104538.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>0.203435</td>\n",
       "      <td>0.336605</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.337144</td>\n",
       "      <td>1.337144</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SRC_index  SRC-edit_distance  Trans-edit_distance  \\\n",
       "original_word                                                          \n",
       "accountant     144062.850000                1.0             2.660000   \n",
       "actor          125710.946746                1.0             2.052071   \n",
       "actress        118696.210526                1.0             2.115789   \n",
       "advisor        133874.583333                1.0             1.894444   \n",
       "aide           104538.000000                1.0             3.533333   \n",
       "\n",
       "               #TransChanges-#SrcChanges  \\\n",
       "original_word                              \n",
       "accountant                      1.660000   \n",
       "actor                           1.052071   \n",
       "actress                         1.115789   \n",
       "advisor                         0.894444   \n",
       "aide                            2.533333   \n",
       "\n",
       "               #TransChanges-#SrcChanges/SentenceLength  \\\n",
       "original_word                                             \n",
       "accountant                                     0.109156   \n",
       "actor                                          0.089356   \n",
       "actress                                        0.093629   \n",
       "advisor                                        0.073700   \n",
       "aide                                           0.203435   \n",
       "\n",
       "               ChangesSpread/SentenceLength  TwoChunksChanged  ChunkDistance  \\\n",
       "original_word                                                                  \n",
       "accountant                         0.283355          0.010000       1.000000   \n",
       "actor                              0.228125          0.050888       2.488372   \n",
       "actress                            0.234790          0.084211       2.839286   \n",
       "advisor                            0.230821          0.022222       3.250000   \n",
       "aide                               0.336605          0.100000       3.666667   \n",
       "\n",
       "               Trans-edit_distance--SD  #TransChanges-#SrcChanges--SD  \\\n",
       "original_word                                                           \n",
       "accountant                    1.261833                       1.261833   \n",
       "actor                         0.735556                       0.735556   \n",
       "actress                       0.884848                       0.884848   \n",
       "advisor                       0.991124                       0.991124   \n",
       "aide                          1.337144                       1.337144   \n",
       "\n",
       "               TwoChunksChanged--total  \n",
       "original_word                           \n",
       "accountant                    0.050000  \n",
       "actor                         0.254438  \n",
       "actress                       0.421053  \n",
       "advisor                       0.111111  \n",
       "aide                          0.500000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[[\n",
    "    'SRC_index', 'SRC', 'original_word', 'perturbed_word', 'SRC_perturbed',\n",
    "    'OriginalSRC-Trans', 'SRC_perturbed-Trans', '#TransChanges-#SrcChanges',\n",
    "    '#TransChanges-#SrcChanges/SentenceLength',\n",
    "    'ChangesSpread/SentenceLength', 'TwoChunksChanged', 'ChunkDistance',\n",
    "    'is_same_subtree', 'changes_similarity', 'perturbed_trans_alignment',\n",
    "    'not_perturbed_TGT_change_type', 'Trans-edit_distance--SD',\n",
    "    '#TransChanges-#SrcChanges--SD', 'TwoChunksChanged--total'\n",
    "]].groupby('original_word').mean().head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb9c49",
   "metadata": {},
   "source": [
    "### Most changes filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89f6d953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC_index</th>\n",
       "      <th>SRC</th>\n",
       "      <th>original_word</th>\n",
       "      <th>perturbed_word</th>\n",
       "      <th>SRC_perturbed</th>\n",
       "      <th>OriginalSRC-Trans</th>\n",
       "      <th>SRC_perturbed-Trans</th>\n",
       "      <th>SRC-edit_distance</th>\n",
       "      <th>Trans-edit_distance</th>\n",
       "      <th>#TransChanges-#SrcChanges</th>\n",
       "      <th>...</th>\n",
       "      <th>ChangesSpread/SentenceLength</th>\n",
       "      <th>TwoChunksChanged</th>\n",
       "      <th>ChunkDistance</th>\n",
       "      <th>is_same_subtree</th>\n",
       "      <th>changes_similarity</th>\n",
       "      <th>perturbed_trans_alignment</th>\n",
       "      <th>not_perturbed_TGT_change_type</th>\n",
       "      <th>Trans-edit_distance--SD</th>\n",
       "      <th>#TransChanges-#SrcChanges--SD</th>\n",
       "      <th>TwoChunksChanged--total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>1876</td>\n",
       "      <td>He was the first Australian and Oceanian referee at the World Cup.</td>\n",
       "      <td>referee</td>\n",
       "      <td>participant</td>\n",
       "      <td>He was the first Australian and Oceanian participant at the World Cup.</td>\n",
       "      <td>Er war der erste australische und ozeanische Schiedsrichter bei einer Weltmeisterschaft.</td>\n",
       "      <td>Er war der erste australische und ozeanische WM-Teilnehmer.</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>{'He': 'Er', 'was': 'war', 'the': 'der', 'first': 'erste', 'Australian': 'australische', 'and': 'und', 'Oceanian': 'ozeanische', 'participant': 'WM-Teilnehmer', 'World': 'WM-Teilnehmer', '.': '.'}</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.516575</td>\n",
       "      <td>1.516575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>1876</td>\n",
       "      <td>He was the first Australian and Oceanian referee at the World Cup.</td>\n",
       "      <td>referee</td>\n",
       "      <td>winner</td>\n",
       "      <td>He was the first Australian and Oceanian winner at the World Cup.</td>\n",
       "      <td>Er war der erste australische und ozeanische Schiedsrichter bei einer Weltmeisterschaft.</td>\n",
       "      <td>Er war der erste australische und ozeanische Weltcupsieger.</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>{'He': 'Er', 'was': 'war', 'the': 'der', 'first': 'erste', 'Australian': 'australische', 'and': 'und', 'Oceanian': 'ozeanische', 'winner': 'Weltcupsieger', 'Cup': 'Weltcupsieger', '.': '.'}</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.516575</td>\n",
       "      <td>1.516575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SRC_index  \\\n",
       "1876       1876   \n",
       "1876       1876   \n",
       "\n",
       "                                                                     SRC  \\\n",
       "1876  He was the first Australian and Oceanian referee at the World Cup.   \n",
       "1876  He was the first Australian and Oceanian referee at the World Cup.   \n",
       "\n",
       "     original_word perturbed_word  \\\n",
       "1876       referee    participant   \n",
       "1876       referee         winner   \n",
       "\n",
       "                                                               SRC_perturbed  \\\n",
       "1876  He was the first Australian and Oceanian participant at the World Cup.   \n",
       "1876       He was the first Australian and Oceanian winner at the World Cup.   \n",
       "\n",
       "                                                                             OriginalSRC-Trans  \\\n",
       "1876  Er war der erste australische und ozeanische Schiedsrichter bei einer Weltmeisterschaft.   \n",
       "1876  Er war der erste australische und ozeanische Schiedsrichter bei einer Weltmeisterschaft.   \n",
       "\n",
       "                                              SRC_perturbed-Trans  \\\n",
       "1876  Er war der erste australische und ozeanische WM-Teilnehmer.   \n",
       "1876  Er war der erste australische und ozeanische Weltcupsieger.   \n",
       "\n",
       "      SRC-edit_distance  Trans-edit_distance  #TransChanges-#SrcChanges  ...  \\\n",
       "1876                  1                    4                          3  ...   \n",
       "1876                  1                    4                          3  ...   \n",
       "\n",
       "      ChangesSpread/SentenceLength  TwoChunksChanged  ChunkDistance  \\\n",
       "1876                      0.111111             False            NaN   \n",
       "1876                      0.111111             False            NaN   \n",
       "\n",
       "      is_same_subtree changes_similarity  \\\n",
       "1876             <NA>               <NA>   \n",
       "1876             <NA>               <NA>   \n",
       "\n",
       "                                                                                                                                                                                 perturbed_trans_alignment  \\\n",
       "1876  {'He': 'Er', 'was': 'war', 'the': 'der', 'first': 'erste', 'Australian': 'australische', 'and': 'und', 'Oceanian': 'ozeanische', 'participant': 'WM-Teilnehmer', 'World': 'WM-Teilnehmer', '.': '.'}   \n",
       "1876         {'He': 'Er', 'was': 'war', 'the': 'der', 'first': 'erste', 'Australian': 'australische', 'and': 'und', 'Oceanian': 'ozeanische', 'winner': 'Weltcupsieger', 'Cup': 'Weltcupsieger', '.': '.'}   \n",
       "\n",
       "     not_perturbed_TGT_change_type Trans-edit_distance--SD  \\\n",
       "1876                          <NA>                1.516575   \n",
       "1876                          <NA>                1.516575   \n",
       "\n",
       "      #TransChanges-#SrcChanges--SD  TwoChunksChanged--total  \n",
       "1876                       1.516575                        0  \n",
       "1876                       1.516575                        0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupped_by_word = output.groupby('original_word').mean()\n",
    "\n",
    "q = 10  # Take the q% groups with the highest changes\n",
    "no_changes_thresthold = np.percentile(groupped_by_word['#TransChanges-#SrcChanges'], 100-q)\n",
    "bias_prediction = groupped_by_word['#TransChanges-#SrcChanges'] > no_changes_thresthold\n",
    "\n",
    "bias_word_predicted = groupped_by_word[bias_prediction].index.values\n",
    "\n",
    "output[\n",
    "    output['original_word'].isin(bias_word_predicted) & \\\n",
    "    (output['#TransChanges-#SrcChanges'] > no_changes_thresthold)\n",
    "].head(2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf0826",
   "metadata": {},
   "source": [
    "### Most-spreaded_changes filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e4e45372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC_index</th>\n",
       "      <th>SRC</th>\n",
       "      <th>original_word</th>\n",
       "      <th>perturbed_word</th>\n",
       "      <th>SRC_perturbed</th>\n",
       "      <th>OriginalSRC-Trans</th>\n",
       "      <th>SRC_perturbed-Trans</th>\n",
       "      <th>SRC-edit_distance</th>\n",
       "      <th>Trans-edit_distance</th>\n",
       "      <th>#TransChanges-#SrcChanges</th>\n",
       "      <th>...</th>\n",
       "      <th>ChangesSpread/SentenceLength</th>\n",
       "      <th>TwoChunksChanged</th>\n",
       "      <th>ChunkDistance</th>\n",
       "      <th>is_same_subtree</th>\n",
       "      <th>changes_similarity</th>\n",
       "      <th>perturbed_trans_alignment</th>\n",
       "      <th>not_perturbed_TGT_change_type</th>\n",
       "      <th>Trans-edit_distance--SD</th>\n",
       "      <th>#TransChanges-#SrcChanges--SD</th>\n",
       "      <th>TwoChunksChanged--total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>This was unacceptable to the firm believers in the co-operative economic model.</td>\n",
       "      <td>model</td>\n",
       "      <td>sector</td>\n",
       "      <td>This was unacceptable to the firm believers in the co - operative economic sector.</td>\n",
       "      <td>Dies war für die fest an das genossenschaftliche Wirtschaftsmodell glaubenden Menschen inakzeptabel.</td>\n",
       "      <td>Dies war für die festen Gläubigen des genossenschaftlichen Wirtschaftssektors inakzeptabel.</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>{'This': 'Dies', 'was': 'war', 'unacceptable': 'inakzeptabel', 'to': 'für', 'the': 'des', 'believers': 'Gläubigen', 'co': 'genossenschaftlichen', 'operative': 'genossenschaftlichen', 'economic': 'Wirtschaftssektors', 'sector': 'Wirtschaftssektors', '.': '.'}</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.788854</td>\n",
       "      <td>1.788854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>This was unacceptable to the firm believers in the co-operative economic model.</td>\n",
       "      <td>model</td>\n",
       "      <td>system</td>\n",
       "      <td>This was unacceptable to the firm believers in the co - operative economic system.</td>\n",
       "      <td>Dies war für die fest an das genossenschaftliche Wirtschaftsmodell glaubenden Menschen inakzeptabel.</td>\n",
       "      <td>Dies war für die festen Gläubigen des kooperativen Wirtschaftssystems inakzeptabel.</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>{'This': 'Dies', 'was': 'war', 'unacceptable': 'inakzeptabel', 'to': 'für', 'the': 'des', 'believers': 'Gläubigen', 'co': 'kooperativen', 'operative': 'kooperativen', 'economic': 'Wirtschaftssystems', 'system': 'Wirtschaftssystems', '.': '.'}</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.788854</td>\n",
       "      <td>1.788854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SRC_index  \\\n",
       "97         97   \n",
       "97         97   \n",
       "\n",
       "                                                                                SRC  \\\n",
       "97  This was unacceptable to the firm believers in the co-operative economic model.   \n",
       "97  This was unacceptable to the firm believers in the co-operative economic model.   \n",
       "\n",
       "   original_word perturbed_word  \\\n",
       "97         model         sector   \n",
       "97         model         system   \n",
       "\n",
       "                                                                         SRC_perturbed  \\\n",
       "97  This was unacceptable to the firm believers in the co - operative economic sector.   \n",
       "97  This was unacceptable to the firm believers in the co - operative economic system.   \n",
       "\n",
       "                                                                                       OriginalSRC-Trans  \\\n",
       "97  Dies war für die fest an das genossenschaftliche Wirtschaftsmodell glaubenden Menschen inakzeptabel.   \n",
       "97  Dies war für die fest an das genossenschaftliche Wirtschaftsmodell glaubenden Menschen inakzeptabel.   \n",
       "\n",
       "                                                                            SRC_perturbed-Trans  \\\n",
       "97  Dies war für die festen Gläubigen des genossenschaftlichen Wirtschaftssektors inakzeptabel.   \n",
       "97          Dies war für die festen Gläubigen des kooperativen Wirtschaftssystems inakzeptabel.   \n",
       "\n",
       "    SRC-edit_distance  Trans-edit_distance  #TransChanges-#SrcChanges  ...  \\\n",
       "97                  1                    7                          6  ...   \n",
       "97                  1                    7                          6  ...   \n",
       "\n",
       "    ChangesSpread/SentenceLength  TwoChunksChanged  ChunkDistance  \\\n",
       "97                      0.454545             False            NaN   \n",
       "97                      0.454545             False            NaN   \n",
       "\n",
       "    is_same_subtree changes_similarity  \\\n",
       "97             <NA>               <NA>   \n",
       "97             <NA>               <NA>   \n",
       "\n",
       "                                                                                                                                                                                                                                             perturbed_trans_alignment  \\\n",
       "97  {'This': 'Dies', 'was': 'war', 'unacceptable': 'inakzeptabel', 'to': 'für', 'the': 'des', 'believers': 'Gläubigen', 'co': 'genossenschaftlichen', 'operative': 'genossenschaftlichen', 'economic': 'Wirtschaftssektors', 'sector': 'Wirtschaftssektors', '.': '.'}   \n",
       "97                  {'This': 'Dies', 'was': 'war', 'unacceptable': 'inakzeptabel', 'to': 'für', 'the': 'des', 'believers': 'Gläubigen', 'co': 'kooperativen', 'operative': 'kooperativen', 'economic': 'Wirtschaftssystems', 'system': 'Wirtschaftssystems', '.': '.'}   \n",
       "\n",
       "   not_perturbed_TGT_change_type Trans-edit_distance--SD  \\\n",
       "97                          <NA>                1.788854   \n",
       "97                          <NA>                1.788854   \n",
       "\n",
       "    #TransChanges-#SrcChanges--SD  TwoChunksChanged--total  \n",
       "97                       1.788854                        0  \n",
       "97                       1.788854                        0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupped_by_word = output.groupby('original_word').mean()\n",
    "\n",
    "q = 10  # Take the q% sentences with the highest spread\n",
    "spread_thresthold = np.percentile(groupped_by_word['ChangesSpread/SentenceLength'], 100-q)\n",
    "bias_prediction = groupped_by_word['ChangesSpread/SentenceLength'] > spread_thresthold\n",
    "\n",
    "bias_word_predicted = groupped_by_word[bias_prediction].index.values\n",
    "\n",
    "output[\n",
    "    output['original_word'].isin(bias_word_predicted) & \\\n",
    "    (output['ChangesSpread/SentenceLength'] > spread_thresthold)\n",
    "].head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069aeb58",
   "metadata": {},
   "source": [
    "### Two-faraway-changes filter\n",
    "\n",
    "ACTUALLY two-changes is not a bias filter. It's just an auxilary filter to avoid paraphrasing cases. Using this we will miss out on the cases where the model has both paraphrasing and \n",
    "\n",
    "Here we consider in each group: the number of sentences that has 2 changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bffe0163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC_index</th>\n",
       "      <th>SRC</th>\n",
       "      <th>original_word</th>\n",
       "      <th>perturbed_word</th>\n",
       "      <th>SRC_perturbed</th>\n",
       "      <th>OriginalSRC-Trans</th>\n",
       "      <th>SRC_perturbed-Trans</th>\n",
       "      <th>SRC-edit_distance</th>\n",
       "      <th>Trans-edit_distance</th>\n",
       "      <th>#TransChanges-#SrcChanges</th>\n",
       "      <th>...</th>\n",
       "      <th>TwoChunksChanged</th>\n",
       "      <th>ChunkDistance</th>\n",
       "      <th>is_same_subtree</th>\n",
       "      <th>changes_similarity</th>\n",
       "      <th>perturbed_trans_alignment</th>\n",
       "      <th>not_perturbed_TGT_change_type</th>\n",
       "      <th>Trans-edit_distance--SD</th>\n",
       "      <th>#TransChanges-#SrcChanges--SD</th>\n",
       "      <th>TwoChunksChanged--total</th>\n",
       "      <th>similarity_not_perturbed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>311</td>\n",
       "      <td>Some physicist then tried to stretch out this group.</td>\n",
       "      <td>physicist</td>\n",
       "      <td>men</td>\n",
       "      <td>Some men then tried to stretch out this group.</td>\n",
       "      <td>Einige PHYSIKER versuchten dann , diese Gruppe AUSZUDEHNEN .</td>\n",
       "      <td>Einige MÄNNER versuchten dann , diese Gruppe AUSZUSTRECKEN .</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'original_word': 'Physiker', 'changed_word': 'Männer', 'semantic_similarity': 0.29928693, 'change_type': 'perturbed'}, {'original_word': 'auszudehnen', 'changed_word': 'auszustrecken', 'semantic_similarity': 0.52432793, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>{'Some': 'Einige', 'men': 'Männer', 'then': 'dann', 'tried': 'versuchten', 'to': ',', 'stretch': 'auszustrecken', 'out': 'auszustrecken', 'this': 'diese', 'group': 'Gruppe', '.': '.'}</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>319</td>\n",
       "      <td>It is also a famous site for fisherman who are on foot or in a bark.</td>\n",
       "      <td>fisherman</td>\n",
       "      <td>people</td>\n",
       "      <td>It is also a famous site for people who are on foot or in a bark.</td>\n",
       "      <td>Es ist auch ein berühmter Ort für FISCHER , die zu Fuß oder in DER Rinde sind .</td>\n",
       "      <td>Es ist auch ein berühmter Ort für MENSCHEN , die zu Fuß oder in EINER Rinde sind .</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'original_word': 'Fischer', 'changed_word': 'Menschen', 'semantic_similarity': 0.28160858, 'change_type': 'perturbed'}, {'original_word': 'der', 'changed_word': 'einer', 'semantic_similarity': 0.7654743, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>{'It': 'Es', 'is': 'ist', 'also': 'auch', 'a': 'einer', 'famous': 'berühmter', 'site': 'Ort', 'for': 'für', 'people': 'Menschen', 'who': 'die', 'are': 'sind', 'on': 'zu', 'foot': 'Fuß', 'or': 'oder', 'in': 'in', 'bark': 'Rinde', '.': '.'}</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>4</td>\n",
       "      <td>0.765474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SRC_index  \\\n",
       "311        311   \n",
       "319        319   \n",
       "\n",
       "                                                                      SRC  \\\n",
       "311                  Some physicist then tried to stretch out this group.   \n",
       "319  It is also a famous site for fisherman who are on foot or in a bark.   \n",
       "\n",
       "    original_word perturbed_word  \\\n",
       "311     physicist            men   \n",
       "319     fisherman         people   \n",
       "\n",
       "                                                         SRC_perturbed  \\\n",
       "311                     Some men then tried to stretch out this group.   \n",
       "319  It is also a famous site for people who are on foot or in a bark.   \n",
       "\n",
       "                                                                   OriginalSRC-Trans  \\\n",
       "311                     Einige PHYSIKER versuchten dann , diese Gruppe AUSZUDEHNEN .   \n",
       "319  Es ist auch ein berühmter Ort für FISCHER , die zu Fuß oder in DER Rinde sind .   \n",
       "\n",
       "                                                                    SRC_perturbed-Trans  \\\n",
       "311                        Einige MÄNNER versuchten dann , diese Gruppe AUSZUSTRECKEN .   \n",
       "319  Es ist auch ein berühmter Ort für MENSCHEN , die zu Fuß oder in EINER Rinde sind .   \n",
       "\n",
       "     SRC-edit_distance  Trans-edit_distance  #TransChanges-#SrcChanges  ...  \\\n",
       "311                  1                    2                          1  ...   \n",
       "319                  1                    2                          1  ...   \n",
       "\n",
       "     TwoChunksChanged  ChunkDistance  is_same_subtree  \\\n",
       "311              True            5.0            False   \n",
       "319              True            6.0             True   \n",
       "\n",
       "                                                                                                                                                                                                                                                 changes_similarity  \\\n",
       "311  [{'original_word': 'Physiker', 'changed_word': 'Männer', 'semantic_similarity': 0.29928693, 'change_type': 'perturbed'}, {'original_word': 'auszudehnen', 'changed_word': 'auszustrecken', 'semantic_similarity': 0.52432793, 'change_type': 'not_perturbed'}]   \n",
       "319                  [{'original_word': 'Fischer', 'changed_word': 'Menschen', 'semantic_similarity': 0.28160858, 'change_type': 'perturbed'}, {'original_word': 'der', 'changed_word': 'einer', 'semantic_similarity': 0.7654743, 'change_type': 'not_perturbed'}]   \n",
       "\n",
       "                                                                                                                                                                                                                          perturbed_trans_alignment  \\\n",
       "311                                                         {'Some': 'Einige', 'men': 'Männer', 'then': 'dann', 'tried': 'versuchten', 'to': ',', 'stretch': 'auszustrecken', 'out': 'auszustrecken', 'this': 'diese', 'group': 'Gruppe', '.': '.'}   \n",
       "319  {'It': 'Es', 'is': 'ist', 'also': 'auch', 'a': 'einer', 'famous': 'berühmter', 'site': 'Ort', 'for': 'für', 'people': 'Menschen', 'who': 'die', 'are': 'sind', 'on': 'zu', 'foot': 'Fuß', 'or': 'oder', 'in': 'in', 'bark': 'Rinde', '.': '.'}   \n",
       "\n",
       "    not_perturbed_TGT_change_type Trans-edit_distance--SD  \\\n",
       "311                          VERB                1.000000   \n",
       "319                          PRON                0.447214   \n",
       "\n",
       "    #TransChanges-#SrcChanges--SD  TwoChunksChanged--total  \\\n",
       "311                      1.000000                        1   \n",
       "319                      0.447214                        4   \n",
       "\n",
       "     similarity_not_perturbed  \n",
       "311                  0.524328  \n",
       "319                  0.765474  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_change_only_groupped_by_word = output[output[\"TwoChunksChanged\"]].groupby('original_word').mean()\n",
    "\n",
    "\n",
    "q = 20  # Take the q% sentences with the furthest distance between 2 changes \n",
    "distance_thresthold = np.percentile(two_change_only_groupped_by_word['ChunkDistance'], 100-q)\n",
    "bias_prediction = two_change_only_groupped_by_word['ChunkDistance'] > distance_thresthold\n",
    "\n",
    "\n",
    "bias_word_predicted = two_change_only_groupped_by_word[bias_prediction].index.values\n",
    "\n",
    "output[\n",
    "    output[\"TwoChunksChanged\"] & \\\n",
    "    output['original_word'].isin(bias_word_predicted) & \\\n",
    "    (output['ChunkDistance'] > distance_thresthold)\n",
    "].head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98cd5f9",
   "metadata": {},
   "source": [
    "### Two-changes-different-subtree filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "876de271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/10_vywcj3lb14yk3sn91jn3c0000gn/T/ipykernel_22756/2334906603.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tmp['not_same_subtree'] = 1- tmp['is_same_subtree'].astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC_index</th>\n",
       "      <th>SRC</th>\n",
       "      <th>original_word</th>\n",
       "      <th>perturbed_word</th>\n",
       "      <th>SRC_perturbed</th>\n",
       "      <th>OriginalSRC-Trans</th>\n",
       "      <th>SRC_perturbed-Trans</th>\n",
       "      <th>SRC-edit_distance</th>\n",
       "      <th>Trans-edit_distance</th>\n",
       "      <th>#TransChanges-#SrcChanges</th>\n",
       "      <th>...</th>\n",
       "      <th>TwoChunksChanged</th>\n",
       "      <th>ChunkDistance</th>\n",
       "      <th>is_same_subtree</th>\n",
       "      <th>changes_similarity</th>\n",
       "      <th>perturbed_trans_alignment</th>\n",
       "      <th>not_perturbed_TGT_change_type</th>\n",
       "      <th>Trans-edit_distance--SD</th>\n",
       "      <th>#TransChanges-#SrcChanges--SD</th>\n",
       "      <th>TwoChunksChanged--total</th>\n",
       "      <th>similarity_not_perturbed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>311</td>\n",
       "      <td>Some physicist then tried to stretch out this group.</td>\n",
       "      <td>physicist</td>\n",
       "      <td>men</td>\n",
       "      <td>Some men then tried to stretch out this group.</td>\n",
       "      <td>Einige PHYSIKER versuchten dann , diese Gruppe AUSZUDEHNEN .</td>\n",
       "      <td>Einige MÄNNER versuchten dann , diese Gruppe AUSZUSTRECKEN .</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'original_word': 'Physiker', 'changed_word': 'Männer', 'semantic_similarity': 0.29928693, 'change_type': 'perturbed'}, {'original_word': 'auszudehnen', 'changed_word': 'auszustrecken', 'semantic_similarity': 0.52432793, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>{'Some': 'Einige', 'men': 'Männer', 'then': 'dann', 'tried': 'versuchten', 'to': ',', 'stretch': 'auszustrecken', 'out': 'auszustrecken', 'this': 'diese', 'group': 'Gruppe', '.': '.'}</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>319</td>\n",
       "      <td>It is also a famous site for fisherman who are on foot or in a bark.</td>\n",
       "      <td>fisherman</td>\n",
       "      <td>visitors</td>\n",
       "      <td>It is also a famous site for visitors who are on foot or in a bark.</td>\n",
       "      <td>Es ist auch ein berühmter Ort für FISCHER , die zu Fuß oder in DER Rinde sind .</td>\n",
       "      <td>Es ist auch ein berühmter Ort für BESUCHER , die zu Fuß oder in EINER Rinde sind .</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'original_word': 'Fischer', 'changed_word': 'Besucher', 'semantic_similarity': 0.1882075, 'change_type': 'perturbed'}, {'original_word': 'der', 'changed_word': 'einer', 'semantic_similarity': 0.7654743, 'change_type': 'not_perturbed'}]</td>\n",
       "      <td>{'It': 'Es', 'is': 'ist', 'also': 'auch', 'a': 'einer', 'famous': 'berühmter', 'site': 'Ort', 'for': 'für', 'visitors': 'Besucher', 'who': 'die', 'are': 'sind', 'on': 'zu', 'foot': 'Fuß', 'or': 'oder', 'in': 'in', 'bark': 'Rinde', '.': '.'}</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>4</td>\n",
       "      <td>0.765474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SRC_index  \\\n",
       "311        311   \n",
       "319        319   \n",
       "\n",
       "                                                                      SRC  \\\n",
       "311                  Some physicist then tried to stretch out this group.   \n",
       "319  It is also a famous site for fisherman who are on foot or in a bark.   \n",
       "\n",
       "    original_word perturbed_word  \\\n",
       "311     physicist            men   \n",
       "319     fisherman       visitors   \n",
       "\n",
       "                                                           SRC_perturbed  \\\n",
       "311                       Some men then tried to stretch out this group.   \n",
       "319  It is also a famous site for visitors who are on foot or in a bark.   \n",
       "\n",
       "                                                                   OriginalSRC-Trans  \\\n",
       "311                     Einige PHYSIKER versuchten dann , diese Gruppe AUSZUDEHNEN .   \n",
       "319  Es ist auch ein berühmter Ort für FISCHER , die zu Fuß oder in DER Rinde sind .   \n",
       "\n",
       "                                                                    SRC_perturbed-Trans  \\\n",
       "311                        Einige MÄNNER versuchten dann , diese Gruppe AUSZUSTRECKEN .   \n",
       "319  Es ist auch ein berühmter Ort für BESUCHER , die zu Fuß oder in EINER Rinde sind .   \n",
       "\n",
       "     SRC-edit_distance  Trans-edit_distance  #TransChanges-#SrcChanges  ...  \\\n",
       "311                  1                    2                          1  ...   \n",
       "319                  1                    2                          1  ...   \n",
       "\n",
       "     TwoChunksChanged  ChunkDistance  is_same_subtree  \\\n",
       "311              True            5.0            False   \n",
       "319              True            6.0            False   \n",
       "\n",
       "                                                                                                                                                                                                                                                 changes_similarity  \\\n",
       "311  [{'original_word': 'Physiker', 'changed_word': 'Männer', 'semantic_similarity': 0.29928693, 'change_type': 'perturbed'}, {'original_word': 'auszudehnen', 'changed_word': 'auszustrecken', 'semantic_similarity': 0.52432793, 'change_type': 'not_perturbed'}]   \n",
       "319                   [{'original_word': 'Fischer', 'changed_word': 'Besucher', 'semantic_similarity': 0.1882075, 'change_type': 'perturbed'}, {'original_word': 'der', 'changed_word': 'einer', 'semantic_similarity': 0.7654743, 'change_type': 'not_perturbed'}]   \n",
       "\n",
       "                                                                                                                                                                                                                            perturbed_trans_alignment  \\\n",
       "311                                                           {'Some': 'Einige', 'men': 'Männer', 'then': 'dann', 'tried': 'versuchten', 'to': ',', 'stretch': 'auszustrecken', 'out': 'auszustrecken', 'this': 'diese', 'group': 'Gruppe', '.': '.'}   \n",
       "319  {'It': 'Es', 'is': 'ist', 'also': 'auch', 'a': 'einer', 'famous': 'berühmter', 'site': 'Ort', 'for': 'für', 'visitors': 'Besucher', 'who': 'die', 'are': 'sind', 'on': 'zu', 'foot': 'Fuß', 'or': 'oder', 'in': 'in', 'bark': 'Rinde', '.': '.'}   \n",
       "\n",
       "    not_perturbed_TGT_change_type Trans-edit_distance--SD  \\\n",
       "311                          VERB                1.000000   \n",
       "319                          PRON                0.447214   \n",
       "\n",
       "    #TransChanges-#SrcChanges--SD  TwoChunksChanged--total  \\\n",
       "311                      1.000000                        1   \n",
       "319                      0.447214                        4   \n",
       "\n",
       "     similarity_not_perturbed  \n",
       "311                  0.524328  \n",
       "319                  0.765474  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = output[output[\"TwoChunksChanged\"] & output['is_same_subtree'].notna()]\n",
    "tmp['not_same_subtree'] = 1- tmp['is_same_subtree'].astype(int)\n",
    "two_change_only_groupped_by_word = tmp.groupby('original_word').sum()\n",
    "\n",
    "q = 20  # Take the q% groups with the highest number of different subtree changes\n",
    "count_thresthold = np.percentile(two_change_only_groupped_by_word['not_same_subtree'], 100-q)\n",
    "bias_prediction = two_change_only_groupped_by_word['ChunkDistance'] > count_thresthold\n",
    "\n",
    "\n",
    "bias_word_predicted = two_change_only_groupped_by_word[bias_prediction].index.values\n",
    "\n",
    "output[\n",
    "    output[\"TwoChunksChanged\"] & \\\n",
    "    output['original_word'].isin(bias_word_predicted) & \\\n",
    "    (output['is_same_subtree'] == 0)\n",
    "].head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a02578",
   "metadata": {},
   "source": [
    "### Two-change-dissimilar filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a50ee3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC_index</th>\n",
       "      <th>SRC</th>\n",
       "      <th>original_word</th>\n",
       "      <th>perturbed_word</th>\n",
       "      <th>SRC_perturbed</th>\n",
       "      <th>OriginalSRC-Trans</th>\n",
       "      <th>SRC_perturbed-Trans</th>\n",
       "      <th>SRC-edit_distance</th>\n",
       "      <th>Trans-edit_distance</th>\n",
       "      <th>#TransChanges-#SrcChanges</th>\n",
       "      <th>...</th>\n",
       "      <th>TwoChunksChanged</th>\n",
       "      <th>ChunkDistance</th>\n",
       "      <th>is_same_subtree</th>\n",
       "      <th>changes_similarity</th>\n",
       "      <th>perturbed_trans_alignment</th>\n",
       "      <th>not_perturbed_TGT_change_type</th>\n",
       "      <th>Trans-edit_distance--SD</th>\n",
       "      <th>#TransChanges-#SrcChanges--SD</th>\n",
       "      <th>TwoChunksChanged--total</th>\n",
       "      <th>similarity_not_perturbed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>2650</td>\n",
       "      <td>These performances are enough for him to be elected Dutch athlete of the year.</td>\n",
       "      <td>athlete</td>\n",
       "      <td>artist</td>\n",
       "      <td>These performances are enough for him to be elected Dutch artist of the year.</td>\n",
       "      <td>Diese LEISTUNGEN reichen ihm , um zum niederländischen SPORTLER des Jahres gewählt zu werden .</td>\n",
       "      <td>Diese AUFTRITTE reichen ihm , um zum niederländischen KÜNSTLER des Jahres gewählt zu werden .</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'original_word': 'Leistungen', 'changed_word': 'Auftritte', 'semantic_similarity': 0.4426266, 'change_type': 'not_perturbed'}, {'original_word': 'Sportler', 'changed_word': 'Künstler', 'semantic_similarity': 0.51654893, 'change_type': 'perturbed'}]</td>\n",
       "      <td>{'These': 'Diese', 'performances': 'Auftritte', 'are': 'reichen', 'him': 'ihm', 'to': 'zu', 'be': 'werden', 'elected': 'gewählt', 'Dutch': 'niederländischen', 'artist': 'Künstler', 'of': 'des', 'year': 'Jahres', '.': '.'}</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.442627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>4836</td>\n",
       "      <td>It was named in honor of the American astronomer Annie Jump Cannon.</td>\n",
       "      <td>astronomer</td>\n",
       "      <td>author</td>\n",
       "      <td>It was named in honor of the American author Annie Jump Cannon.</td>\n",
       "      <td>SIE wurde zu Ehren der amerikanischen ASTRONOMIN Annie Jump Cannon benannt .</td>\n",
       "      <td>ES wurde zu Ehren der amerikanischen AUTORIN Annie Jump Cannon benannt .</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'original_word': 'Sie', 'changed_word': 'Es', 'semantic_similarity': 0.32995936, 'change_type': 'not_perturbed'}, {'original_word': 'Astronomin', 'changed_word': 'Autorin', 'semantic_similarity': 0.4326979, 'change_type': 'perturbed'}]</td>\n",
       "      <td>{'It': 'Es', 'was': 'wurde', 'named': 'benannt', 'in': 'zu', 'honor': 'Ehren', 'the': 'der', 'American': 'amerikanischen', 'author': 'Autorin', 'Annie': 'Annie', 'Jump': 'Jump', 'Cannon': 'Cannon', '.': '.'}</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.329959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SRC_index  \\\n",
       "2650       2650   \n",
       "4836       4836   \n",
       "\n",
       "                                                                                 SRC  \\\n",
       "2650  These performances are enough for him to be elected Dutch athlete of the year.   \n",
       "4836             It was named in honor of the American astronomer Annie Jump Cannon.   \n",
       "\n",
       "     original_word perturbed_word  \\\n",
       "2650       athlete         artist   \n",
       "4836    astronomer         author   \n",
       "\n",
       "                                                                      SRC_perturbed  \\\n",
       "2650  These performances are enough for him to be elected Dutch artist of the year.   \n",
       "4836                It was named in honor of the American author Annie Jump Cannon.   \n",
       "\n",
       "                                                                                   OriginalSRC-Trans  \\\n",
       "2650  Diese LEISTUNGEN reichen ihm , um zum niederländischen SPORTLER des Jahres gewählt zu werden .   \n",
       "4836                    SIE wurde zu Ehren der amerikanischen ASTRONOMIN Annie Jump Cannon benannt .   \n",
       "\n",
       "                                                                                SRC_perturbed-Trans  \\\n",
       "2650  Diese AUFTRITTE reichen ihm , um zum niederländischen KÜNSTLER des Jahres gewählt zu werden .   \n",
       "4836                       ES wurde zu Ehren der amerikanischen AUTORIN Annie Jump Cannon benannt .   \n",
       "\n",
       "      SRC-edit_distance  Trans-edit_distance  #TransChanges-#SrcChanges  ...  \\\n",
       "2650                  1                    2                          1  ...   \n",
       "4836                  1                    2                          1  ...   \n",
       "\n",
       "      TwoChunksChanged  ChunkDistance  is_same_subtree  \\\n",
       "2650              True            6.0            False   \n",
       "4836              True            5.0            False   \n",
       "\n",
       "                                                                                                                                                                                                                                              changes_similarity  \\\n",
       "2650  [{'original_word': 'Leistungen', 'changed_word': 'Auftritte', 'semantic_similarity': 0.4426266, 'change_type': 'not_perturbed'}, {'original_word': 'Sportler', 'changed_word': 'Künstler', 'semantic_similarity': 0.51654893, 'change_type': 'perturbed'}]   \n",
       "4836               [{'original_word': 'Sie', 'changed_word': 'Es', 'semantic_similarity': 0.32995936, 'change_type': 'not_perturbed'}, {'original_word': 'Astronomin', 'changed_word': 'Autorin', 'semantic_similarity': 0.4326979, 'change_type': 'perturbed'}]   \n",
       "\n",
       "                                                                                                                                                                                                          perturbed_trans_alignment  \\\n",
       "2650  {'These': 'Diese', 'performances': 'Auftritte', 'are': 'reichen', 'him': 'ihm', 'to': 'zu', 'be': 'werden', 'elected': 'gewählt', 'Dutch': 'niederländischen', 'artist': 'Künstler', 'of': 'des', 'year': 'Jahres', '.': '.'}   \n",
       "4836                {'It': 'Es', 'was': 'wurde', 'named': 'benannt', 'in': 'zu', 'honor': 'Ehren', 'the': 'der', 'American': 'amerikanischen', 'author': 'Autorin', 'Annie': 'Annie', 'Jump': 'Jump', 'Cannon': 'Cannon', '.': '.'}   \n",
       "\n",
       "     not_perturbed_TGT_change_type Trans-edit_distance--SD  \\\n",
       "2650                          NOUN                0.447214   \n",
       "4836                          PRON                0.000000   \n",
       "\n",
       "     #TransChanges-#SrcChanges--SD  TwoChunksChanged--total  \\\n",
       "2650                      0.447214                        1   \n",
       "4836                      0.000000                        5   \n",
       "\n",
       "      similarity_not_perturbed  \n",
       "2650                  0.442627  \n",
       "4836                  0.329959  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output.join(analyse_df['similarity_not_perturbed'])\n",
    "two_change_only_groupped_by_word = output[output[\"TwoChunksChanged\"]].groupby('original_word').mean()\n",
    "\n",
    "\n",
    "q = 20  # Take the q% sentences with the lowest similarity of the not-perturbed change\n",
    "similiarity_threshold = np.nanpercentile(two_change_only_groupped_by_word['similarity_not_perturbed'], q)\n",
    "bias_prediction = two_change_only_groupped_by_word['similarity_not_perturbed'] < similiarity_threshold\n",
    "\n",
    "\n",
    "bias_word_predicted = two_change_only_groupped_by_word[bias_prediction].index.values\n",
    "\n",
    "output[\n",
    "    output[\"TwoChunksChanged\"] & \\\n",
    "    output['original_word'].isin(bias_word_predicted) & \\\n",
    "    (output['similarity_not_perturbed'] < similiarity_threshold)\n",
    "].head(2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d52f9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11449a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b606c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd6de148",
   "metadata": {},
   "source": [
    "## Find patterns\n",
    "\n",
    "when a word A is replaced with B, then the change C happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed1b076d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55775, 21)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1847d719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4219, 21)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[output['TwoChunksChanged']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3949013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c546de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c508f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b1c93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225343d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189fbab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ce163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test to see if SRC_similarity is higher than Trans_similarity\n",
    "print(output[\"Trans-edit_distance\"].mean() - output[\"SRC-edit_distance\"].mean())\n",
    "stats.ttest_rel(output[\"SRC-edit_distance\"], \n",
    "                output[\"Trans-edit_distance\"], \n",
    "                alternative='less')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4187eb64",
   "metadata": {},
   "source": [
    "Tiny pvalue --> Indeed SRC-edit_distance is significantly lower than Trans-edit_distance\n",
    "\n",
    "\n",
    "(Careful with this tho, bc with number of samples too large then statistical test does not make sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada80a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(output[\"#TransChanges-#SrcChanges\"], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49917779",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"ChangesSpread/SentenceLength\"].describe())\n",
    "output[\"ChangesSpread/SentenceLength\"].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c12040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bfa2ffb",
   "metadata": {},
   "source": [
    "Some changes seems to have the same meaning but different phrasing, e.g., noun index 24, 36, 47\n",
    "\n",
    "Both for en-de and en-vi\n",
    "\n",
    "\n",
    "Kind of bias: en-vi adjective sample 82\n",
    "\n",
    "Should we cherry-pick examples? Or cherry-pick the replacement?\n",
    "\n",
    "\n",
    "Or narrow down scope of perturbation? (e.g., on countries, jobs, gender, ...?)\n",
    "\n",
    "\n",
    "\n",
    "Some cherry-picked examples anyway:\n",
    "\n",
    "- He comes from England --> Ông ấy đến từ Anh\n",
    "- He comes from Vietnam --> Hắn đến từ Việt Nam\n",
    "- He comes from North Korea --> Hắn đến từ Bắc Triều Tiên\n",
    "\n",
    "\n",
    "\n",
    "- He is european --> Hắn là người Châu Âu\n",
    "- He is asian --> Anh ấy là người châu Á.\n",
    "\n",
    "\n",
    "\n",
    "- He has black hair --> Hắn có tóc đen.\n",
    "- He has blonde hair --> Anh ấy có tóc vàng\n",
    "\n",
    "\n",
    "But if we limit this then it would hurt the model overal performance as well? \n",
    "\n",
    "*Jan: some kind of loss to minimize the number of changes, but not completely forbidden the changes*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e35e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ca514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755682c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be18d809",
   "metadata": {},
   "source": [
    "# Translation quality vs #changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848d704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "output[\"OriginalTran_Quality\"] = output.apply(\n",
    "    lambda x: sentence_gleu([nltk.word_tokenize(x['REF'])], nltk.word_tokenize(x['OriginalSRC-Trans'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866fb6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.plot.scatter(x='OriginalTran_Quality', y=\"#TransChanges-#SrcChanges/SentenceLength\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f9d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(output['OriginalTran_Quality'], output[\"#TransChanges-#SrcChanges/SentenceLength\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(output[\"OriginalTran_Quality\"], bins='sturges')\n",
    "bin_boundaries = hist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f74bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use bins with same number of samples instead of equal-sized bins\n",
    "\n",
    "# results, bin_boundaries = pd.qcut(output[\"OriginalTran_Quality\"], q=5, retbins=True)\n",
    "# bin_boundaries\n",
    "\n",
    "\n",
    "# Remove bins with too few samples\n",
    "cut_point = 99999\n",
    "for i, value in enumerate(hist[0]):\n",
    "    if value < 5:\n",
    "        cut_point = i\n",
    "        break\n",
    "        \n",
    "bin_boundaries = bin_boundaries[:i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299dec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_boundaries\n",
    "\n",
    "X = output['OriginalTran_Quality']\n",
    "Y = output[\"#TransChanges-#SrcChanges/SentenceLength\"]\n",
    "\n",
    "x_plot = [(bin_boundaries[i] + bin_boundaries[i+1])/2 for i in range(0, len(bin_boundaries)-1)]\n",
    "y_plot = [stats.trim_mean(Y[(bin_boundaries[i] < X) & (X < bin_boundaries[i+1])], 0.1) for i in range(0, len(bin_boundaries)-1)]\n",
    "plt.plot(x_plot, y_plot)\n",
    "plt.xlabel('OriginalTrans_Quality')\n",
    "plt.ylabel('Avg_changes')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4cb6e1ad",
   "metadata": {},
   "source": [
    "bins = [(bin_boundaries[i], bin_boundaries[i+1]) for i in range(0, len(bin_boundaries)-1)]\n",
    "\n",
    "X = output['OriginalTran_Quality']\n",
    "Y = output[\"#TransChanges-#SrcChanges\"]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.boxplot([Y[(bin_i[0] < X) & (X < bin_i[1])] for bin_i in bins])\n",
    "# ax.set_xticklabels(bins)\n",
    "ax.set_xticklabels('')\n",
    "ax.set_xlabel('OriginalTran_Quality')\n",
    "ax.set_ylabel('#changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd6f40",
   "metadata": {},
   "source": [
    "Most of the time downward trend (not as clear for en-de with verb, adverb, pronoun; en-vi adverb, pronoun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a602006a",
   "metadata": {},
   "source": [
    "**Note**: the plot has outliers removed in both X and Y dimensions, by removing too small bins (X) and trimmed-mean (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f10e72",
   "metadata": {},
   "source": [
    "# #changes vs translation quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce6e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(output[\"#TransChanges-#SrcChanges\"], bins=20)\n",
    "bin_boundaries = hist[1]\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3529f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use bins with same number of samples instead of equal-sized bins\n",
    "# results, bin_boundaries = pd.qcut(output[\"#TransChanges-#SrcChanges\"], q=5, retbins=True)\n",
    "# bin_boundaries\n",
    "\n",
    "\n",
    "# Remove bins with too few samples\n",
    "cut_point = 99999\n",
    "for i, value in enumerate(hist[0]):\n",
    "    if value < 10:\n",
    "        cut_point = i\n",
    "        break\n",
    "        \n",
    "bin_boundaries = bin_boundaries[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb682d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_boundaries\n",
    "\n",
    "X = output['#TransChanges-#SrcChanges']\n",
    "Y = output[\"OriginalTran_Quality\"]\n",
    "\n",
    "x_plot = [(bin_boundaries[i] + bin_boundaries[i+1])/2 for i in range(0, len(bin_boundaries)-1)]\n",
    "\n",
    "y_plot = [stats.trim_mean(Y[(bin_boundaries[i] <= X) & (X <= bin_boundaries[i+1])], 0.1) for i in range(0, len(bin_boundaries)-1)]\n",
    "plt.plot(x_plot, y_plot)\n",
    "plt.xlabel('Avg_changes')\n",
    "plt.ylabel('OriginalTran_Quality')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edfd7c1d",
   "metadata": {},
   "source": [
    "bins = [(bin_boundaries[i], bin_boundaries[i+1]) for i in range(0, len(bin_boundaries)-1)]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.boxplot([Y[(bin_i[0] < X) & (X < bin_i[1])] for bin_i in bins])\n",
    "# ax.set_xticklabels(bins)\n",
    "ax.set_xticklabels('')\n",
    "ax.set_xlabel('#changes')\n",
    "ax.set_ylabel('OriginalTran_Quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c740f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30078a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55ac724c",
   "metadata": {},
   "source": [
    "# SentenceLength vs #changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d29f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['OriginalSRC-length'] = output.apply(\n",
    "    lambda x: len(nltk.word_tokenize(x['SRC'])), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.plot.scatter(x='OriginalSRC-length', y=\"#TransChanges-#SrcChanges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f0011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65022c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(output['OriginalSRC-length'], output[\"#TransChanges-#SrcChanges\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f3790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(output[\"OriginalSRC-length\"], bins=20)\n",
    "bin_boundaries = hist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192befe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove bins with too few samples\n",
    "cut_point = 99999\n",
    "for i, value in enumerate(hist[0]):\n",
    "    if value < 10:\n",
    "        cut_point = i\n",
    "        break\n",
    "        \n",
    "bin_boundaries = bin_boundaries[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ad438",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = output['OriginalSRC-length']\n",
    "Y = output[\"#TransChanges-#SrcChanges\"]\n",
    "\n",
    "x_plot = [(bin_boundaries[i] + bin_boundaries[i+1])/2 for i in range(0, len(bin_boundaries)-1)]\n",
    "y_plot = [stats.trim_mean(Y[(bin_boundaries[i] < X) & (X < bin_boundaries[i+1])], 0.1) for i in range(0, len(bin_boundaries)-1)]\n",
    "plt.plot(x_plot, y_plot)\n",
    "plt.xlabel('OriginalSRC-length')\n",
    "plt.ylabel('Avg_changes')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c18891ee",
   "metadata": {},
   "source": [
    "bins = [(bin_boundaries[i], bin_boundaries[i+1]) for i in range(0, len(bin_boundaries)-1)]\n",
    "\n",
    "X = output['OriginalSRC-length']\n",
    "Y = output[\"#TransChanges-#SrcChanges\"]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.boxplot([Y[(bin_i[0] < X) & (X < bin_i[1])] for bin_i in bins])\n",
    "# ax.set_xticklabels(bins)\n",
    "ax.set_xticklabels('')\n",
    "ax.set_xlabel('OriginalSRC-length')\n",
    "ax.set_ylabel('#changes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5a948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7635704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bc35529",
   "metadata": {},
   "source": [
    "# Beam_size vs #changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf8ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_dict = {}\n",
    "beam_values = [1,2,3,4,5]\n",
    "for beam in beam_values:\n",
    "    beam_dict[beam] = read_output_df(dataset, perturb_type, beam, replacement_strategy)\n",
    "    # Make sure the df all have the same index\n",
    "    if beam > 1:\n",
    "        assert beam_dict[beam].index.equals(beam_dict[beam].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63368394",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(beam_values,\n",
    "              [stats.trim_mean(beam_dict[x]['#TransChanges-#SrcChanges'], 0.1) for x in beam_values])\n",
    "plt.xlabel('beam')\n",
    "plt.ylabel('mean_changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5ff79",
   "metadata": {},
   "source": [
    "The mean might not saying anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76076635",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.boxplot([beam_dict[x]['#TransChanges-#SrcChanges'] for x in beam_values])\n",
    "ax.set_xticklabels(beam_values)\n",
    "ax.set_xlabel('beam')\n",
    "ax.set_ylabel('#changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34085167",
   "metadata": {},
   "source": [
    "# Perturbed word type vs #changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40211a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_type_dict = {}\n",
    "word_type_values = [\"noun\", \"verb\", \"adjective\", \"adverb\", \"pronoun\"]\n",
    "for word_type in word_type_values:\n",
    "    word_type_dict[word_type] = read_output_df(dataset, perturb_type=word_type, beam=beam, replacement_strategy=replacement_strategy)\n",
    "\n",
    "    \n",
    "print('--------------------------------')\n",
    "print('word type    -   trimmed-mean #changes')\n",
    "\n",
    "for word_type in word_type_values:\n",
    "    print(f\"{word_type} - {stats.trim_mean(word_type_dict[word_type]['#TransChanges-#SrcChanges'], 0.1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.boxplot([word_type_dict[x]['#TransChanges-#SrcChanges'] for x in word_type_values])\n",
    "ax.set_xticklabels(word_type_values)\n",
    "ax.set_xlabel('word_type')\n",
    "ax.set_ylabel('#changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b06547",
   "metadata": {},
   "source": [
    "# #Changes per sentence across word types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ceef7",
   "metadata": {},
   "source": [
    "See if the chaos changes are sentence-specific. Excluding perturbing pronouns bc not many samples have pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c13866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sentences that has multiple word types perturbed\n",
    "word_type_values = [\"noun\", \"verb\", \"adjective\", \"adverb\"]\n",
    "index_intersection = word_type_dict[word_type_values[0]].index\n",
    "for i in range(1, len(word_type_values)):\n",
    "    index_intersection = \\\n",
    "        index_intersection.intersection(word_type_dict[word_type_values[i]].index)\n",
    "\n",
    "len(index_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3094f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_per_word_type = pd.DataFrame()\n",
    "for word_type in word_type_values:\n",
    "    changes_per_word_type[word_type] = word_type_dict[word_type][\"#TransChanges-#SrcChanges\"].loc[index_intersection]\n",
    "    \n",
    "# Count the number of samples where the changes in trans always bigger than changes in SRC\n",
    "changes_per_word_type[(changes_per_word_type['noun'] > 0) & (changes_per_word_type['verb'] > 0) & \\\n",
    "                      (changes_per_word_type['adjective'] > 0) & (changes_per_word_type['adverb'] > 0)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba41e95",
   "metadata": {},
   "source": [
    "Small portion of rows --> not sentence-specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ace820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy import displacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentence = \"He is from Vietnam\"\n",
    "doc = nlp(sentence)\n",
    "\n",
    "print(f\"{'Node (from)-->':<15} {'Relation':^10} {'-->Node (to)':>15}\\n\")\n",
    "\n",
    "for token in doc:\n",
    "    print(\"{:<15} {:^10} {:>15}\".format(str(token.head.text), str(token.dep_), str(token.text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42699574",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(f\"Token: {token.text}\")\n",
    "    print(f\"Ancestors: {list(token.ancestors)}\")\n",
    "    print(f\"Children: {list(token.children)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce4e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy import displacy \n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "sentence = \"Er kommt aus Vietnam\"\n",
    "doc = nlp(sentence)\n",
    "\n",
    "print(f\"{'Node (from)-->':<15} {'Relation':^10} {'-->Node (to)':>15}\\n\")\n",
    "\n",
    "for token in doc:\n",
    "    print(\"{:<15} {:^10} {:>15}\".format(str(token.head.text), str(token.dep_), str(token.text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47c9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347d716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f080ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366ccb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
